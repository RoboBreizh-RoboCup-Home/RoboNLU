{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertConfig, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from utils import MODEL_CLASSES, compute_metrics, get_intent_labels, get_slot_labels, compute_metrics_multi_intent,compute_metrics_multi_intent_Pro,compute_metrics_final\n",
    "\n",
    "from seqeval.metrics.sequence_labeling import get_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.modeling_final import JointBERTMultiIntent\n",
    "\n",
    "class Trainer_multi(object):\n",
    "    def __init__(self, args, train_dataset=None, dev_dataset=None, test_dataset=None):\n",
    "        self.args = args\n",
    "        self.train_dataset = train_dataset\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        \n",
    "        self.slot_preds_list = None\n",
    "        self.intent_token_preds_list = None\n",
    "        \n",
    "        \n",
    "        # set of intents\n",
    "        self.intent_label_lst = get_intent_labels(args)\n",
    "        # set of slots\n",
    "        self.slot_label_lst = get_slot_labels(args)\n",
    "\n",
    "        self.num_intent_labels = len(self.intent_label_lst)\n",
    "        self.num_slot_labels = len(self.slot_label_lst)\n",
    "\n",
    "        # Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later\n",
    "        self.pad_token_label_id = args.ignore_index\n",
    "\n",
    "        self.config_class, self.model_class, _ = MODEL_CLASSES[args.model_type]\n",
    "        \n",
    "        self.config = self.config_class.from_pretrained(args.model_name_or_path, finetuning_task=args.task)\n",
    "        # self.config = BertConfig.from_pretrained('bert-base-uncased', finetuning_task='gpsr_pro_instance')\n",
    "\n",
    "        self.model = self.model_class.from_pretrained(args.model_name_or_path,\n",
    "                                                      config=self.config,\n",
    "                                                      intent_label_lst=self.intent_label_lst,\n",
    "                                                      slot_label_lst=self.slot_label_lst,\n",
    "                                                      )\n",
    "\n",
    "        ###############################################################\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name.startswith(\"encoder.layer.11\") or name.startswith(\"encoder.layer.10\"): # unfroze last 2 layers\n",
    "                param.requires_grad = True\n",
    "            # else:\n",
    "            #     param.requires_grad = False\n",
    "            print('name: ',name,'param: ',param.requires_grad)\n",
    "        ###############################################################\n",
    "\n",
    "\n",
    "        # self.model = JointBERTMultiIntent()\n",
    "        \n",
    "        # GPU or CPU\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def get_intent_token_loss(self,intent_token_logits,intent_token_ids,attention_mask):\n",
    "        intent_token_loss = 0.0\n",
    "        intent_token_loss_fct = nn.CrossEntropyLoss(ignore_index=self.args.ignore_index)\n",
    "        if attention_mask is not None:\n",
    "            active_intent_loss = attention_mask.view(-1) == 1\n",
    "            active_intent_logits = intent_token_logits.view(-1, self.num_intent_labels)[active_intent_loss]\n",
    "            active_intent_tokens = intent_token_ids.view(-1)[active_intent_loss]\n",
    "            intent_token_loss = intent_token_loss_fct(active_intent_logits, active_intent_tokens)\n",
    "        else:\n",
    "            intent_token_loss = intent_token_loss_fct(intent_token_logits.view(-1, self.num_intent_labels), intent_token_ids.view(-1))\n",
    "\n",
    "        return self.args.slot_loss_coef * intent_token_loss\n",
    "\n",
    "    def get_slot_loss(self,slot_logits,slot_labels_ids,attention_mask):\n",
    "        slot_loss = 0.0\n",
    "        slot_loss_fct = nn.CrossEntropyLoss(ignore_index=self.args.ignore_index)\n",
    "        # Only keep active parts of the loss\n",
    "        if attention_mask is not None:\n",
    "            try:\n",
    "                active_loss = attention_mask.view(-1) == 1\n",
    "                attention_mask_cpu = attention_mask.data.cpu().numpy()\n",
    "                active_loss_cpu = active_loss.data.cpu().numpy()\n",
    "                active_logits = slot_logits.view(-1, self.num_slot_labels)[active_loss]\n",
    "                active_labels = slot_labels_ids.view(-1)[active_loss]\n",
    "                slot_loss = slot_loss_fct(active_logits, active_labels)\n",
    "            except:\n",
    "                print('attention_mask: ', attention_mask_cpu)\n",
    "                print('active_loss: ', active_loss_cpu)\n",
    "                logger.info('attention_mask: ', attention_mask_cpu)\n",
    "                logger.info('active_loss: ', active_loss_cpu)\n",
    "        else:\n",
    "            slot_loss = slot_loss_fct(slot_logits.view(-1, self.num_slot_labels), slot_labels_ids.view(-1))\n",
    "\n",
    "        return self.args.slot_loss_coef * slot_loss\n",
    "\n",
    "    def get_referee_token_loss(self,referee_token_logits,referee_labels_ids,attention_mask,pro_sample_mask):\n",
    "        referee_token_loss = 0.0\n",
    "        class_weights = torch.FloatTensor([1,10,200]).to(self.device)\n",
    "        referee_token_loss_fct = nn.CrossEntropyLoss(weight = class_weights,ignore_index=self.args.ignore_index) #self.referee_token_loss_fct\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            try:\n",
    "                active_loss = attention_mask[pro_sample_mask].view(-1) == 1\n",
    "                attention_mask_cpu = attention_mask.data.cpu().numpy()\n",
    "                active_loss_cpu = active_loss.data.cpu().numpy()\n",
    "                active_logits = referee_token_logits.view(-1, 3)[active_loss]\n",
    "                active_labels = referee_labels_ids[pro_sample_mask].view(-1)[active_loss]\n",
    "                referee_token_loss = referee_token_loss_fct(active_logits,\n",
    "                                                            active_labels)\n",
    "            except:\n",
    "                logger.info('attention_mask: ', attention_mask_cpu)\n",
    "                logger.info('active_loss: ', active_loss_cpu)\n",
    "        else:\n",
    "            referee_token_loss = referee_token_loss_fct(referee_token_logits.view(-1, 3), referee_labels_ids[pro_sample_mask].view(-1))\n",
    "\n",
    "        return self.args.pro_loss_coef * referee_token_loss\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        #logger.info(vars(self.args))\n",
    "        train_sampler = RandomSampler(self.train_dataset)\n",
    "        train_dataloader = DataLoader(self.train_dataset, sampler=train_sampler, batch_size=self.args.train_batch_size)\n",
    "\n",
    "        if self.args.max_steps > 0:\n",
    "            t_total = self.args.max_steps\n",
    "            self.args.num_train_epochs = self.args.max_steps // (len(train_dataloader) // self.args.gradient_accumulation_steps) + 1\n",
    "        else:\n",
    "            t_total = len(train_dataloader) // self.args.gradient_accumulation_steps * self.args.num_train_epochs\n",
    "\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': self.args.weight_decay},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate, eps=self.args.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=self.args.warmup_steps, num_training_steps=t_total)\n",
    "\n",
    "        # Train!\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(self.train_dataset))\n",
    "        logger.info(\"  Num Epochs = %d\", self.args.num_train_epochs)\n",
    "        logger.info(\"  Total train batch size = %d\", self.args.train_batch_size)\n",
    "        logger.info(\"  Gradient Accumulation steps = %d\", self.args.gradient_accumulation_steps)\n",
    "        logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "        logger.info(\"  Logging steps = %d\", self.args.logging_steps)\n",
    "        logger.info(\"  Save steps = %d\", self.args.save_steps)\n",
    "\n",
    "        global_step = 0\n",
    "        tr_loss = 0.0\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        train_iterator = trange(int(self.args.num_train_epochs), desc=\"Epoch\")\n",
    "\n",
    "        step_per_epoch = len(train_dataloader) // 2\n",
    "\n",
    "        # record the evaluation loss\n",
    "        eval_acc = 0.0\n",
    "        MAX_RECORD = self.args.patience\n",
    "        num_eval = -1\n",
    "        eval_result_record = (num_eval, eval_acc)\n",
    "        flag = False\n",
    "        for _ in train_iterator:\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=FLAG)\n",
    "            for step, batch in enumerate(epoch_iterator):\n",
    "                self.model.train()\n",
    "                batch = tuple(t.to(self.device) for t in batch)  # GPU or CPU\n",
    "\n",
    "                attention_mask = batch[1]\n",
    "                intent_label_ids = batch[3]\n",
    "                slot_labels_ids =  batch[4]\n",
    "                intent_token_ids =  batch[5]\n",
    "                B_tag_mask =  batch[6]\n",
    "                BI_tag_mask =  batch[7]\n",
    "                tag_intent_label =  batch[8]\n",
    "                referee_labels_ids =  batch[9] #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                pro_labels_ids = batch[10]\n",
    "\n",
    "                inputs = {'input_ids': batch[0],\n",
    "                          'attention_mask': batch[1],\n",
    "                          'pro_labels_ids' : batch[10]}\n",
    "                if self.args.model_type != 'distilbert':\n",
    "                    inputs['token_type_ids'] = batch[2]\n",
    "\n",
    "\n",
    "                outputs = self.model(**inputs)\n",
    "\n",
    "                if self.args.pro and self.args.intent_seq:\n",
    "                    slot_logits, intent_token_logits, referee_token_logits,all_referee_token_logits = outputs\n",
    "\n",
    "                slot_loss = self.get_slot_loss(slot_logits,slot_labels_ids,attention_mask)\n",
    "                intent_token_loss =  self.get_intent_token_loss(intent_token_logits,intent_token_ids,attention_mask)\n",
    "\n",
    "                pro_token_mask = pro_labels_ids > 0\n",
    "                pro_sample_mask = torch.max(pro_token_mask.long(),dim = 1)[0] > 0\n",
    "                referee_token_loss = self.get_referee_token_loss(referee_token_logits,referee_labels_ids,attention_mask,pro_sample_mask)\n",
    "                loss = slot_loss + intent_token_loss + referee_token_loss\n",
    "\n",
    "\n",
    "                if self.args.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                tr_loss += loss.item()\n",
    "                if (step + 1) % self.args.gradient_accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()  # Update learning rate schedule\n",
    "                    self.model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "                    # if self.args.logging_steps > 0 and global_step % self.args.logging_steps == 0:\n",
    "                    if self.args.logging_steps > 0 and global_step % step_per_epoch == 0:\n",
    "                        logger.info(\"***** Training Step %d *****\", step)\n",
    "                        logger.info(\"  total_loss = %f\", loss)\n",
    "                        logger.info(\"  slot_loss = %f\", slot_loss)\n",
    "                        logger.info(\"  intent_token_loss = %f\", intent_token_loss)\n",
    "                        logger.info(\"  referee_token_loss = %f\", referee_token_loss) #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "                        dev_result = self.evaluate(\"dev\")\n",
    "                        test_result = self.evaluate(\"test\")\n",
    "                        num_eval += 1\n",
    "                        if self.args.patience != 0:\n",
    "                            if dev_result['sementic_frame_acc'] + dev_result['intent_acc'] + dev_result['slot_f1']   > eval_result_record[1]:\n",
    "                                self.save_model()\n",
    "                                eval_result_record = (num_eval, dev_result['sementic_frame_acc'] + dev_result['intent_acc'] + dev_result['slot_f1'] )\n",
    "                            else:\n",
    "                                cur_num_eval = eval_result_record[0]\n",
    "                                if num_eval - cur_num_eval >= MAX_RECORD:\n",
    "                                    # it has been ok\n",
    "                                    logger.info(' EARLY STOP Evaluate: at {}, best eval {} intent_slot_acc: {} '.format(num_eval, cur_num_eval, eval_result_record[1]))\n",
    "                                    flag = True\n",
    "                                    break\n",
    "                        else:\n",
    "                            self.save_model()\n",
    "\n",
    "                            \n",
    "\n",
    "                if 0 < self.args.max_steps < global_step:\n",
    "                    epoch_iterator.close()\n",
    "                    break\n",
    "\n",
    "            if flag:\n",
    "                train_iterator.close()\n",
    "                break\n",
    "\n",
    "            if 0 < self.args.max_steps < global_step:\n",
    "                train_iterator.close()\n",
    "                break\n",
    "\n",
    "        return global_step, tr_loss / global_step\n",
    "\n",
    "    def evaluate(self, mode):\n",
    "        if mode == 'test':\n",
    "            dataset = self.test_dataset\n",
    "        elif mode == 'dev':\n",
    "            dataset = self.dev_dataset\n",
    "        else:\n",
    "            raise Exception(\"Only dev and test dataset available\")\n",
    "\n",
    "        eval_sampler = SequentialSampler(dataset)\n",
    "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.args.eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation on %s dataset *****\", mode)\n",
    "        logger.info(\"  Num examples = %d\", len(dataset))\n",
    "        logger.info(\"  Batch size = %d\", self.args.eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        intent_preds = None\n",
    "        slot_preds = None\n",
    "        intent_token_preds = None\n",
    "        out_intent_label_ids = None\n",
    "        out_slot_labels_ids = None\n",
    "        out_intent_token_ids = None\n",
    "        \n",
    "        tag_intent_preds = None\n",
    "        out_tag_intent_ids = None\n",
    "        referee_preds = None #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        out_referee_labels_ids = None #!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        all_referee_preds = None #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        all_out_referee_labels_ids = None #!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\", disable=FLAG):\n",
    "            batch = tuple(t.to(self.device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                attention_mask = batch[1]\n",
    "                intent_label_ids = batch[3]\n",
    "                slot_labels_ids =  batch[4]\n",
    "                intent_token_ids =  batch[5]\n",
    "                B_tag_mask =  batch[6]\n",
    "                BI_tag_mask =  batch[7]\n",
    "                tag_intent_label =  batch[8]\n",
    "                referee_labels_ids =  batch[9] #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                pro_labels_ids = batch[10]\n",
    "\n",
    "                inputs = {'input_ids': batch[0],\n",
    "                          'attention_mask': batch[1],\n",
    "                          'pro_labels_ids' : batch[10]}\n",
    "\n",
    "\n",
    "                if self.args.model_type != 'distilbert':\n",
    "                    inputs['token_type_ids'] = batch[2]\n",
    "                outputs = self.model(**inputs)\n",
    "\n",
    "            # logits = outputs[0]\n",
    "            if self.args.pro and self.args.intent_seq:\n",
    "                slot_logits, intent_token_logits, referee_token_logits,all_referee_token_logits = outputs\n",
    "\n",
    "            slot_loss = self.get_slot_loss(slot_logits,slot_labels_ids,attention_mask)\n",
    "            intent_token_loss =  self.get_intent_token_loss(intent_token_logits,intent_token_ids,attention_mask)\n",
    "\n",
    "            pro_token_mask = pro_labels_ids > 0\n",
    "            pro_sample_mask = torch.max(pro_token_mask.long(),dim = 1)[0] > 0\n",
    "            referee_token_loss = self.get_referee_token_loss(referee_token_logits,referee_labels_ids,attention_mask,pro_sample_mask)\n",
    "            loss = slot_loss + intent_token_loss + referee_token_loss\n",
    "\n",
    "            # ============================= Slot prediction ==============================\n",
    "            if slot_preds is None:\n",
    "                if self.args.use_crf:\n",
    "                    # decode() in `torchcrf` returns list with best index directly\n",
    "                    slot_preds = np.array(self.model.crf.decode(slot_logits))\n",
    "                else:\n",
    "                    slot_preds = slot_logits.detach().cpu().numpy()\n",
    "\n",
    "                out_slot_labels_ids = slot_labels_ids.detach().cpu().numpy()\n",
    "            else:\n",
    "                if self.args.use_crf:\n",
    "                    slot_preds = np.append(slot_preds, np.array(self.model.crf.decode(slot_logits)), axis=0)\n",
    "                else:\n",
    "                    slot_preds = np.append(slot_preds, slot_logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "                out_slot_labels_ids = np.append(out_slot_labels_ids, slot_labels_ids.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "            # ============================= Pronoun referee prediction ==============================\n",
    "            if self.args.pro:\n",
    "                if all_referee_preds is None:\n",
    "\n",
    "                    all_referee_preds = all_referee_token_logits.detach().cpu().numpy()\n",
    "                    referee_preds = referee_token_logits.detach().cpu().numpy()\n",
    "\n",
    "                    pro_sample_mask_np = (torch.max(inputs[\"pro_labels_ids\"],dim = 1)[0] > 0).detach().cpu().numpy()\n",
    "                    all_out_referee_labels_ids = referee_labels_ids.detach().cpu().numpy()\n",
    "                    out_referee_labels_ids = all_out_referee_labels_ids[pro_sample_mask_np]\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    all_referee_preds = np.append(all_referee_preds,all_referee_token_logits.detach().cpu().numpy(), axis = 0)\n",
    "                    referee_preds = np.append(referee_preds, referee_token_logits.detach().cpu().numpy(), axis = 0)\n",
    "\n",
    "                    pro_sample_mask_np = (torch.max(inputs[\"pro_labels_ids\"],dim = 1)[0] > 0).detach().cpu().numpy()\n",
    "                    new_all_out_referee_labels_ids = referee_labels_ids.detach().cpu().numpy()\n",
    "                    all_out_referee_labels_ids = np.append(all_out_referee_labels_ids,new_all_out_referee_labels_ids,axis = 0)\n",
    "                    new_out_referee_labels_ids = new_all_out_referee_labels_ids[pro_sample_mask_np]#np.array([ele for i,ele in enumerate(new_all_out_referee_labels_ids) if pro_sample_mask_np[i] != False])\n",
    "                    out_referee_labels_ids = np.append(out_referee_labels_ids, new_out_referee_labels_ids, axis = 0)\n",
    "\n",
    "            if self.args.intent_seq:\n",
    "                if intent_token_preds is None:\n",
    "                    if self.args.use_crf:\n",
    "                        intent_token_preds = np.array(self.model.crf.decode(intent_token_logits))\n",
    "                    else:\n",
    "                        intent_token_preds = intent_token_logits.detach().cpu().numpy()\n",
    "\n",
    "                    out_intent_token_ids = intent_token_ids.detach().cpu().numpy()\n",
    "                else:\n",
    "                    if self.args.use_crf:\n",
    "                        intent_token_preds = np.append(intent_token_preds, np.array(self.model.crf.decode(intent_token_logits)), axis=0)\n",
    "                    else:\n",
    "                        intent_token_preds = np.append(intent_token_preds, intent_token_logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "                    out_intent_token_ids = np.append(out_intent_token_ids, intent_token_ids.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            nb_eval_steps += 1\n",
    "            eval_loss = eval_loss / nb_eval_steps\n",
    "            results = {\n",
    "                \"loss\": eval_loss\n",
    "            }\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "        # Slot result\n",
    "        # (batch_size, seq_len)\n",
    "        if not self.args.use_crf:\n",
    "            slot_preds = np.argmax(slot_preds, axis=2)\n",
    "        slot_label_map = {i: label for i, label in enumerate(self.slot_label_lst)}\n",
    "        out_slot_label_list = [[] for _ in range(out_slot_labels_ids.shape[0])]\n",
    "        slot_preds_list = [[] for _ in range(out_slot_labels_ids.shape[0])]\n",
    "        \n",
    "        B_tag_mask_pred = []\n",
    "        BI_tag_mask_pred = []\n",
    "        \n",
    "        # generate mask\n",
    "        for i in range(out_slot_labels_ids.shape[0]):\n",
    "            # record the padding position\n",
    "            pos_offset = [0 for _ in range(out_slot_labels_ids.shape[1])]\n",
    "            pos_cnt = 0\n",
    "            padding_recording = [0 for _ in range(out_slot_labels_ids.shape[1])]\n",
    "            \n",
    "            for j in range(out_slot_labels_ids.shape[1]):\n",
    "                if out_slot_labels_ids[i, j] != self.pad_token_label_id:\n",
    "                    out_slot_label_list[i].append(slot_label_map[out_slot_labels_ids[i][j]])\n",
    "                    slot_preds_list[i].append(slot_label_map[slot_preds[i][j]])\n",
    "                    pos_offset[pos_cnt+1] = pos_offset[pos_cnt]\n",
    "                    pos_cnt += 1\n",
    "                else:\n",
    "                    pos_offset[pos_cnt] = pos_offset[pos_cnt] + 1\n",
    "                    padding_recording[j] = 1\n",
    "\n",
    "        # ============================= Pronoun Referee Prediction ============================ !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # print('referee_preds shape: ',referee_preds.shape)\n",
    "        # print('all_referee_preds shape: ', all_referee_preds.shape)\n",
    "        # print('out_referee_labels_ids shape: ',out_referee_labels_ids.shape)\n",
    "        print('all_out_referee_labels_ids shape: ', all_out_referee_labels_ids.shape)\n",
    "        # print('out_intent_token_ids shape: ',out_intent_token_ids.shape)\n",
    "\n",
    "        referee_token_map = {0:'PAD', 1:'O' ,2: 'B-referee'} # All referee are just one word in EGPSR\n",
    "\n",
    "\n",
    "        if self.args.pro:\n",
    "            referee_preds = np.argmax(referee_preds, axis=2)\n",
    "            all_referee_preds = np.argmax(all_referee_preds, axis=2)\n",
    "\n",
    "\n",
    "            referee_preds_list = [[] for _ in range(out_referee_labels_ids.shape[0])]\n",
    "            out_referee_label_list = [[] for _ in range(out_referee_labels_ids.shape[0])]\n",
    "            all_referee_preds_list = [[] for _ in range(all_out_referee_labels_ids.shape[0])]\n",
    "            all_out_referee_label_list = [[] for _ in range(all_out_referee_labels_ids.shape[0])]\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(out_referee_labels_ids.shape[0]):\n",
    "                for j in range(out_referee_labels_ids.shape[1]):\n",
    "                    if out_referee_labels_ids[i, j] != self.pad_token_label_id:\n",
    "                        out_referee_label_list[i].append(referee_token_map[out_referee_labels_ids[i][j]])\n",
    "                        referee_preds_list[i].append(referee_token_map[referee_preds[i][j]])\n",
    "\n",
    "            for i in range(all_out_referee_labels_ids.shape[0]):\n",
    "                for j in range(all_out_referee_labels_ids.shape[1]):\n",
    "                    if all_out_referee_labels_ids[i, j] != self.pad_token_label_id:\n",
    "                        all_out_referee_label_list[i].append(referee_token_map[all_out_referee_labels_ids[i][j]])\n",
    "                        all_referee_preds_list[i].append(referee_token_map[all_referee_preds[i][j]])\n",
    "\n",
    "\n",
    "\n",
    "        intent_token_map = {i: label for i, label in enumerate(self.intent_label_lst)}\n",
    "        out_intent_token_list = None\n",
    "        intent_token_preds_list = None\n",
    "        # ============================= Intent Seq Prediction ============================\n",
    "        if self.args.intent_seq:\n",
    "            if not self.args.use_crf:\n",
    "                intent_token_preds = np.argmax(intent_token_preds, axis=2)\n",
    "            out_intent_token_list = [[] for _ in range(out_intent_token_ids.shape[0])]\n",
    "            intent_token_preds_list = [[] for _ in range(out_intent_token_ids.shape[0])]\n",
    "\n",
    "            for i in range(out_intent_token_ids.shape[0]):\n",
    "                for j in range(out_intent_token_ids.shape[1]):\n",
    "                    if out_intent_token_ids[i, j] != self.pad_token_label_id:\n",
    "                        out_intent_token_list[i].append(intent_token_map[out_intent_token_ids[i][j]])\n",
    "                        intent_token_preds_list[i].append(intent_token_map[intent_token_preds[i][j]])\n",
    "\n",
    "\n",
    "        total_result = compute_metrics_final(\n",
    "                                       slot_preds_list,\n",
    "                                       out_slot_label_list,\n",
    "                                       intent_token_preds_list,\n",
    "                                       out_intent_token_list,\n",
    "                                       referee_preds_list,\n",
    "                                       out_referee_label_list\n",
    "                                      )\n",
    "        results.update(total_result)\n",
    "        print(total_result)\n",
    "\n",
    "\n",
    "\n",
    "        print(slot_label_map)\n",
    "        print(intent_token_map)\n",
    "\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Pronoun Acc !!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        correct = 0\n",
    "        for ref_pred_seq,ref_label_seq in zip(referee_preds_list,out_referee_label_list):\n",
    "            if ref_pred_seq == ref_label_seq:\n",
    "                correct += 1\n",
    "        ref_acc = correct/len(referee_preds_list)\n",
    "        print('Pronoun Accurac: ',ref_acc, ', correct: ',correct, ', total: ',len(referee_preds_list))\n",
    "        results.update({'Pronoun Accuracy':ref_acc})\n",
    "\n",
    "\n",
    "        correct = 0\n",
    "        for slot_pred_seq,slot_label_seq in zip(slot_preds_list,out_slot_label_list):\n",
    "            if slot_pred_seq == slot_label_seq:\n",
    "                correct += 1\n",
    "            else:\n",
    "                print('pred: ',slot_pred_seq)\n",
    "                print('true: ',slot_label_seq,'\\n')\n",
    "        slot_acc = correct/len(slot_preds_list)\n",
    "        print('Slot Accurac: ',slot_acc, ', correct: ',correct, ', total: ',len(slot_preds_list))\n",
    "\n",
    "\n",
    "\n",
    "        correct = 0\n",
    "        for intent_pred_seq,intent_label_seq in zip(intent_token_preds_list,out_intent_token_list):\n",
    "            if intent_pred_seq == intent_label_seq:\n",
    "                correct += 1\n",
    "            else:\n",
    "                print('pred: ',intent_pred_seq)\n",
    "                print('true: ',intent_label_seq,'\\n')\n",
    "        intent_acc = correct/len(intent_token_preds_list)\n",
    "        print('Intent Accurac: ',intent_acc, ', correct: ',correct, ', total: ',len(intent_token_preds_list))\n",
    "\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(results.keys()):\n",
    "            logger.info(\"  %s_%s = %s\", mode, key, str(results[key]))\n",
    "        \n",
    "        #self.store_pred(slot_preds_list,intent_token_preds_list)\n",
    "        self.slot_preds_list = slot_preds_list\n",
    "        self.intent_token_preds_list = intent_token_preds_list\n",
    "        return results\n",
    "\n",
    "    # def save_model(self):\n",
    "    #     # Save model checkpoint (Overwrite)\n",
    "    #     if not os.path.exists(self.args.model_dir):\n",
    "    #         os.makedirs(self.args.model_dir)\n",
    "    #     model_to_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "    #     #model_to_save.save_pretrained(os.path.join(self.args.model_dir, 'pytorch_model.pt'))\n",
    "    #     torch.save(model_to_save, os.path.join(self.args.model_dir, 'pytorch_model.pt'))\n",
    "    #     # Save training arguments together with the trained model\n",
    "    #     # torch.save(self.args, os.path.join(self.args.model_dir, 'training_args.pt'))\n",
    "    #     logger.info(\"Saving model checkpoint to %s\", self.args.model_dir)\n",
    "\n",
    "    def save_model(self):\n",
    "        # Save model checkpoint (Overwrite)\n",
    "        if not os.path.exists(self.args.model_dir):\n",
    "            os.makedirs(self.args.model_dir)\n",
    "        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "        model_to_save.save_pretrained(self.args.model_dir)\n",
    "\n",
    "        # Save training arguments together with the trained model\n",
    "        torch.save(self.args, os.path.join(self.args.model_dir, 'training_args.bin'))\n",
    "        logger.info(\"Saving model checkpoint to %s\", self.args.model_dir)\n",
    "\n",
    "    def load_model(self):\n",
    "        # Check whether model exists\n",
    "        if not os.path.exists(self.args.model_dir):\n",
    "            raise Exception(\"Model doesn't exists! Train first!\")\n",
    "\n",
    "        try:\n",
    "            self.model = self.model_class.from_pretrained(self.args.model_dir,\n",
    "                                                          args=self.args,\n",
    "                                                          intent_label_lst=self.intent_label_lst,\n",
    "                                                          slot_label_lst=self.slot_label_lst)\n",
    "            self.model.to(self.device)\n",
    "            logger.info(\"***** Model Loaded *****\")\n",
    "        except:\n",
    "            raise Exception(\"Some model files might be missing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLAG = False\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launing with model name: google/mobilebert-uncased\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import sys\n",
    "sys.argv = ['']\n",
    "\n",
    "#from trainer import Trainer, Trainer_multi, Trainer_woISeq\n",
    "from utils import init_logger, load_tokenizer, read_prediction_text, set_seed, MODEL_CLASSES, MODEL_PATH_MAP\n",
    "from data_loader import load_and_cache_examples\n",
    "\n",
    "def init_logger():\n",
    "    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                        datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                        level=logging.INFO)\n",
    "\n",
    "def main(args):\n",
    "#     init_logger(args)\n",
    "#     init_logger()\n",
    "\n",
    "    set_seed(args)\n",
    "    tokenizer = load_tokenizer(args)\n",
    "    train_dataset = load_and_cache_examples(args, tokenizer, mode=\"train\")\n",
    "    dev_dataset = load_and_cache_examples(args, tokenizer, mode=\"dev\")\n",
    "    test_dataset = load_and_cache_examples(args, tokenizer, mode=\"test\")\n",
    "    \n",
    "    if args.multi_intent == 1:\n",
    "        trainer = Trainer_multi(args, train_dataset, dev_dataset, test_dataset)\n",
    "    else:\n",
    "        trainer = Trainer(args, train_dataset, dev_dataset, test_dataset)\n",
    "    if args.do_train:\n",
    "        trainer.train()\n",
    "    if args.do_eval:\n",
    "        trainer.load_model()\n",
    "        trainer.evaluate(\"test\")\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    time_wait = random.uniform(0, 10)\n",
    "    time.sleep(time_wait)\n",
    "    parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--task\", default='mixsnips', required=True, type=str, help=\"The name of the task to train\")\n",
    "    parser.add_argument(\"--task\", default='gpsr_pro_instance_say', type=str, help=\"The name of the task to train\")\n",
    "\n",
    "#     parser.add_argument(\"--model_dir\", default='./gpsr_model', required=True, type=str, help=\"Path to save, load model\")\n",
    "    parser.add_argument(\"--model_dir\", default='./gpsr_final_model', type=str, help=\"Path to save, load model\")\n",
    "\n",
    "    parser.add_argument(\"--data_dir\", default=\"./data\", type=str, help=\"The input data dir\")\n",
    "    parser.add_argument(\"--intent_label_file\", default=\"intent_label.txt\", type=str, help=\"Intent Label file\")\n",
    "    parser.add_argument(\"--slot_label_file\", default=\"slot_label.txt\", type=str, help=\"Slot Label file\")\n",
    "    parser.add_argument(\"--model_type\", default=\"mobilebert\", type=str, help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()))\n",
    "#     parser.add_argument(\"--intent_seq\", type=int, default=0, help=\"whether we use intent seq setting\")\n",
    "    parser.add_argument(\"--intent_seq\", type=int, default=1, help=\"whether we use intent seq setting\")\n",
    "\n",
    "    parser.add_argument(\"--pro\", type=int, default=1, help=\"support pronoun disambiguition\")#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "    parser.add_argument(\"--multi_intent\", type=int, default=1, help=\"whether we use multi intent setting\")\n",
    "    parser.add_argument(\"--tag_intent\", type=int, default=0, help=\"whether we can use tag to predict intent\")\n",
    "    \n",
    "    parser.add_argument(\"--BI_tag\", type=int, default=0, help='use BI sum or just B')\n",
    "    parser.add_argument(\"--cls_token_cat\", type=int, default=1, help='whether we cat the cls to the slot output of bert')\n",
    "    parser.add_argument(\"--intent_attn\", type=int, default=1, help='whether we use attention mechanism on the CLS intent output')\n",
    "    parser.add_argument(\"--num_mask\", type=int, default=7, help=\"assumptive number of slot in one sentence\")\n",
    "                                           #max slot num = 7\n",
    "    \n",
    "    parser.add_argument('--seed', type=int, default=25, help=\"random seed for initialization\")\n",
    "    parser.add_argument(\"--train_batch_size\", type=int, default=64,  help=\"Batch size for training.\")\n",
    "#     parser.add_argument(\"--train_batch_size\", default=64, type=int, help=\"Batch size for training.\")\n",
    "\n",
    "    parser.add_argument(\"--eval_batch_size\", default=128, type=int, help=\"Batch size for evaluation.\")\n",
    "    parser.add_argument(\"--max_seq_len\", default=32, type=int, help=\"The maximum total input sequence length after tokenization.\")\n",
    "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
    "#     parser.add_argument(\"--num_train_epochs\", default=10.0, type=float, help=\"Total number of training epochs to perform.\")\n",
    "    parser.add_argument(\"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\")\n",
    "    \n",
    "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
    "    parser.add_argument('--gradient_accumulation_steps', type=int, default=1, help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--max_grad_norm\", default=1, type=float, help=\"Max gradient norm.\")\n",
    "    parser.add_argument(\"--max_steps\", default=-1, type=int, help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n",
    "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "    parser.add_argument(\"--dropout_rate\", default=0.1, type=float, help=\"Dropout for fully-connected layers\")\n",
    "    parser.add_argument('--logging_steps', type=int, default=500, help=\"Log every X updates steps.\")\n",
    "    parser.add_argument('--save_steps', type=int, default=300, help=\"Save checkpoint every X updates steps.\")\n",
    "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
    "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the test set.\")\n",
    "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "    parser.add_argument(\"--ignore_index\", default=0, type=int, help='Specifies a target value that is ignored and does not contribute to the input gradient')\n",
    "    parser.add_argument('--slot_loss_coef', type=float, default=2.0, help='Coefficient for the slot loss.')\n",
    "\n",
    "\n",
    "    parser.add_argument('--pro_loss_coef', type=float, default=10.0, help='Coefficient for the pronoun loss.')\n",
    "\n",
    "\n",
    "\n",
    "    parser.add_argument('--tag_intent_coef', type=float, default=1.0, help='Coefficient for the tag intent loss')\n",
    "\n",
    "    # CRF option\n",
    "    parser.add_argument(\"--use_crf\", action=\"store_true\", help=\"Whether to use CRF\")\n",
    "    parser.add_argument(\"--slot_pad_label\", default=\"PAD\", type=str, help=\"Pad token for slot label pad (to be ignore when calculate loss)\")\n",
    "    parser.add_argument(\"--patience\", default=0, type=int, help=\"The initial learning rate for Adam.\")\n",
    "    \n",
    "    parser.add_argument('-f')#########################\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    now = datetime.now()\n",
    "    args.model_dir = args.model_dir + '_' + now.strftime('%m-%d-%H:%M:%S')\n",
    "    args.model_name_or_path = MODEL_PATH_MAP[args.model_type]\n",
    "\n",
    "tokenizer = load_tokenizer(args)\n",
    "print(\"Launing with model name: {}\".format(args.model_name_or_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b6d12a45d045b285a782f00c08c6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/147M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing JointMobileBERTMultiIntent: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing JointMobileBERTMultiIntent from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing JointMobileBERTMultiIntent from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of JointMobileBERTMultiIntent were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['multi_intent_classifier.linear.weight', 'multi_intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias', 'intent_token_classifier.linear.weight', 'intent_token_classifier.linear.bias', 'pro_classifier.linear1.weight', 'pro_classifier.linear1.bias', 'pro_classifier.linear2.weight', 'pro_classifier.linear2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:  mobilebert.embeddings.word_embeddings.weight param:  True\n",
      "name:  mobilebert.embeddings.position_embeddings.weight param:  True\n",
      "name:  mobilebert.embeddings.token_type_embeddings.weight param:  True\n",
      "name:  mobilebert.embeddings.embedding_transformation.weight param:  True\n",
      "name:  mobilebert.embeddings.embedding_transformation.bias param:  True\n",
      "name:  mobilebert.embeddings.LayerNorm.bias param:  True\n",
      "name:  mobilebert.embeddings.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.0.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.1.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.2.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.3.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.4.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.5.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.6.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.7.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.8.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.9.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.10.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.11.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.12.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.13.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.14.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.15.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.16.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.17.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.18.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.19.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.20.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.21.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.22.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.attention.self.query.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.attention.self.query.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.attention.self.key.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.attention.self.key.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.attention.self.value.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.attention.self.value.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.attention.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.attention.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.attention.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.attention.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.output.bottleneck.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.output.bottleneck.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.output.bottleneck.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.output.bottleneck.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.bottleneck.input.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.bottleneck.input.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.bottleneck.input.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.bottleneck.input.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.bottleneck.attention.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.bottleneck.attention.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.0.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.0.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.0.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.0.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.0.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.0.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.1.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.1.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.1.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.1.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.1.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.1.output.LayerNorm.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.2.intermediate.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.2.intermediate.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.2.output.dense.weight param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.2.output.dense.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.2.output.LayerNorm.bias param:  True\n",
      "name:  mobilebert.encoder.layer.23.ffn.2.output.LayerNorm.weight param:  True\n",
      "name:  multi_intent_classifier.linear.weight param:  True\n",
      "name:  multi_intent_classifier.linear.bias param:  True\n",
      "name:  slot_classifier.linear.weight param:  True\n",
      "name:  slot_classifier.linear.bias param:  True\n",
      "name:  intent_token_classifier.linear.weight param:  True\n",
      "name:  intent_token_classifier.linear.bias param:  True\n",
      "name:  pro_classifier.linear1.weight param:  True\n",
      "name:  pro_classifier.linear1.bias param:  True\n",
      "name:  pro_classifier.linear2.weight param:  True\n",
      "name:  pro_classifier.linear2.bias param:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 24/24 [00:01<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (3016, 32)\n",
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 1.0, 'Pro_recall': 1.0, 'Pro_f1': 1.0, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  1.0 , correct:  648 , total:  648\n",
      "Slot Accurac:  1.0 , correct:  3016 , total:  3016\n",
      "Intent Accurac:  1.0 , correct:  3016 , total:  3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 95/95 [00:05<00:00, 16.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (12068, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'slot_precision': 0.9999767144021423, 'slot_recall': 0.9999767144021423, 'slot_f1': 0.9999767144021423, 'Pro_precision': 0.9969430645777608, 'Pro_recall': 0.9996168582375479, 'Pro_f1': 0.9982781710350106, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  0.9969348659003832 , correct:  2602 , total:  2610\n",
      "pred:  ['O', 'B-dest', 'B-what', 'I-what', 'O', 'O', 'O', 'O', 'I-what', 'I-what', 'I-what', 'I-what', 'I-what']\n",
      "true:  ['O', 'B-dest', 'B-what', 'I-what', 'I-what', 'O', 'O', 'O', 'I-what', 'I-what', 'I-what', 'I-what', 'I-what'] \n",
      "\n",
      "Slot Accurac:  0.9999171362280411 , correct:  12067 , total:  12068\n",
      "Intent Accurac:  1.0 , correct:  12068 , total:  12068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 24/24 [00:01<00:00, 17.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (3016, 32)\n",
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 0.9984591679506933, 'Pro_recall': 1.0, 'Pro_f1': 0.9992289899768697, 'intent_token_precision': 0.9998354044934573, 'intent_token_recall': 0.999917695473251, 'intent_token_f1': 0.9998765482901938}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  0.9984567901234568 , correct:  647 , total:  648\n",
      "Slot Accurac:  1.0 , correct:  3016 , total:  3016\n",
      "pred:  ['O', 'O', 'B-go', 'I-go', 'I-go', 'I-go', 'O', 'B-find', 'I-find', 'I-find', 'I-take', 'O', 'O', 'B-take', 'I-take', 'I-take', 'I-take']\n",
      "true:  ['O', 'O', 'B-go', 'I-go', 'I-go', 'I-go', 'O', 'B-find', 'I-find', 'I-find', 'I-find', 'O', 'O', 'B-take', 'I-take', 'I-take', 'I-take'] \n",
      "\n",
      "Intent Accurac:  0.9996684350132626 , correct:  3015 , total:  3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 95/95 [00:05<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (12068, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|| 708/708 [02:13<00:00,  5.32it/s]\n",
      "Epoch:  33%|      | 1/3 [02:13<04:26, 133.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 0.9992340099578706, 'Pro_recall': 0.9996168582375479, 'Pro_f1': 0.9994253974334418, 'intent_token_precision': 0.9998359714590339, 'intent_token_recall': 0.9999179790026247, 'intent_token_f1': 0.9998769735493132}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  0.9992337164750957 , correct:  2608 , total:  2610\n",
      "Slot Accurac:  1.0 , correct:  12068 , total:  12068\n",
      "pred:  ['B-go', 'I-go', 'I-go', 'I-go', 'O', 'B-find', 'I-find', 'I-take', 'O', 'O', 'B-take', 'I-take', 'I-take', 'I-take', 'I-take']\n",
      "true:  ['B-go', 'I-go', 'I-go', 'I-go', 'O', 'B-find', 'I-find', 'I-find', 'O', 'O', 'B-take', 'I-take', 'I-take', 'I-take', 'I-take'] \n",
      "\n",
      "pred:  ['B-go', 'I-go', 'I-go', 'I-go', 'I-go', 'O', 'B-find', 'I-find', 'I-take', 'O', 'O', 'B-take', 'I-take', 'I-take', 'I-take', 'I-take', 'O']\n",
      "true:  ['B-go', 'I-go', 'I-go', 'I-go', 'I-go', 'O', 'B-find', 'I-find', 'I-find', 'O', 'O', 'B-take', 'I-take', 'I-take', 'I-take', 'I-take', 'O'] \n",
      "\n",
      "pred:  ['B-go', 'I-go', 'I-go', 'I-go', 'O', 'B-find', 'I-find', 'I-find', 'I-take', 'O', 'O', 'B-take', 'I-take', 'I-take', 'I-take', 'I-take', 'O']\n",
      "true:  ['B-go', 'I-go', 'I-go', 'I-go', 'O', 'B-find', 'I-find', 'I-find', 'I-find', 'O', 'O', 'B-take', 'I-take', 'I-take', 'I-take', 'I-take', 'O'] \n",
      "\n",
      "pred:  ['O', 'O', 'B-go', 'I-go', 'I-go', 'I-go', 'O', 'B-find', 'I-find', 'I-take', 'O', 'O', 'B-take', 'I-take', 'I-take', 'I-take', 'I-take']\n",
      "true:  ['O', 'O', 'B-go', 'I-go', 'I-go', 'I-go', 'O', 'B-find', 'I-find', 'I-find', 'O', 'O', 'B-take', 'I-take', 'I-take', 'I-take', 'I-take'] \n",
      "\n",
      "Intent Accurac:  0.9996685449121644 , correct:  12064 , total:  12068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 24/24 [00:01<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (3016, 32)\n",
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 0.9984591679506933, 'Pro_recall': 1.0, 'Pro_f1': 0.9992289899768697, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  0.9984567901234568 , correct:  647 , total:  648\n",
      "Slot Accurac:  1.0 , correct:  3016 , total:  3016\n",
      "Intent Accurac:  1.0 , correct:  3016 , total:  3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 95/95 [00:05<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (12068, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 0.9996168582375479, 'Pro_recall': 0.9996168582375479, 'Pro_f1': 0.9996168582375479, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  0.9996168582375479 , correct:  2609 , total:  2610\n",
      "Slot Accurac:  1.0 , correct:  12068 , total:  12068\n",
      "Intent Accurac:  1.0 , correct:  12068 , total:  12068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 24/24 [00:01<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (3016, 32)\n",
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 0.9984591679506933, 'Pro_recall': 1.0, 'Pro_f1': 0.9992289899768697, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  0.9984567901234568 , correct:  647 , total:  648\n",
      "Slot Accurac:  1.0 , correct:  3016 , total:  3016\n",
      "Intent Accurac:  1.0 , correct:  3016 , total:  3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 95/95 [00:06<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (12068, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|| 708/708 [02:13<00:00,  5.31it/s]\n",
      "Epoch:  67%|   | 2/3 [04:26<02:13, 133.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 0.9996170049789352, 'Pro_recall': 1.0, 'Pro_f1': 0.9998084658111472, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  0.9996168582375479 , correct:  2609 , total:  2610\n",
      "Slot Accurac:  1.0 , correct:  12068 , total:  12068\n",
      "Intent Accurac:  1.0 , correct:  12068 , total:  12068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 24/24 [00:01<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (3016, 32)\n",
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 1.0, 'Pro_recall': 1.0, 'Pro_f1': 1.0, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  1.0 , correct:  648 , total:  648\n",
      "Slot Accurac:  1.0 , correct:  3016 , total:  3016\n",
      "Intent Accurac:  1.0 , correct:  3016 , total:  3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 95/95 [00:05<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (12068, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 0.9996170049789352, 'Pro_recall': 1.0, 'Pro_f1': 0.9998084658111472, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  0.9996168582375479 , correct:  2609 , total:  2610\n",
      "Slot Accurac:  1.0 , correct:  12068 , total:  12068\n",
      "Intent Accurac:  1.0 , correct:  12068 , total:  12068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 24/24 [00:01<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (3016, 32)\n",
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 1.0, 'Pro_recall': 1.0, 'Pro_f1': 1.0, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  1.0 , correct:  648 , total:  648\n",
      "Slot Accurac:  1.0 , correct:  3016 , total:  3016\n",
      "Intent Accurac:  1.0 , correct:  3016 , total:  3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Evaluating: 100%|| 95/95 [00:05<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (12068, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|| 708/708 [02:11<00:00,  5.38it/s]\n",
      "Epoch: 100%|| 3/3 [06:38<00:00, 132.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 0.9996170049789352, 'Pro_recall': 1.0, 'Pro_f1': 0.9998084658111472, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  0.9996168582375479 , correct:  2609 , total:  2610\n",
      "Slot Accurac:  1.0 , correct:  12068 , total:  12068\n",
      "Intent Accurac:  1.0 , correct:  12068 , total:  12068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2124, 0.24817539988782883)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_and_cache_examples(args, tokenizer, mode=\"train\")\n",
    "dev_dataset = load_and_cache_examples(args, tokenizer, mode=\"dev\")\n",
    "test_dataset = load_and_cache_examples(args, tokenizer, mode=\"test\")\n",
    "trainer = Trainer_multi(args, train_dataset, dev_dataset, test_dataset)\n",
    "trainer.train()\n",
    "# test_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 95/95 [00:05<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_out_referee_labels_ids shape:  (12068, 32)\n",
      "{'slot_precision': 1.0, 'slot_recall': 1.0, 'slot_f1': 1.0, 'Pro_precision': 0.9996170049789352, 'Pro_recall': 1.0, 'Pro_f1': 0.9998084658111472, 'intent_token_precision': 1.0, 'intent_token_recall': 1.0, 'intent_token_f1': 1.0}\n",
      "{0: 'PAD', 1: 'O', 2: 'I-obj', 3: 'B-sour', 4: 'B-dest', 5: 'I-sour', 6: 'B-what', 7: 'B-obj', 8: 'I-dest', 9: 'I-per', 10: 'I-what', 11: 'B-per'}\n",
      "{0: 'PAD', 1: 'O', 2: 'B-greet', 3: 'I-greet', 4: 'B-know', 5: 'I-know', 6: 'B-follow', 7: 'I-follow', 8: 'B-take', 9: 'I-take', 10: 'B-tell', 11: 'I-tell', 12: 'B-guide', 13: 'I-guide', 14: 'B-go', 15: 'I-go', 16: 'B-answer', 17: 'I-answer', 18: 'B-find', 19: 'I-find'}\n",
      "Pronoun Accurac:  0.9996168582375479 , correct:  2609 , total:  2610\n",
      "Slot Accurac:  1.0 , correct:  12068 , total:  12068\n",
      "Intent Accurac:  1.0 , correct:  12068 , total:  12068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.5992251583198933e-07,\n",
       " 'slot_precision': 1.0,\n",
       " 'slot_recall': 1.0,\n",
       " 'slot_f1': 1.0,\n",
       " 'Pro_precision': 0.9996170049789352,\n",
       " 'Pro_recall': 1.0,\n",
       " 'Pro_f1': 0.9998084658111472,\n",
       " 'intent_token_precision': 1.0,\n",
       " 'intent_token_recall': 1.0,\n",
       " 'intent_token_f1': 1.0,\n",
       " 'Pronoun Accuracy': 0.9996168582375479}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD',\n",
       " 'O',\n",
       " 'B-greet',\n",
       " 'I-greet',\n",
       " 'B-know',\n",
       " 'I-know',\n",
       " 'B-follow',\n",
       " 'I-follow',\n",
       " 'B-take',\n",
       " 'I-take',\n",
       " 'B-tell',\n",
       " 'I-tell',\n",
       " 'B-guide',\n",
       " 'I-guide',\n",
       " 'B-go',\n",
       " 'I-go',\n",
       " 'B-answer',\n",
       " 'I-answer',\n",
       " 'B-find',\n",
       " 'I-find']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_lab = get_intent_labels(args)\n",
    "slot_label_lst = get_slot_labels(args)\n",
    "slot_label_lst\n",
    "intent_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
    "trainer.model.save_pretrained('trained_model')\n",
    "print('finished')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
