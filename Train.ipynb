{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='0'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAHqCAYAAADRZ5BFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABDAElEQVR4nO3dfbxtVV3o/8+Xw2MoKoqGoILeo10kUTmghTdTU+lqQZmF+YBpUoopt/sQdu1qFletn1qUT6jIsXwILa+EkRGKiFeBw7OA5LmCytUrZKn0ZKHf3x9jbM46m332XnPNMfZeZ5/P+/Var73X3GuOPdYaY435nWOOMWZkJpIkSepnt7XOgCRJ0npnwCVJktSZAZckSVJnBlySJEmdGXBJkiR1tvtaZ2Al97nPffKQQw5Z62xIkiSt6PLLL//bzDxg8fa5D7gOOeQQtmzZstbZkCRJWlFEfGmp7V5SlCRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqbKqAKyLuGREfiojPR8QNEfFDEbF/RJwfEV+oP+818fpXRMTWiLgxIp46sf3IiLi2/u30iIgeb0qSJGmeTNvD9fvAX2bmDwBHADcApwIXZOZG4IL6nIg4DDgBeDhwLPCWiNhQ03krcBKwsT6ObfQ+JEmS5taKAVdE7Af8CPAugMz818z8JnAcsLm+bDNwfP39OOADmfmdzLwJ2AocHREHAvtl5mcyM4H3TOwjSZK0bk3Tw/Vg4Dbg3RFxZUS8MyL2Be6XmV8DqD/vW19/EPCVif1vqdsOqr8v3n4XEXFSRGyJiC233XbboDckSZI0b6YJuHYHHg28NTMfBfwj9fLhDiw1LiuX2X7XjZlnZOamzNx0wAEHTJFFSZKk+TVNwHULcEtmXlKff4gSgH29Xiak/rx14vUPmNj/YOCrdfvBS2yXJEla11YMuDLz/wFfiYiH1U1PAq4HzgFOrNtOBD5Sfz8HOCEi9oqIQymD4y+tlx1vj4jH1tmJz5vYR5Ikad3afcrX/Qrw3ojYE/gi8AuUYO3siHgh8GXgmQCZeV1EnE0Jyu4ATs7M79Z0XgycBewDnFcfkiRJ61qUCYPza9OmTblly5Y7nx9y6kdX3Ofm1z2tZ5YkSZKWFBGXZ+amxdtdaV6SJKkzAy5JkqTODLgkSZI6M+CSJEnqzIBLkiSpMwMuSZKkzgy4JEmSOjPgkiRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqzIBLkiSpMwMuSZKkzgy4JEmSOjPgkiRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqzIBLkiSpMwMuSZKkzgy4JEmSOjPgkiRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqzIBLkiSpMwMuSZKkzgy4JEmSOjPgkiRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqbKqAKyJujohrI+KqiNhSt+0fEedHxBfqz3tNvP4VEbE1Im6MiKdObD+yprM1Ik6PiGj/liRJkubLkB6uJ2TmIzNzU31+KnBBZm4ELqjPiYjDgBOAhwPHAm+JiA11n7cCJwEb6+PY8W9BkiRpvo25pHgcsLn+vhk4fmL7BzLzO5l5E7AVODoiDgT2y8zPZGYC75nYR5Ikad2aNuBK4K8i4vKIOKluu19mfg2g/rxv3X4Q8JWJfW+p2w6qvy/efhcRcVJEbImILbfddtuUWZQkSZpPu0/5umMy86sRcV/g/Ij4/DKvXWpcVi6z/a4bM88AzgDYtGnTkq+RJEnaWUzVw5WZX60/bwU+DBwNfL1eJqT+vLW+/BbgARO7Hwx8tW4/eIntkiRJ69qKAVdE7BsRd1/4HXgK8DngHODE+rITgY/U388BToiIvSLiUMrg+EvrZcfbI+KxdXbi8yb2kSRJWremuaR4P+DDdQWH3YH3ZeZfRsRlwNkR8ULgy8AzATLzuog4G7geuAM4OTO/W9N6MXAWsA9wXn1IkiStaysGXJn5ReCIJbZ/A3jSDvY5DThtie1bgMOHZ1OSJGnn5UrzkiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmdTB1wRsSEiroyIc+vz/SPi/Ij4Qv15r4nXviIitkbEjRHx1IntR0bEtfVvp0dEtH07kiRJ82dID9fLgRsmnp8KXJCZG4EL6nMi4jDgBODhwLHAWyJiQ93nrcBJwMb6OHZU7iVJknYCUwVcEXEw8DTgnRObjwM21983A8dPbP9AZn4nM28CtgJHR8SBwH6Z+ZnMTOA9E/tIkiStW9P2cP0e8N+A701su19mfg2g/rxv3X4Q8JWJ191Stx1Uf1+8/S4i4qSI2BIRW2677bYpsyhJkjSfVgy4IuLpwK2ZefmUaS41LiuX2X7XjZlnZOamzNx0wAEHTPlvJUmS5tPuU7zmGOAnI+I/AnsD+0XEHwNfj4gDM/Nr9XLhrfX1twAPmNj/YOCrdfvBS2yXJEla11bs4crMV2TmwZl5CGUw/Mcz8znAOcCJ9WUnAh+pv58DnBARe0XEoZTB8ZfWy463R8Rj6+zE503sI0mStG5N08O1I68Dzo6IFwJfBp4JkJnXRcTZwPXAHcDJmfndus+LgbOAfYDz6kOSJGldGxRwZeaFwIX1928AT9rB604DTlti+xbg8KGZlCRJ2pm50rwkSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLU2YoBV0TsHRGXRsTVEXFdRPxm3b5/RJwfEV+oP+81sc8rImJrRNwYEU+d2H5kRFxb/3Z6RESftyVJkjQ/punh+g7wxMw8AngkcGxEPBY4FbggMzcCF9TnRMRhwAnAw4FjgbdExIaa1luBk4CN9XFsu7ciSZI0n1YMuLL4h/p0j/pI4Dhgc92+GTi+/n4c8IHM/E5m3gRsBY6OiAOB/TLzM5mZwHsm9pEkSVq3phrDFREbIuIq4Fbg/My8BLhfZn4NoP68b335QcBXJna/pW47qP6+eLskSdK6NlXAlZnfzcxHAgdTeqsOX+blS43LymW23zWBiJMiYktEbLntttumyaIkSdLcGjRLMTO/CVxIGXv19XqZkPrz1vqyW4AHTOx2MPDVuv3gJbYv9X/OyMxNmbnpgAMOGJJFSZKkuTPNLMUDIuKe9fd9gB8DPg+cA5xYX3Yi8JH6+znACRGxV0QcShkcf2m97Hh7RDy2zk583sQ+kiRJ69buU7zmQGBznWm4G3B2Zp4bEZ8Bzo6IFwJfBp4JkJnXRcTZwPXAHcDJmfndmtaLgbOAfYDz6kOSJGldWzHgysxrgEctsf0bwJN2sM9pwGlLbN8CLDf+S5Ikad1xpXlJkqTODLgkSZI6M+CSJEnqzIBLkiSpMwMuSZKkzgy4JEmSOjPgkiRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqzIBLkiSpMwMuSZKkzgy4JEmSOjPgkiRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqzIBLkiSpMwMuSZKkzgy4JEmSOjPgkiRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqzIBLkiSpMwMuSZKkzgy4JEmSOjPgkiRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqzIBLkiSpsxUDroh4QER8IiJuiIjrIuLldfv+EXF+RHyh/rzXxD6viIitEXFjRDx1YvuREXFt/dvpERF93pYkSdL8mKaH6w7gP2fmvwceC5wcEYcBpwIXZOZG4IL6nPq3E4CHA8cCb4mIDTWttwInARvr49iG70WSJGkurRhwZebXMvOK+vvtwA3AQcBxwOb6ss3A8fX344APZOZ3MvMmYCtwdEQcCOyXmZ/JzATeM7GPJEnSujVoDFdEHAI8CrgEuF9mfg1KUAbct77sIOArE7vdUrcdVH9fvF2SJGldmzrgioi7AX8KnJKZ317upUtsy2W2L/W/ToqILRGx5bbbbps2i5IkSXNpqoArIvagBFvvzcw/q5u/Xi8TUn/eWrffAjxgYveDga/W7Qcvsf0uMvOMzNyUmZsOOOCAad+LJEnSXJpmlmIA7wJuyMw3TvzpHODE+vuJwEcmtp8QEXtFxKGUwfGX1suOt0fEY2uaz5vYR5Ikad3afYrXHAM8F7g2Iq6q234deB1wdkS8EPgy8EyAzLwuIs4GrqfMcDw5M79b93sxcBawD3BefUiSJK1rKwZcmXkxS4+/AnjSDvY5DThtie1bgMOHZFCSJGln50rzkiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJnBlySJEmdGXBJkiR1ZsAlSZLUmQGXJElSZwZckiRJnRlwSZIkdWbAJUmS1JkBlyRJUmcGXJIkSZ2tGHBFxJkRcWtEfG5i2/4RcX5EfKH+vNfE314REVsj4saIeOrE9iMj4tr6t9MjItq/HUmSpPkzTQ/XWcCxi7adClyQmRuBC+pzIuIw4ATg4XWft0TEhrrPW4GTgI31sThNSZKkdWnFgCszLwL+btHm44DN9ffNwPET2z+Qmd/JzJuArcDREXEgsF9mfiYzE3jPxD6SJEnr2qxjuO6XmV8DqD/vW7cfBHxl4nW31G0H1d8Xb19SRJwUEVsiYsttt902YxYlSZLmQ+tB80uNy8plti8pM8/IzE2ZuemAAw5oljlJkqS1MGvA9fV6mZD689a6/RbgAROvOxj4at1+8BLbJUmS1r1ZA65zgBPr7ycCH5nYfkJE7BURh1IGx19aLzveHhGPrbMTnzexjyRJ0rq2+0oviIj3Az8K3CcibgFeBbwOODsiXgh8GXgmQGZeFxFnA9cDdwAnZ+Z3a1Ivpsx43Ac4rz4kSZLWvRUDrsx81g7+9KQdvP404LQltm8BDh+UO0mSpHXAleYlSZI6M+CSJEnqzIBLkiSpMwMuSZKkzgy4JEmSOjPgkiRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqzIBLkiSpMwMuSZKkzgy4JEmSOjPgkiRJ6syAS5IkqTMDLkmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTOdl/rDKyFQ0796Iqvufl1T1uFnEiSpF3BLhlwtWLgJkmSpuElRUmSpM4MuCRJkjoz4JIkSerMgEuSJKkzAy5JkqTODLgkSZI6M+CSJEnqzIBLkiSpMxc+XWOtFk91EVZJkuaXAZfuZNAmSVIfXlKUJEnqzB4uNbdST5m9ZJKkXY09XJIkSZ3Zw6W55HgySdJ6Yg+XJElSZ/ZwaV1zPJkkaR7YwyVJktSZPVzSChxPJkkay4BLWgXzdEcBA0hJWn0GXJJm4vg4SZqeY7gkSZI6s4dL0prx8qakXYU9XJIkSZ0ZcEmSJHXmJUVJO70WA/i9vCmpJwMuSWrEoE3Sjqx6wBURxwK/D2wA3pmZr1vtPEjSPJun9dbmKS/SzmxVA66I2AC8GXgycAtwWUSck5nXr2Y+JEk7n3m6dDwveTGY3Xmsdg/X0cDWzPwiQER8ADgOMOCSJGmNzFPwNy/BbGuRmav3zyJ+Bjg2M3+xPn8u8JjMfOmi150EnFSfPgy4cZlk7wP8bYPstUjHvMx3GubFvKx2GuZl/vOy3t6PeVn7vDwoMw9YvHG1e7hiiW13ifgy8wzgjKkSjNiSmZtGZ6xBOuZlvtMwL+ZltdMwL/Ofl/X2fszL/OZltdfhugV4wMTzg4GvrnIeJEmSVtVqB1yXARsj4tCI2BM4AThnlfMgSZK0qlb1kmJm3hERLwU+RlkW4szMvG5kslNdelyldMzLfKfRKh3z0i+NVunMSxqt0jEv851Gq3TMS780WqUzcxqrOmhekiRpV+S9FCVJkjoz4JIkSerMgEuSJKkzAy5JkqTOVv3m1S1ExMGUJSX+A3B/4J+BzwEfBc7LzO8NTG9f4F8y87trkZeI2Bt4+lJpDJnFGRGblkjjrzPz7wakcV/gmEVpbBnymUbEDwHPqXk5kO0/kz/OzG9Nm9ZEmjOVUau60uizbZWX3YAjJtK4LjO/Pm0+ahqjy6hhvZ2LOte6XalpjmlbWpTz6DKap7oykd69JtK5eZayqemMKZ+5aefqvqO/RzWdUZ9ty+/RmLy0LJ9mn+3ONksxIt4NHAScC2wBbgX2Bh4KPAE4Ejg1My9aJo3dKBXi2cBRwHeAvYDbgL8AzsjML6xSXl4N/ARwIXD5EmnsDfznzLxmmTSeD7wMuGmJNI6hVI7fyMwvL5PGE4BTgf2BKxel8RDgQ8AbMvPbO/xASjrnURaz/QhLfyY/AbwxM5ddf61FGTUqn+cz8rNtmJeHAL8G/BjwBcpnsZDGPwFvBzav1Ai0KKNG9XZu6lyL8qnptKi3rcr51Ywvo7moKzWdewAnA88C9mTb53I/4LPAWzLzEyuk0artn6d2bvT3qMVnW9Np0c61KOdW5dOkjbpTZu5UD+DwFf6+J/DvVnjNJ4HfAB4B7DaxfX/gGcCfAs9Zpbw8bYW/3xfYtMJrTgb2WebvjwSetEIavws8cAd/2x04HnjGFJ/JfRq9ZnQZNSqf0Z9tw7y8H/gR6onSEvXkFODE1SijRvV2bupci/Kpr2tRb1uVc4symou6Ul93PvBc4J5L/O1I4PeAF/Yun1afS8P6Mvp71OKzra9t0c61KOdW5dOkjVp47HQ9XC1ExB6Z+W9jX6N+LCPtjKy3823eymfe8qO+1s2g+YjYHBFvjYjDV3rtNJV3TAUfkpdl0vifEfFrEXHvEWm8JCJ+LiJmHqsXEcdFxGNm3X8inb+OiPMi4unTvL5nGTUqn9GfbcO8bIqIg8bko6YzqIx2kEaLersmdW4HaQwqn871tlU5tyijuagrNZ0DI2KvaV67Cm3/PLVzo79HQz7bFdJp0c6NzkuLelvTmemzXTcBF/CHwF9TuiJnEhE31MdL1zovwKXAHcCbRqQRwOOAPxuRxmOAV9Zr4mM8D3gl8KAxiTQqoxbl0+KzbZWXXwHOjYg/GZmXFmXUot7OU51rUT6t6m2rcm5RRvNSVwD+CPh8RPx/sybQsO2fp3auxfdo9GdbtfgetchLk/Jh1s922muP8/gA7gbs2zjNe7PCmINO7+WYabYts/9uwM+udZlM5Ofl02xbjTJihXEFa/T53B24W+s0Z9hnT+Dw+thjhv1H1dvG7//l02xbZv8NwO92zF+TtmVoOTdoWzZQZnWNzXe3ukI5AXr4apfPPLVzvR4tPtu1ykvP8pnlsVOO4YqIl1BmDuxLKYDbgddn5ltmSOtBwMbM/OuI2AfYPTNvn3LfPwd2+AFm5k8OyMcVmfnolbatkMZFmfkj075+B2nsAbyYMmgXyqDOt+XAbu0dvJ8rM/NRA9N5AfCpnGLm0DJpXEwJLM4C3peZ35whjXsAr6ZMMYbyubwmB079jogfBN5DGRQblBk4z8thyyhckJlPWmnbFOn8KLAZuLnm5QGUwdjLzsRblMbM9TYinpiZH4+In17izwn8HXBxTjlFvkWdi4iPUyZBjGoYI+L1mflrK21bIY1W5dyibfkY8BOZ+a9D/nfLfETEfpn57YjYf4k/J/DtAXVldPnUfVq1cy3qS6u2+wi2tXMX5QqzRxft+3uZecoOjo0L3+m3Z+ZnV0hnN+CazJz5EmRNZ1T5tG6jdrp1uCLilcAPAz+amV+s2x4M/H5E7J+Zvz0grRcBJ1EOfg8BDgbeBkzboC10bf408P3AH9fnz6IcxKbJww9R3s8BEfGrE3/aj3JmOcT5EfFfgD8B/nFhYw5YKwp4K7AHsBC8Prdu+8Vpdo6IZwE/DxwaEZNTbvcDvjEgHwsOAZ5TA+PLgU9RArCrpk0gMx8XERuBFwBbIuJS4KzM/KsB+TiTsgTEz9bnzwXeTSn7Id4O/GrWac016HkHpQ4sK8paRt8H3CfK+jRR/7QfZX2Yod4APCUzb6zpP5QyQ+7IKfLSot4+Hvg4ZYr2Uu5N6f5/8gp5aVnnrgQ+EhEfZPvv0NBLx0+mLO0w6ceX2HYXrcq5cdtyM/Dp+vlOfi5vXMV8vI+yltfllINdLPr73SLiHZn561OkNXP5QJd2blR+qlFtN0BEvBx4EduGSrw3Is7IzD+YMok/qj93dNnvPpS29LDlEsnM70XE1RHxwFxhyZ2lNCyfJm3Ugp0u4KJUoiMy818WNmTmFyPiZ4GrgakDLsqU/6OBS2o6X4iywNlUMvOTABHxW4t6lv48IqbtJdiTcml0d8plpgXfBn5m2rxUL6g/T57MJvDgAWkclZlHTDz/eERcPWD//w18jfLFesPE9tuBqc+UFmTm/wCovY8vAv4rZVrwoANGLdtXUtZkOR14VEQE8OtTHkwfkpnPmHj+mxFx1ZA8VPvmxBoymXlhlMUOp/FLlCUB7k856CwccL4NvHmGvOyxEGzVvPxNPUuexuh6m5mvqj9/YUeviYh3TZFUyzq3P6VBfuJkVplyrF5EvBh4CfDgiJj833cHPj1lHlqVc8u25av1sduitFYtH5n59Prz0KX+HhEbKCdFOwy4GpUPNKpzDfMD49tugBcCj8nMf6z5ez3wGWCqgCszL68/PxkRewI/QPn+3LjQOxoR0/aSHghcV0+QJ4P8aa4cNSmfhm3UnQnuVA9Kwe3ob58fmNYl9eeV9efulG7MoXm6AXjwxPNDgRsGpvGgid93A/Zbo8/3CkpwsfD8wcAVM6SzL3VdGcoicT/JbGOEXgmcR+nZOp3Sw3TgwDQeQRmY+zeUA9aj6/b7A1+aMo3PAI+beH4M8JkZ3s+HKevuHFIfrwT+18A0fqVRWZ8JvAv40fp4B/DugWk8aOL3meot5Szx9Fr3Lgd+H7j3WtW5kZ/pPWq5vp8yMHfhsf8MabUq59FlNPkZz0k+fhp4I+VgevxalE+LOte4voxuu4Frgb0nnu8NXDtDXp4GfIWy2O0ngS8DPz4wjccv9VjN8plIp00bNUslW8sHcAFLLDRJOSP9xMC0fodyNvR5Spfgh4HTZsjTsbVCXVgfNwNPHZjG+yjdnfvW/HwN+K8D0/g+ygH8jPp8I/D0gWk8ceK9fLK+lyfM8JlcXvNzUP3ifRh47wzpXEGZzfQqSlCw9wxpXETpGb3LAqbAc6dM4whKD+rN9XEl8IgZ8nKviS/uFZTeunsNTOOZ1IHTtbz/jBpEDkxnL+BX6/4fBv4TsNca1NvzKUHoofXxSsptk1a9zlEa5QuAz9XnjwBeOUNeHrLwWdZ6+zKWWMhxlcq5RRn9EHA98OX6/AjKit+rmo+azluAvwJ+oT7+EnjzwDQeuNRjLepcw/oyuu2ubcDVlPGqrwauAk6Z4f18nokFTuv7G9QhUvd7EPBj9ffvY/iEkVbl06aNGrrDWj+AhwNbKQOgfwV4KWXg71YGzqSgnGW9CPggZYn+F43I1161ETqCgQetuv9V9eezKWduezCwt40yduu/se1gsc9CulPuv6F+4faiHGhmei81rSvqz18B/lv9/coZ07o7ZTzDaZRbnVy8ynXuztlrlAPGTGfmNZ3BX9Il0rmm/nwcpefvOGpv7Wo/GtXby5fYtmWGvIyuc5QD1dGT+y18n4Z+LpQe838H/B9KD+tfrEU5NyqjSyiTKmb+XFrko+5/HROr8Nd2/LqBaVxLubR0bW1T7hiaRqs616K+tGi76+f4w8CjKQHfy4FHDX0vNa2LFj2PxdumSONFwGXA/6nPNwIXrFH5NGmjdsYxXNdTprD/PCX4CkoPxi9lHdcVEZH1E1nBq7OMEXpH3W9DRLw3M589Q76OpHQN7w4cERFk5nsG7L9HHT9zPPCHmflvETHNe5j0kMz8uTpgkMz85zpOaSqZ+d2I+MnMfBMzjLdaJOpg2WdTxgXADGMGoyyU9x8o3cmbKGcpnxqYxkbgtZSBmnsvbM/Mqca21c/lyPr7dPfM2nE6/xQR98gZbmw7YWFGzNOAt2bmR6Lcr26QiLiWu84k+hZlnNtvZ+Y0g0tb1NtPRMQJwNn1+c9QbjA7VIs6932Zeemir80dM+Tle5l5R53d9HuZ+QcRceXANJqUM23KiMz8yqLPZegNlpvkA7iR0iP1pfr8AQxsrzLzByefR8SjKWPnhmrSzjGyvrRou7MMVH9DZv4Qpfd9sInZfNdFxF9QvtNJ6a29bGByo8ZYb8tSk/Jp0kbtjAHXJyj3l/pIZp65sDEi9oyIJwIn1tecNUVaD4yIV2Tma+sAvw9SLhUNEhF/ROkyvYptjVBSpv9P6+2ULuCrgYvqrLyhB/d/rYPLs+brIZSboQ7xvyPiD7nrTMehX8BTgFcAH87M66LMJP3EwDQAXk8JqE8HLsvZVl1+N+WS5JuAJ1AuQ0wdiFZX1tkuY2ev/QtwbUScvyidlw1I4/9GxNspNzd+fZTVl2dZxPg8Sn19X31+AuVz+Rbl+7OjmTmTZq63EXE722ab/SrbZvnuBvwDpcyGOIXxde5v6/dm4Tv0M5RLX0P9Wz3xeR7bPsdpJyQsaFXOLdqWr0TEDwNZ28qXUcaurlo+YttSA/cAbqiDqaEclP/3wLxsJzOviIijZtj1FNq0cy3qS4u2+68i4hnAn03ZabHYZJvxdcqJMpTlb+41MK3vZOa/LgT5Ue7qMTRPpzCifFq3UTvdOlxRpky/gBKxHgp8k9JrsYFyXf/NOeWSAbX3572UbuUnAOfVM4SheboBOGzGCrpcurtn5tRn1xHxZMq15cMon8UxwPMz88IBaSxVGTMzn7jE9mnS2zfrjJdZ1Qb+ofXpjUODroi4PDOPjIhrF85sI+JTmfkfVtp3Io13L7E5M/MFS2xfLp0Tl9qemZsHpPF9lHGD19azvgOBH8xhy1wQEZ/OzGOW2jb5WQ01tN62NqbO1Qb5DMqllb8HbgKenZlfWnbHu6ZzGPDLlIkV74+IQ4Gfy8zXDUijSTnvIO2hbct9KAOFf4xysPkYZQHJWZZAmCkfEfH45f6eddb4lGlNLk+xG+Uy2r0z86nTprEovVHtXKP6MrrtrgHGvpQTsYWVADIz95s2jVYi4ncox/fnUS4JvgS4PjP/+wxpjT4OtbDTBVyTavf0fYB/zgGLWdbu4wV7UM68Pk2ZsTW4NyfKmj0vy8xZzoQX0rgf8D+B+2fmj9cv4A9l5vRTTks69wYeS4nIP5uZfztrnsao3bjvoqym/sAoi+n9Uma+ZGA6j6f0FN7M7ItzfppyWfJDlDVV/i/wusx82JC8tBI7mC49MI3HURbsfXdEHED5nG8amMbVwEmZeUl9fjTwjsw8IqZcHLBhvf1Jti3YeGFmnjtk/5pGkzpX01qY3TTVIsg7SGMfykDsG1d88Y7TaFHOTcporJb5qGkt9Ehdmpm3Dtx/smfiDkr78qc5sdzQlOm0rHOj68u8iIiDKUtJHENp5y6mBOi3DEhjN8plwKdQ2v6PAe8c0rHRuHxGt1GDB8OthwelS3FHj4/PmN7fUyrEOQuPgWmcR1ny4Or6fHdmm447OV36p2bYv9UU/dGDbOs+lwMPm3j+UJYYwLhCGkdR1gE6mHJ58c+Axw5M48HAn1O6xm8FPgIcOsP7+Y+Mny79qpqXv6nP7w98eoa8HEXp3b2JcsC5pm7blylvE9Wi3gKvo8wMfEF9nE8JiFe9zjWs/z9BGWt0U33+yBnahFbl3KKMlqr/D17tfNT9fpYyfmsz5WTsJuBnhqZT09qPGW6J1bLONawvreruTEtuLErjfMrQjd3r4/nA+TOksydlEsAPAnuuYfm0aaNmrWg+tiuMxy/1GJjGZfXnZMW4amAaLaZLt5qiv90aZ/X3q2dI5y6zmJbaNiC9WdeK+ixlaYmFBuQ5zDZjbPR0acpYwVj02Y75TO7BwCnoE/u2qLfXUNfKqc83zPJ+WtS5hvX/8vq5TuZlaJDTpJwbldHo+t8iHwtlCtx34vkBM5TzJsrJxs1sG1d25FrUuYb1ZXTdpcExZEflOkOda7GWV7PjUIs2amccNN9URDyNMttxcvbaa4akkQPGDizjH+vlwKz5eixl8PIQj6fcqHkhjc2URmWI/TPztyae/3ZEHD8wDWgzyBbKrXjexbZbRjyb0jhNLSLeRxkf8d267z0i4o2Z+btDksnMP5p4/scR8dIh+ahuzcytE8+/SOkxGOJfMzOjzvCK6VeqX1JmfisizqXcNmWoFvUW4J6U+5JBOfDMokWda1X/76if6+S2HJhGq3JuUUYt6n+rurJbbn8J8RsMn0xwJvCSzPxUzcvjKL3fjxiYTqt2rkV9aVF3WxxDoEw+eQ5lQVcot7sbOt7vDZR1xLbWvDyEMjPwvAFptCofaNBG7dIBV0S8jbIo2hOAd1Kmel667E7b739xlvv0LcxkuPNPDB9o+KuUS5EPqWOODmD47TdGT5em3RT9X6Z0aR8E3EI5azp52T2W9uK638vYtgTI0JuUH5blprfPBv6Ccn+yy4EhAdcnIuJU4AOUsv454KNRb6Sb09+vcsnp0lGnU+d0sx7PjjJ77Z5R7gf6AurSJiMcNON+LertaymzQD9BKeMfocwsGqpFnWtV/z8XET8PbIiyLMnLGD6TrlU5tyijFvW/RT4A/jLKzbQXDuY/R/leD3H7QrAFkJkX13Z8qFbtXIv60qLutjiGQKmrf0iZGZ6U9zJoghFtTk5blU+TNmqnHjQ/VkRck5mPmPh5N8p02KdMuf+Ds95Au1F+dgceRinQWWbjfZIyBmchaDyKckuaf4Lp7kG1aJYKlK7ThdkdQ4PIuRAR11HGRLyPsv7PJyPi6tz+vmMrpXHTMn/OnHJNr1h6tuNkOlM1SlFmpN45mDQzz59mv2XSO3Pa/73EvqPqbU3jQEp9DcplgP83S17GalX/o8ww/O9sP+D3t3L4oOwm5dygbWlV/0fXlZrOT1MWhF1YUPPDA/d/E+Vk+/1sCyD/nrLkEDl8GZxRWtSXFnW3xTGklYh4K2Wl+cmT0xup95ic8uS0ZX5Gt1G7esB1SWY+JiI+Sxko+A3KgLqNU+6/sNzABZn5pBnz8NPL/X1IpYqG06ZnFRF/wDJd4TnlelOx9KKck+lM3fUfES+j9GpdTRkX8EDgj3PAshDaXst62yAvTercejMvZTQv+ZgUSy+hsCBzhaUU1mud63kMiYin54CZfWNOTue1fHbpS4rAuRFxT8qlpSsoBfTOAfvvVqcXPzS2X9cFgMx84xRpLCwUd1/K2j8fr8+fQBksOHVjtBoB1RS21J/HUNYD+5P6/JkMG3s1y3iiJWXm6ZTZOwBExJcpn+8oEfH9LXpipm2Ilrh0vZ0BvS8bKWfTf0eZjfQOyrIZ/wf4xcycZkXoZvV2B3m8IjMfvfIrgXZ1brTYtjjnkgb0Mo8uZ/qX0bT1v2s+al7OyMyTpn19Zo79/jepcy3qS0utjiERcXhmfm7R5qOAqQOuzPyFEVno3ibElEvnbGfoKPv19GDiXlOUe1DdgwH3n6J0jf8aZSXqVy1+DMzLucCBE88PpFzeHPsez2iQxqA7ztd9PsHEXdkp6519Yg7K/NyGaX10hn0OX2Lbbw5M4zWURQDvTpnW/mLqfcKm3P9i4CTgv1DWJHsmZdLIkxk+86xLvZ2xPLrUuSH1n22zlH+f0sj/RH28D/ifq1nOvctoaP3vWVeYYYbhZL7Wqs61rC87SP/KBmkMPobUNubSWn/v2aKMa7pPX83yaf1Yk386L4+lGtIZg4tBU1V3kMbnFj3fbfG2GdOduSEa+X9vpMyaWXh+L8qYjWn3v51y24+Fx+2TP0fk68oZ93sBZQHKsZ/L6IZoqaBoSKDExPRsYOuO/jZlWk3qLWWsxo/V3/dhhrWRxta5lg+WuFHvUtt6lnPLMmpR/3u1cQ3K6soR+zapcy3qS8fPZ6ZjCOVm068FttYA8skD929xctqqfF4/zbaVHrvkJcWI+H7KrIV9IuJRcOd99fajDKQcJDPvnKYaEedm5iyXwy6cmHmTlPvaLTfOYNq8De4+jXKPs42Z+ddRVj/ePYevuP06ts3qgHIW9+ppd87Muw/8f9O6csb9DgGeUz+byyk30L4oM68ekkiWWa0bKQewLVHuB/fuHDYY+rt1xuXCjLFnMexGwt+b+H3xvey+xzCj622dgXcSsD9lXbKDgbcBQ8dFjqpzE/lpUf8PmJxUE+VWLQcMTGNsOS9o0bYcwvj6PyofHS+/zdomQKM6R4P6EhGvz8xfW2nbULMcQ+p+X4iIV1Iu750OPCoiAvj1nG7c3tvqUg5nAe/LzG9m5qsGZqNV+TyZcjVr0o8vsW1Zu+Sg+Sj3s3s+ZfG7y9gWcH0b2DxlZdhR2lfm0Ou62/b9KbbdOmDqmTctG6LJg19mPqQGB2/LGSYF1MD2MfXpzDPPotyOYWGA+0WZOcs05SbqAfhFlMtxB2XmhhnT2QAcT2mIvk2pg1M1RBFxCOUSxMJtMz4NnJKZN0/5v/+JctYZlABnYep1UFYPH7Te06z1dmL/qyg3IL5k4bsTM97LcWyda1X/I+JYyj0ZF2YxH0K5jdLU90EcW86L0hpVRhPpjKr/Y/IxMaD7p4HvZ9uNhJ8F3JyZvz4kL620aOca1Ze7jHtcmIE/xb5Ng9mIeARl4dSnURZkfVeWG4Tfn3K/yAdNmc7CyekzKVcGhp6cjiqfiHgx5WrEgyljXBfcnXLXh+cMysuuGHAtiIhnZOafNk5z5un1I/5ns4ao5cGvhYh4OaWBXwhEfooypuAPpti3xeDwhbReSTnw3Y1yRnwx8KkceP/MVg3RGFFu0LzDnpLM/FJERK5S4zAxW/jKzHxUXTrgimkOFB3ychXtgr+9KPfMhHI3ge80y+gqa1X/G+Xlosz8kZW27WDfZm1Ca7PWlxZBQetgNiIuony2H8rMf170t+fm9ovorpTWzCenY0XEPSiXIV8LnDrxp9tz+rUXtxl6DXK9Pmg4mLphngYNVqThuBHquAbKTNaZbxuzKO1ZxsddA+w78XzfafND28HhV1DOsF4F/Ciw94yfwUWUW6Tss8Tfnjvis516MCllZtivUG6UO7l9T+CJlHvUPX9EXobW298Bfp1y26MnAx8GTluLOte5/n9/gzQGDRpuWEZN6v/YfNR9bmDiPo6U29jcMOW+zdqEZf7HlatZXyiTvQ6hXKp90MRj/xn+59yMJaOs+v8m4G+ANwOPrtvvD3xpNcuHspTQXR6D01mLD3IeHzMWwkbK9eU3UsadnAf8A2W9p6Ma5GnQYMUxDdHEPt0OfjN+BtdONu61cZzqHmM0HBxe97k75br9acAXgIvX6DMZNZi0foYvoVyi+ipwPeVSxpcoZ6WPHJm/ofV2N0ov5geBDwEvWsP61jP4Gzqrb/Sg4VZlVPdpXv9nzMexlPvqXVgfNwNPnXLfqyZ+H90m9HzMUF9GBwUtjiF1v431u7zQtnwR+OLANLqcnM5YFtdSTv6vrXX/DuC6wemsdaWalwdw5gz7dD9bGpifmRuiiTSaHfxoM/PsVykB7Kvr4yrKOJZp9r1iqd+Xej5FWodTpuV/gDLm6RPAa2Z4Py0aomZTrinTpA8ckw6lZ+zw+thjhv1fs+j5BuC9a1HnWtV/2szq6zK1fsa8tKr/o+rKRDp7AUfUx5ClfJq1CXWfJrPXGtWX0UFBi2NITediyqSXa+p38tU0OllYi/JZIo1HA28fut8uPYZrrIi4KjMfWX/fmpn/bqm/rZBG68GKo8aNRMRrMvN/TDzfALwnM589MJ1Rg48j4tDMvKn+/mi2v43HlVOm0WxweER8lHLG9Sngspz9liQXUy7LvImy3s4vUMZSvmpgOqMHk7YQET9KuQR5M+VzfQBwYmZeNCCNsyhTtV9bZyV9kNLj/OqBeRk94L1h/X8Npc4+iBGzWseUc+PJNKPrf4u6MpHWD1Muo9050z4z3zPFfq0njMw8UH3RPk3qy6I0Hw38Umb+0sD9Ro89jG13Yblz/GNEfCoH3N2j1v3XUhYu3Xthe055G6maRpPymTbtFffZFQOuVgMnJz/wxR/+tIXRYbDiTA3RxP5n0ebgdxUjBh9Hm9smNR0cXj+Ph9ans94zcHRDNJHWmg0mncjD5cDPZ+aN9flDgfdn5pED0gjgvZQz8ycA52Xmm2bIy1WMHPDeqv5PpDd6Vuus5dyhbRlV/1vUlbrfH1GCpavY9v3OnOJ2La3ahNaz1ybSbTILeiK94UHByGNITePTlGPqhyh3Fvi/wOsy82ED0pj55LT57MLt7ySzG6WH696Z+dRB6eyiAdfFwHso6279J+AU4M8pFeS3M/MxO957u3Ra9qDMPPNm4vUzN0QTabQ6+I2aeRYRVwL/C/hFyhduOznFbZMi4kLKzWg/kplfnti+J+Vs8kTKqsNnTZHW4yl15mZGnJ03aojWfKbjRF7ucrY47RlkPQNfsAfwdsq4snfB8BsIt5jt2LD+j57V16qcG7Uto+v/mLqyaJ8bgMOmPVFatO+FNGgTWs9ea1RfRgcFLY4hNZ2jKOPB7gn8FmVg/+9k5mcHpDHzyWmH8pkM8u6gfA/+NIfejH4XDbhGXwqsr23Wg1Ibkafl9gvf/UVm/vtp8jKRxqwNUeuD3+8A3wSeR5kR9xLg+sz871Pu/zDKWf0plEUwt5OZvzlFGntTLsc8mzL485uUrukNwF8Bb87Mq6bMT6uz8xYNUbMp12NFxJmUy1YL//PZlIVCV7wPWoy8gfAS6c1c5zrU/ysoDfNHgU8Cnx3cODcq50ZtS4uezJnryqJ0Pgi8bEgwMrFvszahpvfApbZPBnNTptOivowOCsYcQ5ZJczfgbpm5eJHllfZrcXLapHwm0tuv7D54IeSy/y4acI2+FFhfeyHtelCWWvjulzLzY9PkpaYxpiFqffDbDXgh8BTKGfHHMvMdM+Trx3NiJf9ZRcQewH2Af87Mb86wf5Oz80X7z9QQzZMo4z1OZmKMHfCWXIM1p8bUudb1v6Z5d8rn8jjgZ4GvZ+bjhqYzVqO2ZXT9b1VXalk9kjKm7c59c/h411FtQk3jWkoQGZTA7VDK5daHz5BWk/oyJigYcwxZlM77gF+mdEhcTjmxfGNm/u6ANFqcnDYpn4jYBLybckkS4FvAC3LgKvy7asDV5FJgh7OlsQPemzRELUSjwceL0pz1tkmjNTw7b9EQjR5MOm8i4mnAw9n+/bxmYBrN69ysIuJwytn54yl3tPgK5RLR/1h2x+3TaFbODdqWJvW/hdg2Nm07mfnJ1c7LYjH7QPUW9WV0UNAwmL0qMx8Z5dZUR1JugXP5rCeorU5OR5TPNcDJmfmp+vxxlJOFQe9nl7yXImVK8rL3JJvmUmDtqn0L8JYWZ0uUinkIpVyOiIihgxVfPeP/3U6Lgx/wwIh4RS4afDwyaweN3H+MF1POzl/GxNn5DOkclpnfrg3RX1AbImDqgIvSqC4MJn0CdTDpDHkZbeIMctK3KPdP++3M/MYUabyNcg/TJwDvBH6G0uAP1aTONar/r6fUkdOZfVZry3Ie27aMrv8t6grMR2C1I1nG2B01w64t6suZwEsWBQXvpiwgOq1Xz/B/l7JHPSYeD/xhZv5bRAzq3Vnq5DQiBp2cLjaifG5f+FxrOhdHxPAexF20h+tCGl0KbJinJoMVG+RjyYNfZr5wYDpNBh8vSnPVb5vUWkRcRzmDfB+lIfpkRFydmUcMSKPZTMex6rip71LeD5QbEgflQPq4zPyJKdK4JjMfMfHzbsCfZeZTBuZldJ1rVf9rWqNn9bUo5zlqW0bVlYi4OMvN329n+8AtKO9nvw7ZXlY0mr1W0xpbXz6dmcestG01RMTLKCeTV1MmfTwQ+OMhdbdFL1mr8omIN1HahYUbr/8c8PeUOGLqMZ67ag/XsZRLge+PMoD0m2x/KfBNQy4FNrKJ2Qe8t2yIfnji4PebEfEGtt3HcJq8TI5/+322DT7+ZEQ8etqKuZS1CLZ2cFZ+pxm6yN9OGcx6NXBRRDyIMtV/iH+pXexfiIiXUgaT3ndgGq0cs6hBv3ahkY+IaadeLwwI/6coM/C+QblEP5XGdW5U/Z/I011m9UXEiTlsVmurch7TtrSs/2PryvPq/7z7Si9cRZN5WRj0Pvj+vI3qy6UR8Xa2DwouXPh+LPc9aB3MZubplN66hfS/TDmJGWJ0LxmNyodykgylx3nSD1M+r6nGeO6SAVeHS4EtfI6yVs4sgxVbNkSjDn7AGxY9/3vKGJQ3MKBixvzcZLbpmLFGDdEplLOtl1EGkz6R0iu7Fu4WEY/JzEsAIuJoytR2KA3cNM6NiHtSLqteQakn7xyQhyZ1rhpb/xe8EXhKLprVRzlTn9YptCnnMW1Ly/o/tq58EBi1Nl9rWWdLx8jZa7SpL4+sP2cJCroFs7Ft7O207cGC0SenrconM4e20UvaJS8pzqMxgxWjwSKhE2n9BvAHlNsyvJl68MvM3xiT7gz5aLJW2jyLBpMAWg0mHfH/j6KMHbkb5Wz425SZgtdTliI4e4o09so6iDvK4O69gX/JtZnp2KT+R+NZrWPKeUzb0tLYuhIN1uZrLVrNXuswC3rg/292DFki7SuzLkQ8Mp0ANmTm1IFbq/JZlObM7bYB15yIETNvWjZELQ9+MWLwcTRaK22sHXWxL/wcM25k1oYoGsx0bC3KQoMxSy9xLH37jcErZNf9Rg14b1X/o8GsvlblPLJtaV7/Z60r0WBtvtai0ey1FvVlUXqDgoKewWw0GHs7a5DTqnwWpTlzALlLXlKcR9M0fss4gdIQ7c7216xn8RnKwELqQeY7URblG3p7iLEzz7438fvis/rvsUo6jxeZddZmi5mOTWXmtyLiXAZcgoqI76fMPN0nIh7Fthl4+1HqziAN6hw0qv+0mdXapJzHtC096v8sdaXudyPw+trzM3ptvkaazF6j3SzoBUNndLc8hmyn0djbWWeotyqfSTPPtjfgWmMtBiu2aIhaH/wYP/j4B+rZSQAPqb9Tn6/JelMRcQTlkiaUG8tes9zrVzKiIWoxmLSHoY3iU4HnAwdTxlst1LlvA4Pu81fNXOda1/8arL2xPmY1qpxbD4RuXP9nXuJlso1rcVl+pJkHqk9qVF8mDQoKWgWzHcfezhrkNCmfSWMCSAOutddssOLIhqj1wW/s4OMma6W1EhEvp9xUduEA/t6IOCMz/2DK/Vs2RC1mOvYwtJHfDGyOiGdk5iwzhxYbU+ea1P9oO6tvbDk3a1vG1v8ljF2Tb8Fars0HI2evNa4vk/vNFBQ0CGbfzbaxt5dQLv/+FKWt+0NgprG3I4KcR9afs5ZP2wAyM32s4YOyrgjABY3TvXLG/Z7R6P//BuWWDM8A/h9lhtRvDdj/Qsr98B64aPue9UuyGXj+KpbTNcC+E8/3Ba4ZsP/FwEnAf6FM738mZXzQk4FLRuYtKOM9VuWz6Pw5nzti31F1rqYxqv4DD1rusZrl3LJtGVv/O9aXM9c6D2tdX4CNwFmUgOBg4DzgHyiB+lEj8nblDPtcNfH71h39bS3ez4yfQdN220Hza6zXYMW1HKhY9x01+Dga3zZprHomelTWG8HW/F2WdUHKKfa/KjtMAlirSyq9Lh2MGZDacsJHTWOtL1fdaZa8NJ5MM3P9X6YXZ+HS5qrMxOttDb+LXWZ0z3IMiQb3Ke74fmb5DjVtt72kuPa6DFYcG2xVY7rrRw0+zvlbK+3dwCUR8eH6/HjgXQP27zUJYK0uqXS5dMC4S02tBrwvGPzZdpzVOks5t2xbxtT/42gwPKDj+KBW1qq+3C0zz6jp/XJmfrBuPz8ixtwGZ5ZjSIuxt13eD7N9h5q22wZcayzbDHifm4GKHQbfk+UWF6PuXj+riDg0M2/KzDdGuSXU4yjv6Rcyc8jn02sSQKuxMEPNTSPfo85Vgz/b7DerdZa8tGhbWtT/M1nmVmoR8RrgE5TLSMvpFeS3slb1ZXRQ0PAY0mLsba+T01nayqbttpcU59DQrs9eXbCziIgTKYOPNwGXsf3g482ZOfg2KWspGi0IGBEPZpmGKDO/tJqTAMZqdOmgSSM/r3Wu9azWFmZoW0bX/1bDA3pdlp8Xs9aXiPgnYCs1KKi/U58/ODP3nSKNJseQaHCf4hbvp5XW7bYB1xwaOo6lRUPUupes4cyzNdVqHEyjhmhuLqnMUyM/kd7Mda5D/V88q++ngKlm9fUc8zRD29J0jOmY4QEtgvxW5qy+jA4KWgWzLYLrRu+nyXeoRbs9yUuK82lo12eLLtim3fWTB755Gnw8g1bjYFrcMH2eLqm0uHTQ9LLkyDrX+rN9IfCYzPzHmp/XU8aYTbOMQpMxTzswtG1pOsZ05PCAeVqbb57qS4tLtk0u42Wbsbct3k+r71CLdnvb/7SHa+fXqLehW3f90LPqeRQRPz7rOJgl0pqpIZqnSyqNeuy69VisRS/xovTGzOq7kIZn1S20rP8j8jA3l+XnrL606FWap8t4Ld7PhTT+Do3pnV1gD9caa9Q1Pc8DFWHtBnY3kw1Xtx5xlj8XtzuqWpz59eyxWIte4kljZvU1OatueWmyZf0fodXg+xbmpr406lWam4WmG72fpj1TNV+jJ2/Zw7XGWoxjWW8DFefdWvXYzWsZjeixm6ceiyafbdRZffX3R7NtVt9FOWxW60J6Y8Y8dfl817D+z83afPNaX2Y1j72qrbTomWqWFwOutdWia3peBirWdOZmYHcv0WBR2Rn/79wEKC20auRb9OQ0rP9NZrW20Osgulb1f1Ee1vQgut7qyzwFs+uZAdcaaz2OZURvw4W0OfjNzRIV6816Owtt1ci3OPg1rP9d7hwxCw+i/azH+jKRp7npEVpvDLjW2LxcJmp48Jubgd0tzFOP3Xo+gI68dHYh4y+pt6r/D6OMvzkFeNviv2fmb07znlobcSI2N/V/nqz3+qI+DLjW2DxeJhp58JubtXJamNceO89Ct2kdiLb4bGMOZvW1MK/1f55YXzQtA641tg4vE81Fj10r663Hbr2bx0A0duJ16Kz/q29nri9anstCrL3m01fX2NxML25knpZi0ApyDe+7uYy1usF4C9b/1bcz1xctwx6uOTKPZ+dD2WMnbW8eZvXNyvq/+nbm+qLlGXCpqfU2sHsex9hJq8X6L7VjwKVu7LHTrma9zeqz/vfVYg057TwMuKRlrLceO/W13mb1Wf/7sgdx12LAJU1pPfTYqa/1PKvP+t+ePYi7FmcpSlOa0xlwmi/rdlaf9b+L9TZLXcuwh0uSGnFWn2ZlD+L6Z8AlSY04JkfSjuy21hmQpHXkTOAnKTPMvrTwoFyKe0hEbKaMy5G0i7GHS5IacVafpB0x4JKkDhyTI2mSAZckSVJnjuGSJEnqzIBLkiSpMwMuSbuUiDg2Im6MiK0Rcepa50fSrsExXJJ2GRGxAfgb4MnALcBlwLMy8/o1zZikdc8eLkm7kqOBrZn5xcz8V+ADwHFrnCdJuwADLkm7koOAr0w8v6Vuk6SuDLgk7UpiiW2Oq5DUnQGXpF3JLcADJp4fDHx1jfIiaRdiwCVpV3IZsDEiDo2IPYETgHPWOE+SdgG7r3UGJGm1ZOYdEfFS4GOU+xuemZnXrXG2JO0CXBZCkiSpMy8pSpIkdWbAJUmS1JkBlyRJUmcGXJIkSZ0ZcEmSJHVmwCVJktSZAZckSVJn/z+rFUSJeRUBoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_path = \"./Dataset/dataset_seq_in.txt\"\n",
    "\n",
    "with open(in_path, encoding='utf-8') as f:\n",
    "    seq_in = [line.rstrip().split() for line in f if line != '\\n' ]\n",
    "\n",
    "\n",
    "out_path = \"./Dataset/dataset_seq_out.txt\"\n",
    "\n",
    "with open(out_path, encoding='utf-8') as f:\n",
    "    seq_out = [line.rstrip().split() for line in f if line != '\\n']\n",
    "\n",
    "\n",
    "label_df = pd.DataFrame( x for seq in seq_out for x in seq)\n",
    "# display(label_df.head(5))\n",
    "label_df.value_counts(subset=None, dropna = True).plot(kind = 'bar', figsize = (10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent_label_lst: \n",
      " ['O', 'B-take', 'B-find', 'B-follow', 'B-say', 'B-go', 'B-put'] \n",
      "\n",
      "slot_label_lst: \n",
      " ['B-find.dest', 'B-find.per', 'B-take.pro', 'B-take.dest', 'B-follow.pro', 'B-say.pro', 'B-say.dest', 'B-go.dest', 'B-take.obj', 'I-take.dest', 'B-take.per', 'B-follow.dest', 'I-say.dest', 'I-find.dest', 'B-follow.per', 'I-go.dest', 'B-find.obj', 'B-put.dest', 'I-follow.dest', 'B-put.pro', 'B-find.pro', 'B-say.obj', 'B-say.per', 'I-put.dest', 'B-put.obj']\n"
     ]
    }
   ],
   "source": [
    "val_coun = label_df.value_counts(subset=None, dropna = True)\n",
    "\n",
    "intent_label_lst = [label[0] for label in val_coun.index if '.' not in label[0]]\n",
    "slot_label_lst = [label[0] for label in val_coun.index if '.' in label[0]]\n",
    "\n",
    "print('intent_label_lst: \\n',intent_label_lst,'\\n')\n",
    "print('slot_label_lst: \\n',slot_label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train \n",
      "\n",
      "min length:  2\n",
      "max length:  19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_label</th>\n",
       "      <th>words</th>\n",
       "      <th>words_label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>could you please give me the apple from the si...</td>\n",
       "      <td>O O O B-take B-take.pro O B-take.obj O O B-tak...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B-find, B-follow, B-take]</td>\n",
       "      <td>meet francis at the desk follow him and escort...</td>\n",
       "      <td>B-find B-find.per O O B-find.dest B-follow B-f...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B-say]</td>\n",
       "      <td>say the time to the person pointing to the lef...</td>\n",
       "      <td>B-say O O O O O O O O O O O B-say.dest</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>take mary from the dishwasher to the couch</td>\n",
       "      <td>B-take B-take.per O O B-take.dest O O O</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B-say]</td>\n",
       "      <td>tell me the gender of the person at the dining...</td>\n",
       "      <td>B-say B-say.pro O O O O O O O B-say.dest I-say...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>[B-find, B-follow, B-take]</td>\n",
       "      <td>meet john at the bed follow him and take him back</td>\n",
       "      <td>B-find B-find.per O O B-find.dest B-follow B-f...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>take the chocolate drink to the bookcase</td>\n",
       "      <td>B-take O O B-take.obj O O B-take.dest</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>[B-say]</td>\n",
       "      <td>tell me how many cutlery there are on the dini...</td>\n",
       "      <td>B-say B-say.pro O O B-say.obj O O O O B-say.de...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>[]</td>\n",
       "      <td>the living room</td>\n",
       "      <td>O O O</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>[B-say]</td>\n",
       "      <td>robot please tell me how many orange there are...</td>\n",
       "      <td>O O B-say B-say.pro O O B-say.obj O O O O B-sa...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   intent_label  \\\n",
       "0                      [B-take]   \n",
       "1    [B-find, B-follow, B-take]   \n",
       "2                       [B-say]   \n",
       "3                      [B-take]   \n",
       "4                       [B-say]   \n",
       "..                          ...   \n",
       "745  [B-find, B-follow, B-take]   \n",
       "746                    [B-take]   \n",
       "747                     [B-say]   \n",
       "748                          []   \n",
       "749                     [B-say]   \n",
       "\n",
       "                                                 words  \\\n",
       "0    could you please give me the apple from the si...   \n",
       "1    meet francis at the desk follow him and escort...   \n",
       "2    say the time to the person pointing to the lef...   \n",
       "3           take mary from the dishwasher to the couch   \n",
       "4    tell me the gender of the person at the dining...   \n",
       "..                                                 ...   \n",
       "745  meet john at the bed follow him and take him back   \n",
       "746           take the chocolate drink to the bookcase   \n",
       "747  tell me how many cutlery there are on the dini...   \n",
       "748                                    the living room   \n",
       "749  robot please tell me how many orange there are...   \n",
       "\n",
       "                                           words_label  length  \n",
       "0    O O O B-take B-take.pro O B-take.obj O O B-tak...      11  \n",
       "1    B-find B-find.per O O B-find.dest B-follow B-f...      11  \n",
       "2               B-say O O O O O O O O O O O B-say.dest      13  \n",
       "3              B-take B-take.per O O B-take.dest O O O       8  \n",
       "4    B-say B-say.pro O O O O O O O B-say.dest I-say...      11  \n",
       "..                                                 ...     ...  \n",
       "745  B-find B-find.per O O B-find.dest B-follow B-f...      11  \n",
       "746              B-take O O B-take.obj O O B-take.dest       7  \n",
       "747  B-say B-say.pro O O B-say.obj O O O O B-say.de...      11  \n",
       "748                                              O O O       3  \n",
       "749  O O B-say B-say.pro O O B-say.obj O O O O B-sa...      12  \n",
       "\n",
       "[750 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "val \n",
      "\n",
      "min length:  2\n",
      "max length:  18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_label</th>\n",
       "      <th>words</th>\n",
       "      <th>words_label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>could you please the living room</td>\n",
       "      <td>O O O O O O</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B-find, B-say]</td>\n",
       "      <td>contact charlie at the dining table and ask hi...</td>\n",
       "      <td>B-find B-find.per O O B-find.dest I-find.dest ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>please deliver drinks to the person raising th...</td>\n",
       "      <td>O B-take O O O O O O O O O O B-take.dest</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B-say]</td>\n",
       "      <td>answer a question to the person raising their ...</td>\n",
       "      <td>B-say O O O O O O O O O O O B-say.dest I-say.dest</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B-follow]</td>\n",
       "      <td>follow robert from the entrance to the corridor</td>\n",
       "      <td>B-follow B-follow.per O O B-follow.dest O O O</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[B-take, B-find]</td>\n",
       "      <td>take francis to the bed you will find her at t...</td>\n",
       "      <td>B-take B-take.per O O B-take.dest B-take.pro O...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>bring the pringles to the storage table</td>\n",
       "      <td>B-take O B-take.obj O O B-take.dest I-take.dest</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[B-find, B-say]</td>\n",
       "      <td>please find charlie at the rear entrance and i...</td>\n",
       "      <td>O B-find B-find.per O O O B-find.dest O B-say ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[B-follow]</td>\n",
       "      <td>could you please follow skyler from the bookca...</td>\n",
       "      <td>O O O B-follow B-follow.per O O B-follow.dest ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>take my trolley to the cab</td>\n",
       "      <td>B-take O O O O O</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[B-find, B-say]</td>\n",
       "      <td>contact charlie at the end table and ask her t...</td>\n",
       "      <td>B-find B-find.per O O O B-find.dest O B-say B-...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[B-say]</td>\n",
       "      <td>robot please tell me how many people in the ki...</td>\n",
       "      <td>O O B-say B-say.pro O O O O O B-say.dest O O</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>give me the right most object from the side table</td>\n",
       "      <td>B-take B-take.pro O O O O O O B-take.dest I-ta...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[B-find, B-follow, B-take]</td>\n",
       "      <td>meet robert at the entrance follow him and lea...</td>\n",
       "      <td>B-find B-find.per O O B-find.dest B-follow B-f...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>please bring me the cutlery</td>\n",
       "      <td>O B-take B-take.pro O B-take.obj</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[B-follow]</td>\n",
       "      <td>follow linda</td>\n",
       "      <td>B-follow O</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>could you serve drinks to everyone in the corr...</td>\n",
       "      <td>O O B-take O O O O O B-take.dest</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[B-take, B-find]</td>\n",
       "      <td>lead charlie to the couch you will find her at...</td>\n",
       "      <td>B-take B-take.per O O B-take.dest B-take.pro O...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[B-find, B-follow]</td>\n",
       "      <td>meet skyler at the sink and follow him to the ...</td>\n",
       "      <td>B-find B-find.per O O B-find.dest O B-follow B...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[B-go, B-find, B-follow]</td>\n",
       "      <td>go to the bookcase meet alex and follow her</td>\n",
       "      <td>B-go O O B-go.dest B-find B-find.per O B-follo...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>take the grape juice to the bookcase</td>\n",
       "      <td>B-take O O B-take.obj O O B-take.dest</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[B-go, B-find, B-take]</td>\n",
       "      <td>navigate to the dining table meet charlie and ...</td>\n",
       "      <td>B-go O O B-go.dest I-go.dest B-find B-find.per...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>please give me the lightest object from the di...</td>\n",
       "      <td>O B-take B-take.pro O O O O O B-take.dest I-ta...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[B-go, B-find, B-take]</td>\n",
       "      <td>navigate to the exit meet jennifer and accompa...</td>\n",
       "      <td>B-go O O O B-find B-find.per O B-take B-take.p...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[B-find]</td>\n",
       "      <td>please find the fruits in the dining room</td>\n",
       "      <td>O B-find O O O O B-find.dest I-find.dest</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[B-say]</td>\n",
       "      <td>tell me which are the three biggest fruits on ...</td>\n",
       "      <td>B-say B-say.pro O O O O O O O O B-say.dest</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>please bring fruits to the person raising thei...</td>\n",
       "      <td>O B-take O O O O O O O O O O B-take.dest</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[B-find, B-follow, B-take]</td>\n",
       "      <td>meet robin at the entrance follow her and guid...</td>\n",
       "      <td>B-find B-find.per O O B-find.dest B-follow B-f...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[B-find, B-take]</td>\n",
       "      <td>robot please meet michael and escort him</td>\n",
       "      <td>O O B-find B-find.per O B-take B-take.pro</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[B-go, B-find, B-take]</td>\n",
       "      <td>could you please navigate to the entrance meet...</td>\n",
       "      <td>O O O B-go O O B-go.dest B-find O O B-take B-t...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[B-find, B-take]</td>\n",
       "      <td>could you face william at the entrance and gui...</td>\n",
       "      <td>O O B-find B-find.per O O B-find.dest O B-take...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[]</td>\n",
       "      <td>the living room</td>\n",
       "      <td>O O O</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>please lead jennifer from the bed to the bookcase</td>\n",
       "      <td>O B-take B-take.per O O O O O B-take.dest</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[B-say]</td>\n",
       "      <td>robot please tell me the pose of the person at...</td>\n",
       "      <td>O O B-say B-say.pro O O O O O O O O B-say.dest</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[B-find, B-take]</td>\n",
       "      <td>could you please meet james at the sink and ac...</td>\n",
       "      <td>O O O B-find B-find.per O O B-find.dest O B-ta...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[B-find, B-follow, B-take]</td>\n",
       "      <td>meet alex at the bookcase follow him and accom...</td>\n",
       "      <td>B-find B-find.per O O B-find.dest B-follow B-f...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>could you please bring the coke to the storage...</td>\n",
       "      <td>O O O B-take O B-take.obj O O B-take.dest I-ta...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[B-find]</td>\n",
       "      <td>please look for the fruits in the kitchen</td>\n",
       "      <td>O B-find O O O O O B-find.dest</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[B-go, B-find, B-follow]</td>\n",
       "      <td>navigate to the dishwasher meet john and follo...</td>\n",
       "      <td>B-go O O B-go.dest B-find B-find.per O B-follo...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>give me the paprika from the storage table</td>\n",
       "      <td>B-take B-take.pro O B-take.obj O O B-take.dest...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[B-go, B-find, B-take]</td>\n",
       "      <td>please go to the exit meet linda and escort he...</td>\n",
       "      <td>O B-go O O O B-find O O B-take B-take.pro O O ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[B-find, B-follow, B-go]</td>\n",
       "      <td>meet william at the dining table follow him an...</td>\n",
       "      <td>B-find B-find.per O O B-find.dest I-find.dest ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>deliver drinks to everyone in the corridor</td>\n",
       "      <td>B-take O O O O O B-take.dest</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>bring cleaning stuff to the person raising the...</td>\n",
       "      <td>B-take O O O O O O O O O O O B-take.dest</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[B-take, B-find]</td>\n",
       "      <td>guide robert to the exit you may find him at t...</td>\n",
       "      <td>B-take B-take.per O O O B-take.pro O B-find B-...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>bring me the object under the apple from the sink</td>\n",
       "      <td>B-take B-take.pro O O O O B-take.obj O O B-tak...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>take my baggage to the uber</td>\n",
       "      <td>B-take O O O O O</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[B-take, B-find]</td>\n",
       "      <td>escort jennifer to the dishwasher you can find...</td>\n",
       "      <td>B-take B-take.per O O B-take.dest B-take.pro B...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[B-find, B-take]</td>\n",
       "      <td>robot please meet charlie and escort him</td>\n",
       "      <td>O O B-find B-find.per O B-take B-take.pro</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[B-go, B-find, B-follow]</td>\n",
       "      <td>robot please go to the bookcase meet patricia ...</td>\n",
       "      <td>O O B-go O O B-go.dest B-find B-find.per O B-f...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  intent_label  \\\n",
       "0                           []   \n",
       "1              [B-find, B-say]   \n",
       "2                     [B-take]   \n",
       "3                      [B-say]   \n",
       "4                   [B-follow]   \n",
       "5             [B-take, B-find]   \n",
       "6                     [B-take]   \n",
       "7              [B-find, B-say]   \n",
       "8                   [B-follow]   \n",
       "9                     [B-take]   \n",
       "10             [B-find, B-say]   \n",
       "11                     [B-say]   \n",
       "12                    [B-take]   \n",
       "13  [B-find, B-follow, B-take]   \n",
       "14                    [B-take]   \n",
       "15                  [B-follow]   \n",
       "16                    [B-take]   \n",
       "17            [B-take, B-find]   \n",
       "18          [B-find, B-follow]   \n",
       "19    [B-go, B-find, B-follow]   \n",
       "20                    [B-take]   \n",
       "21      [B-go, B-find, B-take]   \n",
       "22                    [B-take]   \n",
       "23      [B-go, B-find, B-take]   \n",
       "24                    [B-find]   \n",
       "25                     [B-say]   \n",
       "26                    [B-take]   \n",
       "27  [B-find, B-follow, B-take]   \n",
       "28            [B-find, B-take]   \n",
       "29      [B-go, B-find, B-take]   \n",
       "30            [B-find, B-take]   \n",
       "31                          []   \n",
       "32                    [B-take]   \n",
       "33                     [B-say]   \n",
       "34            [B-find, B-take]   \n",
       "35  [B-find, B-follow, B-take]   \n",
       "36                    [B-take]   \n",
       "37                    [B-find]   \n",
       "38    [B-go, B-find, B-follow]   \n",
       "39                    [B-take]   \n",
       "40      [B-go, B-find, B-take]   \n",
       "41    [B-find, B-follow, B-go]   \n",
       "42                    [B-take]   \n",
       "43                    [B-take]   \n",
       "44            [B-take, B-find]   \n",
       "45                    [B-take]   \n",
       "46                    [B-take]   \n",
       "47            [B-take, B-find]   \n",
       "48            [B-find, B-take]   \n",
       "49    [B-go, B-find, B-follow]   \n",
       "\n",
       "                                                words  \\\n",
       "0                    could you please the living room   \n",
       "1   contact charlie at the dining table and ask hi...   \n",
       "2   please deliver drinks to the person raising th...   \n",
       "3   answer a question to the person raising their ...   \n",
       "4     follow robert from the entrance to the corridor   \n",
       "5   take francis to the bed you will find her at t...   \n",
       "6             bring the pringles to the storage table   \n",
       "7   please find charlie at the rear entrance and i...   \n",
       "8   could you please follow skyler from the bookca...   \n",
       "9                          take my trolley to the cab   \n",
       "10  contact charlie at the end table and ask her t...   \n",
       "11  robot please tell me how many people in the ki...   \n",
       "12  give me the right most object from the side table   \n",
       "13  meet robert at the entrance follow him and lea...   \n",
       "14                        please bring me the cutlery   \n",
       "15                                       follow linda   \n",
       "16  could you serve drinks to everyone in the corr...   \n",
       "17  lead charlie to the couch you will find her at...   \n",
       "18  meet skyler at the sink and follow him to the ...   \n",
       "19        go to the bookcase meet alex and follow her   \n",
       "20               take the grape juice to the bookcase   \n",
       "21  navigate to the dining table meet charlie and ...   \n",
       "22  please give me the lightest object from the di...   \n",
       "23  navigate to the exit meet jennifer and accompa...   \n",
       "24          please find the fruits in the dining room   \n",
       "25  tell me which are the three biggest fruits on ...   \n",
       "26  please bring fruits to the person raising thei...   \n",
       "27  meet robin at the entrance follow her and guid...   \n",
       "28           robot please meet michael and escort him   \n",
       "29  could you please navigate to the entrance meet...   \n",
       "30  could you face william at the entrance and gui...   \n",
       "31                                    the living room   \n",
       "32  please lead jennifer from the bed to the bookcase   \n",
       "33  robot please tell me the pose of the person at...   \n",
       "34  could you please meet james at the sink and ac...   \n",
       "35  meet alex at the bookcase follow him and accom...   \n",
       "36  could you please bring the coke to the storage...   \n",
       "37          please look for the fruits in the kitchen   \n",
       "38  navigate to the dishwasher meet john and follo...   \n",
       "39         give me the paprika from the storage table   \n",
       "40  please go to the exit meet linda and escort he...   \n",
       "41  meet william at the dining table follow him an...   \n",
       "42         deliver drinks to everyone in the corridor   \n",
       "43  bring cleaning stuff to the person raising the...   \n",
       "44  guide robert to the exit you may find him at t...   \n",
       "45  bring me the object under the apple from the sink   \n",
       "46                        take my baggage to the uber   \n",
       "47  escort jennifer to the dishwasher you can find...   \n",
       "48           robot please meet charlie and escort him   \n",
       "49  robot please go to the bookcase meet patricia ...   \n",
       "\n",
       "                                          words_label  length  \n",
       "0                                         O O O O O O       6  \n",
       "1   B-find B-find.per O O B-find.dest I-find.dest ...      11  \n",
       "2            O B-take O O O O O O O O O O B-take.dest      13  \n",
       "3   B-say O O O O O O O O O O O B-say.dest I-say.dest      14  \n",
       "4       B-follow B-follow.per O O B-follow.dest O O O       8  \n",
       "5   B-take B-take.per O O B-take.dest B-take.pro O...      12  \n",
       "6     B-take O B-take.obj O O B-take.dest I-take.dest       7  \n",
       "7   O B-find B-find.per O O O B-find.dest O B-say ...      18  \n",
       "8   O O O B-follow B-follow.per O O B-follow.dest ...      11  \n",
       "9                                    B-take O O O O O       6  \n",
       "10  B-find B-find.per O O O B-find.dest O B-say B-...      11  \n",
       "11       O O B-say B-say.pro O O O O O B-say.dest O O      12  \n",
       "12  B-take B-take.pro O O O O O O B-take.dest I-ta...      10  \n",
       "13  B-find B-find.per O O B-find.dest B-follow B-f...      11  \n",
       "14                   O B-take B-take.pro O B-take.obj       5  \n",
       "15                                         B-follow O       2  \n",
       "16                   O O B-take O O O O O B-take.dest       9  \n",
       "17  B-take B-take.per O O B-take.dest B-take.pro O...      13  \n",
       "18  B-find B-find.per O O B-find.dest O B-follow B...      11  \n",
       "19  B-go O O B-go.dest B-find B-find.per O B-follo...       9  \n",
       "20              B-take O O B-take.obj O O B-take.dest       7  \n",
       "21  B-go O O B-go.dest I-go.dest B-find B-find.per...      10  \n",
       "22  O B-take B-take.pro O O O O O B-take.dest I-ta...      10  \n",
       "23  B-go O O O B-find B-find.per O B-take B-take.p...      12  \n",
       "24           O B-find O O O O B-find.dest I-find.dest       8  \n",
       "25         B-say B-say.pro O O O O O O O O B-say.dest      11  \n",
       "26           O B-take O O O O O O O O O O B-take.dest      13  \n",
       "27  B-find B-find.per O O B-find.dest B-follow B-f...      11  \n",
       "28          O O B-find B-find.per O B-take B-take.pro       7  \n",
       "29  O O O B-go O O B-go.dest B-find O O B-take B-t...      15  \n",
       "30  O O B-find B-find.per O O B-find.dest O B-take...      13  \n",
       "31                                              O O O       3  \n",
       "32          O B-take B-take.per O O O O O B-take.dest       9  \n",
       "33     O O B-say B-say.pro O O O O O O O O B-say.dest      13  \n",
       "34  O O O B-find B-find.per O O B-find.dest O B-ta...      15  \n",
       "35  B-find B-find.per O O B-find.dest B-follow B-f...      11  \n",
       "36  O O O B-take O B-take.obj O O B-take.dest I-ta...      10  \n",
       "37                     O B-find O O O O O B-find.dest       8  \n",
       "38  B-go O O B-go.dest B-find B-find.per O B-follo...       9  \n",
       "39  B-take B-take.pro O B-take.obj O O B-take.dest...       8  \n",
       "40  O B-go O O O B-find O O B-take B-take.pro O O ...      14  \n",
       "41  B-find B-find.per O O B-find.dest I-find.dest ...      14  \n",
       "42                       B-take O O O O O B-take.dest       7  \n",
       "43           B-take O O O O O O O O O O O B-take.dest      13  \n",
       "44  B-take B-take.per O O O B-take.pro O B-find B-...      12  \n",
       "45  B-take B-take.pro O O O O B-take.obj O O B-tak...      10  \n",
       "46                                   B-take O O O O O       6  \n",
       "47  B-take B-take.per O O B-take.dest B-take.pro B...      12  \n",
       "48          O O B-find B-find.per O B-take B-take.pro       7  \n",
       "49  O O B-go O O B-go.dest B-find B-find.per O B-f...      11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "test \n",
      "\n",
      "min length:  2\n",
      "max length:  19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_label</th>\n",
       "      <th>words</th>\n",
       "      <th>words_label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>guide alex to the dishwasher</td>\n",
       "      <td>B-take B-take.per O O B-take.dest</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B-find, B-follow, B-go]</td>\n",
       "      <td>could you please meet patricia at the bed foll...</td>\n",
       "      <td>O O O B-find B-find.per O O B-find.dest B-foll...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B-find, B-take]</td>\n",
       "      <td>contact james at the couch and take him to his...</td>\n",
       "      <td>B-find B-find.per O O B-find.dest O B-take B-t...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>give drinks to all the elders in the kitchen</td>\n",
       "      <td>B-take O O O O O O O B-take.dest</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>please guide charlie to the dishwasher</td>\n",
       "      <td>O B-take B-take.per O O B-take.dest</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[B-follow]</td>\n",
       "      <td>robot please follow alex from the desk to the ...</td>\n",
       "      <td>O O B-follow B-follow.per O O O O O B-follow.dest</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[B-take, B-take]</td>\n",
       "      <td>could you get the cup from the counter and put...</td>\n",
       "      <td>O O B-take O B-take.obj O O B-take.dest O B-ta...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[B-go, B-find, B-say]</td>\n",
       "      <td>robot please go to the bedroom find a person l...</td>\n",
       "      <td>O O B-go O O B-go.dest B-find O O O O O B-say ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[B-take]</td>\n",
       "      <td>could you please take out the junk</td>\n",
       "      <td>O O O B-take O O O</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[B-find, B-follow]</td>\n",
       "      <td>could you please meet jennifer at the desk and...</td>\n",
       "      <td>O O O B-find B-find.per O O B-find.dest O B-fo...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 intent_label  \\\n",
       "0                    [B-take]   \n",
       "1    [B-find, B-follow, B-go]   \n",
       "2            [B-find, B-take]   \n",
       "3                    [B-take]   \n",
       "4                    [B-take]   \n",
       "..                        ...   \n",
       "195                [B-follow]   \n",
       "196          [B-take, B-take]   \n",
       "197     [B-go, B-find, B-say]   \n",
       "198                  [B-take]   \n",
       "199        [B-find, B-follow]   \n",
       "\n",
       "                                                 words  \\\n",
       "0                         guide alex to the dishwasher   \n",
       "1    could you please meet patricia at the bed foll...   \n",
       "2    contact james at the couch and take him to his...   \n",
       "3         give drinks to all the elders in the kitchen   \n",
       "4               please guide charlie to the dishwasher   \n",
       "..                                                 ...   \n",
       "195  robot please follow alex from the desk to the ...   \n",
       "196  could you get the cup from the counter and put...   \n",
       "197  robot please go to the bedroom find a person l...   \n",
       "198                 could you please take out the junk   \n",
       "199  could you please meet jennifer at the desk and...   \n",
       "\n",
       "                                           words_label  length  \n",
       "0                    B-take B-take.per O O B-take.dest       5  \n",
       "1    O O O B-find B-find.per O O B-find.dest B-foll...      15  \n",
       "2    B-find B-find.per O O B-find.dest O B-take B-t...      11  \n",
       "3                     B-take O O O O O O O B-take.dest       9  \n",
       "4                  O B-take B-take.per O O B-take.dest       6  \n",
       "..                                                 ...     ...  \n",
       "195  O O B-follow B-follow.per O O O O O B-follow.dest      10  \n",
       "196  O O B-take O B-take.obj O O B-take.dest O B-ta...      15  \n",
       "197  O O B-go O O B-go.dest B-find O O O O O B-say ...      17  \n",
       "198                                 O O O B-take O O O       7  \n",
       "199  O O O B-find B-find.per O O B-find.dest O B-fo...      15  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def parse_seq(seq_in, seq_out):\n",
    "    intent_label_lst = [ele for ele in seq_out if ele != 'O' and '.' not in ele]\n",
    "    command = \" \".join(seq_in)\n",
    "    return {\n",
    "        'intent_label': intent_label_lst,\n",
    "        'words': command,\n",
    "        'words_label': \" \".join(seq_out),\n",
    "        'length': len(seq_in)\n",
    "    }\n",
    "\n",
    "\n",
    "def get_dataframe(seq_in,seq_out):\n",
    "    parsed = [parse_seq(seq_in[i], seq_out[i]) for i in range(len(seq_in))]\n",
    "    return pd.DataFrame([p for p in parsed if p is not None])\n",
    "\n",
    "def df_for_envs(env_names):\n",
    "    envs = env_names.copy()\n",
    "    for env,name_lst in env_names.items():\n",
    "        for name in name_lst:\n",
    "            path = f'./Dataset/{env}/{name}.txt'\n",
    "            #path = './Dataset/' + name + '.txt'\n",
    "            with open(path, encoding='utf-8') as f:\n",
    "                if 'X' in name:\n",
    "                    seq_in = [line.rstrip().split() for line in f if line != '\\n' ]\n",
    "                elif 'Y' in name:\n",
    "                    seq_out = [line.rstrip().split() for line in f if line != '\\n' ]\n",
    "                    \n",
    "        envs.update({env : get_dataframe(seq_in,seq_out)})\n",
    "    return envs\n",
    "            \n",
    "env_names = {'train':['X_train', 'Y_train'], 'val':['X_val', 'Y_val'], 'test':['X_test','Y_test']}\n",
    "envs = df_for_envs(env_names)\n",
    "\n",
    "\n",
    "for env,df in envs.items():\n",
    "    print(env,'\\n')\n",
    "    print('min length: ', min(df['length']))\n",
    "    print('max length: ', max(df['length']))\n",
    "    display(df)\n",
    "    print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could you take the tray from the end table and deliver it to william at the dining table\n",
      "['could', 'you', 'take', 'the', 'tray', 'from', 'the', 'end', 'table', 'and', 'deliver', 'it', 'to', 'william', 'at', 'the', 'dining', 'table']\n",
      "18\n",
      "[101, 2071, 2017, 2202, 1996, 11851, 2013, 1996, 2203, 2795, 1998, 8116, 2009, 2000, 2520, 2012, 1996, 7759, 2795, 102]\n",
      "20\n",
      "decode: \n",
      "[CLS] could you take the tray from the end table and deliver it to william at the dining table [SEP]\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_train = envs['train']\n",
    "df_val = envs['val']\n",
    "df_t = envs['train']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "first_sentence = df_train.iloc[600]['words']\n",
    "print(first_sentence)\n",
    "sen = tokenizer.tokenize(first_sentence)\n",
    "print(sen)\n",
    "print(len(sen))\n",
    "encode = tokenizer.encode(first_sentence)\n",
    "print(encode)\n",
    "print(len(encode))\n",
    "\n",
    "print('decode: ')\n",
    "print(tokenizer.decode(tokenizer.encode(first_sentence)))\n",
    "print('------------------------------------')\n",
    "# bert_vocab_items = list(tokenizer.vocab.items())\n",
    "# print(bert_vocab_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'])\n",
      "[100, 102, 0, 101, 103]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.special_tokens_map.values())\n",
    "print(tokenizer.convert_tokens_to_ids(special for special in tokenizer.special_tokens_map.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stevengolovkine.netlify.app/post/joint-intent-classification-slot-filling-with-transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode words\n",
    "def encode_dataset(tokenizer, text_sequences, max_length):\n",
    "    token_ids = np.zeros(shape=(len(text_sequences), max_length),\n",
    "                         dtype=np.int32)\n",
    "    for i, text_sequence in enumerate(text_sequences):\n",
    "        encoded = tokenizer.encode(text_sequence)\n",
    "        token_ids[i, 0:len(encoded)] = encoded\n",
    "    attention_masks = (token_ids != 0).astype(np.int32)\n",
    "    \n",
    "    return {'input_ids': token_ids, 'attention_masks': attention_masks}\n",
    "\n",
    "encoded_train = encode_dataset(tokenizer, df['words'], 50)\n",
    "encoded_val = encode_dataset(tokenizer, df_val['words'], 50)\n",
    "encoded_test = encode_dataset(tokenizer, df_test['words'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'find': 0, 'go': 1, 'take': 2, 'put': 3, 'follow': 4, 'say': 5}\n",
      "{'pro': 1, 'dest': 2, 'obj': 3, 'per': 4} \n",
      "\n",
      "{'B-take.dest': array([1, 2, 2]), 'B-put': array([1, 3, 0]), 'B-put.obj': array([1, 3, 3]), 'B-follow.dest': array([1, 4, 2]), 'B-say': array([1, 5, 0]), 'B-go.dest': array([1, 1, 2]), 'B-follow.per': array([1, 4, 4]), 'B-take.obj': array([1, 2, 3]), 'B-say.dest': array([1, 5, 2]), 'B-follow': array([1, 4, 0]), 'I-say.dest': array([2, 5, 2]), 'B-find.obj': array([1, 0, 3]), 'B-take.pro': array([1, 2, 1]), 'I-go.dest': array([2, 1, 2]), 'B-take.per': array([1, 2, 4]), 'B-say.per': array([1, 5, 4]), 'I-find.dest': array([2, 0, 2]), 'I-put.dest': array([2, 3, 2]), 'B-say.obj': array([1, 5, 3]), 'B-find.per': array([1, 0, 4]), 'B-put.dest': array([1, 3, 2]), 'B-find': array([1, 0, 0]), 'B-put.pro': array([1, 3, 1]), 'B-find.dest': array([1, 0, 2]), 'B-find.pro': array([1, 0, 1]), 'I-take.dest': array([2, 2, 2]), 'B-take': array([1, 2, 0]), 'B-follow.pro': array([1, 4, 1]), 'B-say.pro': array([1, 5, 1]), 'I-follow.dest': array([2, 4, 2]), 'B-go': array([1, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "# # Encodes labels\n",
    "# def get_label_map():\n",
    "#     env = 'train'\n",
    "#     intent_path = f'./Dataset/{env}/{env}_intents.txt'\n",
    "#     slot_path = f'./Dataset/{env}/{env}_slots.txt'\n",
    "    \n",
    "#     unique_intent = Path(intent_path).read_text('utf-8').strip().splitlines()#.extend(['UNK'])\n",
    "#     unique_slot = Path(slot_path).read_text('utf-8').strip().splitlines()\n",
    "        \n",
    "#     slot_type = set()\n",
    "#     for slot in unique_slot:\n",
    "#         idx = slot.find('.')\n",
    "#         category = slot[idx+1 ::]\n",
    "#         slot_type.add(category)\n",
    "#     slot_type.remove('O')\n",
    "    \n",
    "#     intent_type = set()\n",
    "#     for intent in unique_intent:\n",
    "#         idx = intent.find('-')\n",
    "#         category = intent[idx+1::]\n",
    "#         intent_type.add(category)    \n",
    "    \n",
    "    \n",
    "#     intent_map = dict((label, idx) for idx, label in enumerate(intent_type))\n",
    "#     slot_type_map = dict((label, idx+1) for idx, label in enumerate(slot_type))\n",
    "    \n",
    "#     print(intent_map)\n",
    "#     print(slot_type_map,'\\n')\n",
    "    \n",
    "#     all_labels = set(unique_intent).union(unique_slot)\n",
    "#     all_label_map = {}\n",
    "#     for L in all_labels:\n",
    "#         if L == 'O':\n",
    "#             label = np.array([0,0,0])\n",
    "#         else:\n",
    "#             if L[0] == 'B':\n",
    "#                 BIO_code = 1\n",
    "#             elif L[0] == 'I':\n",
    "#                 BIO_code = 2\n",
    "                \n",
    "#             intent_idx = L.find('-') + 1\n",
    "#             slot_idx = L.find('.') + 1\n",
    "            \n",
    "#             if slot_idx == 0:\n",
    "#                 intent = L[intent_idx::]\n",
    "#                 label = np.array([BIO_code,intent_map[intent],0])\n",
    "#             else:\n",
    "#                 intent = L[intent_idx:slot_idx-1]\n",
    "#                 slot = L[slot_idx::]\n",
    "#                 label = np.array([BIO_code,intent_map[intent],slot_type_map[slot]])\n",
    "                \n",
    "#             all_label_map.update({L:label})\n",
    "            \n",
    "#     return all_label_map\n",
    "\n",
    "    \n",
    "# all_label_map = get_label_map()\n",
    "# print(all_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-take.dest': 1, 'B-put': 2, 'O': 3, 'B-put.obj': 4, 'B-follow.dest': 5, 'B-say': 6, 'B-go.dest': 7, 'B-follow.per': 8, 'B-take.obj': 9, 'B-say.dest': 10, 'B-follow': 11, 'I-say.dest': 12, 'B-find.obj': 13, 'B-take.pro': 14, 'I-go.dest': 15, 'B-take.per': 16, 'B-say.per': 17, 'I-find.dest': 18, 'I-put.dest': 19, 'B-say.obj': 20, 'B-find.per': 21, 'B-put.dest': 22, 'B-find': 23, 'B-put.pro': 24, 'B-find.dest': 25, 'B-find.pro': 26, 'I-take.dest': 27, 'B-take': 28, 'B-follow.pro': 29, 'B-say.pro': 30, 'I-follow.dest': 31, 'B-go': 32}\n"
     ]
    }
   ],
   "source": [
    "# Encodes labels\n",
    "def get_label_map():\n",
    "    env = 'train'\n",
    "    intent_path = f'./Dataset/{env}/{env}_intents.txt'\n",
    "    slot_path = f'./Dataset/{env}/{env}_slots.txt'\n",
    "    \n",
    "    unique_intent = Path(intent_path).read_text('utf-8').strip().splitlines()#.extend(['UNK'])\n",
    "    unique_slot = Path(slot_path).read_text('utf-8').strip().splitlines()\n",
    "    \n",
    "    all_labels = set(unique_intent).union(unique_slot)\n",
    "    all_label_map = dict((label, idx+1) for idx, label in enumerate(all_labels))\n",
    "            \n",
    "    return all_label_map\n",
    "\n",
    "all_label_map = get_label_map()\n",
    "print(all_label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align the BIO labels with the BERT tokens\n",
    "\n",
    "if a specific word is too long to be represented as a single token, we expand its label for all the tokens of that word while taking care of using â€œB-â€ labels only for the first token and then use â€œI-â€ for the matching slot type for subsequent tokens of the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_token_labels(text_sequences, slot_names, tokenizer, slot_map, max_length):\n",
    "    #slot_map.update('')\n",
    "    encoded = np.zeros(shape=(len(text_sequences), max_length), dtype=np.int32)\n",
    "    for i, (text_sequence, word_labels) in enumerate(zip(text_sequences, slot_names)):\n",
    "        encoded_labels = []\n",
    "        \n",
    "        if i == 0:\n",
    "            print(i)\n",
    "            print(text_sequence,'\\n')\n",
    "            print('#word_labels:',word_labels)\n",
    "            \n",
    "        for word, word_label in zip(text_sequence.split(),word_labels.split()):\n",
    "            tokens = tokenizer.tokenize(word)\n",
    "            if i == 0:\n",
    "                print(word,',tokens',tokens,', label: ',word_label, 'code: ',slot_map[word_label])\n",
    "            encoded_labels.append(slot_map[word_label])\n",
    "            expand_label = word_label.replace(\"B-\", \"I-\")\n",
    "            if not expand_label in slot_map:\n",
    "                expand_label = word_label\n",
    "            encoded_labels.extend([slot_map[expand_label]] *\\\n",
    "                                    (len(tokens) - 1))\n",
    "        encoded[i, 1:len(encoded_labels) + 1] = encoded_labels\n",
    "        if i == 0:\n",
    "            print('encode: ',encoded,'\\n')\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "could you please give me the apple from the side table \n",
      "\n",
      "#word_labels: O O O B-take B-take.pro O B-take.obj O O B-take.dest I-take.dest\n",
      "could ,tokens ['could'] , label:  O code:  3\n",
      "you ,tokens ['you'] , label:  O code:  3\n",
      "please ,tokens ['please'] , label:  O code:  3\n",
      "give ,tokens ['give'] , label:  B-take code:  28\n",
      "me ,tokens ['me'] , label:  B-take.pro code:  14\n",
      "the ,tokens ['the'] , label:  O code:  3\n",
      "apple ,tokens ['apple'] , label:  B-take.obj code:  9\n",
      "from ,tokens ['from'] , label:  O code:  3\n",
      "the ,tokens ['the'] , label:  O code:  3\n",
      "side ,tokens ['side'] , label:  B-take.dest code:  1\n",
      "table ,tokens ['table'] , label:  I-take.dest code:  27\n",
      "encode:  [[0 3 3 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "\n",
      "0\n",
      "could you please the living room \n",
      "\n",
      "#word_labels: O O O O O O\n",
      "could ,tokens ['could'] , label:  O code:  3\n",
      "you ,tokens ['you'] , label:  O code:  3\n",
      "please ,tokens ['please'] , label:  O code:  3\n",
      "the ,tokens ['the'] , label:  O code:  3\n",
      "living ,tokens ['living'] , label:  O code:  3\n",
      "room ,tokens ['room'] , label:  O code:  3\n",
      "encode:  [[0 3 3 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "\n",
      "0\n",
      "B-take B-take.per O O B-take.dest \n",
      "\n",
      "#word_labels: B-take B-take.per O O B-take.dest\n",
      "B-take ,tokens ['b', '-', 'take'] , label:  B-take code:  28\n",
      "B-take.per ,tokens ['b', '-', 'take', '.', 'per'] , label:  B-take.per code:  16\n",
      "O ,tokens ['o'] , label:  O code:  3\n",
      "O ,tokens ['o'] , label:  O code:  3\n",
      "B-take.dest ,tokens ['b', '-', 'take', '.', 'des', '##t'] , label:  B-take.dest code:  1\n",
      "encode:  [[ 0 28 28 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_train = encode_token_labels(df_train['words'], df_train['words_label'],\n",
    "                                  tokenizer, all_label_map, 50)\n",
    "label_val = encode_token_labels(df_val['words'],\n",
    "                                      df_val['words_label'],\n",
    "                                      tokenizer, all_label_map, 50)\n",
    "label_test = encode_token_labels(df_test['words'], df_test['words_label'],\n",
    "                                tokenizer, all_label_map, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could you please give me the apple from the side table\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  3,  3, 28, 14,  3,  9,  3,  3,  1, 27,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = df_train.iloc[0]['words']\n",
    "print(sentence)\n",
    "slot_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#         if self.labels:\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "train_dataset = Dataset(encoded_train, label_train)\n",
    "val_dataset = Dataset(encoded_val, label_val)\n",
    "test_dataset = Dataset(encoded_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  5009,  4074,  2000,  1996,  9841, 28556,  2121,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        dtype=torch.int32),\n",
       " 'attention_masks': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0], dtype=torch.int32),\n",
       " 'labels': tensor([ 0,  3,  3,  3, 28, 14,  3,  9,  3,  3,  1, 27,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        dtype=torch.int32)}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: \n",
    "\n",
    "https://huggingface.co/databuzzword/JointBERT-atis/tree/main\n",
    "\n",
    "https://huggingface.co/databuzzword/JointBERT-snips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at JointBERT-snips/ were not used when initializing BertModel: ['intent_classifier.linear.bias', 'slot_classifier.linear.bias', 'slot_classifier.linear.weight', 'intent_classifier.linear.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"databuzzword/JointBERT-snips\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('JointBERT-snips/', local_files_only=True)\n",
    "\n",
    "model = AutoModel.from_pretrained('JointBERT-snips/', local_files_only=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "model\n",
    "# Check whether have weights too\n",
    "# model.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 200\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n",
      "The following columns in the training set don't have a corresponding argument in `BertModel.forward` and have been ignored: labels, attention_masks. If labels, attention_masks are not expected by `BertModel.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17348/4222109776.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m         )\n\u001b[1;32m-> 1409\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1410\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1649\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1651\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1653\u001b[0m                 if (\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2344\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2345\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2386\u001b[0m             \u001b[1;31m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2387\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2389\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0minner_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,#df_train[\"train\"],\n",
    "    eval_dataset=val_dataset,#df_val[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertConfig, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from utils import MODEL_CLASSES, compute_metrics, get_intent_labels, get_slot_labels\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, args, train_dataset=None, dev_dataset=None, test_dataset=None):\n",
    "        self.args = args\n",
    "        self.train_dataset = train_dataset\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "        self.intent_label_lst = get_intent_labels(args)\n",
    "        self.slot_label_lst = get_slot_labels(args)\n",
    "        # Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later\n",
    "        self.pad_token_label_id = args.ignore_index\n",
    "\n",
    "        self.config_class, self.model_class, _ = MODEL_CLASSES[args.model_type]\n",
    "        self.config = self.config_class.from_pretrained(args.model_name_or_path, finetuning_task=args.task)\n",
    "        self.model = self.model_class.from_pretrained(args.model_name_or_path,\n",
    "                                                      config=self.config,\n",
    "                                                      args=args,\n",
    "                                                      intent_label_lst=self.intent_label_lst,\n",
    "                                                      slot_label_lst=self.slot_label_lst)\n",
    "\n",
    "        # GPU or CPU\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train(self):\n",
    "        train_sampler = RandomSampler(self.train_dataset)\n",
    "        train_dataloader = DataLoader(self.train_dataset, sampler=train_sampler, batch_size=self.args.train_batch_size)\n",
    "\n",
    "        if self.args.max_steps > 0:\n",
    "            t_total = self.args.max_steps\n",
    "            self.args.num_train_epochs = self.args.max_steps // (len(train_dataloader) // self.args.gradient_accumulation_steps) + 1\n",
    "        else:\n",
    "            t_total = len(train_dataloader) // self.args.gradient_accumulation_steps * self.args.num_train_epochs\n",
    "\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': self.args.weight_decay},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate, eps=self.args.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=self.args.warmup_steps, num_training_steps=t_total)\n",
    "\n",
    "        # Train!\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(self.train_dataset))\n",
    "        logger.info(\"  Num Epochs = %d\", self.args.num_train_epochs)\n",
    "        logger.info(\"  Total train batch size = %d\", self.args.train_batch_size)\n",
    "        logger.info(\"  Gradient Accumulation steps = %d\", self.args.gradient_accumulation_steps)\n",
    "        logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "        logger.info(\"  Logging steps = %d\", self.args.logging_steps)\n",
    "        logger.info(\"  Save steps = %d\", self.args.save_steps)\n",
    "\n",
    "        global_step = 0\n",
    "        tr_loss = 0.0\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        train_iterator = trange(int(self.args.num_train_epochs), desc=\"Epoch\")\n",
    "\n",
    "        for _ in train_iterator:\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "            for step, batch in enumerate(epoch_iterator):\n",
    "                self.model.train()\n",
    "                batch = tuple(t.to(self.device) for t in batch)  # GPU or CPU\n",
    "\n",
    "                inputs = {'input_ids': batch[0],\n",
    "                          'attention_mask': batch[1],\n",
    "                          'intent_label_ids': batch[3],\n",
    "                          'slot_labels_ids': batch[4]}\n",
    "                if self.args.model_type != 'distilbert':\n",
    "                    inputs['token_type_ids'] = batch[2]\n",
    "                outputs = self.model(**inputs)\n",
    "                loss = outputs[0]\n",
    "\n",
    "                if self.args.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                tr_loss += loss.item()\n",
    "                if (step + 1) % self.args.gradient_accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()  # Update learning rate schedule\n",
    "                    self.model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "                    if self.args.logging_steps > 0 and global_step % self.args.logging_steps == 0:\n",
    "                        self.evaluate(\"dev\")\n",
    "\n",
    "                    if self.args.save_steps > 0 and global_step % self.args.save_steps == 0:\n",
    "                        self.save_model()\n",
    "\n",
    "                if 0 < self.args.max_steps < global_step:\n",
    "                    epoch_iterator.close()\n",
    "                    break\n",
    "\n",
    "            if 0 < self.args.max_steps < global_step:\n",
    "                train_iterator.close()\n",
    "                break\n",
    "\n",
    "        return global_step, tr_loss / global_step\n",
    "\n",
    "    def evaluate(self, mode):\n",
    "        if mode == 'test':\n",
    "            dataset = self.test_dataset\n",
    "        elif mode == 'dev':\n",
    "            dataset = self.dev_dataset\n",
    "        else:\n",
    "            raise Exception(\"Only dev and test dataset available\")\n",
    "\n",
    "        eval_sampler = SequentialSampler(dataset)\n",
    "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.args.eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation on %s dataset *****\", mode)\n",
    "        logger.info(\"  Num examples = %d\", len(dataset))\n",
    "        logger.info(\"  Batch size = %d\", self.args.eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        intent_preds = None\n",
    "        slot_preds = None\n",
    "        out_intent_label_ids = None\n",
    "        out_slot_labels_ids = None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            batch = tuple(t.to(self.device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {'input_ids': batch[0],\n",
    "                          'attention_mask': batch[1],\n",
    "                          'intent_label_ids': batch[3],\n",
    "                          'slot_labels_ids': batch[4]}\n",
    "                if self.args.model_type != 'distilbert':\n",
    "                    inputs['token_type_ids'] = batch[2]\n",
    "                outputs = self.model(**inputs)\n",
    "                tmp_eval_loss, (intent_logits, slot_logits) = outputs[:2]\n",
    "\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            # Intent prediction\n",
    "            if intent_preds is None:\n",
    "                intent_preds = intent_logits.detach().cpu().numpy()\n",
    "                out_intent_label_ids = inputs['intent_label_ids'].detach().cpu().numpy()\n",
    "            else:\n",
    "                intent_preds = np.append(intent_preds, intent_logits.detach().cpu().numpy(), axis=0)\n",
    "                out_intent_label_ids = np.append(\n",
    "                    out_intent_label_ids, inputs['intent_label_ids'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "            # Slot prediction\n",
    "            if slot_preds is None:\n",
    "                if self.args.use_crf:\n",
    "                    # decode() in `torchcrf` returns list with best index directly\n",
    "                    slot_preds = np.array(self.model.crf.decode(slot_logits))\n",
    "                else:\n",
    "                    slot_preds = slot_logits.detach().cpu().numpy()\n",
    "\n",
    "                out_slot_labels_ids = inputs[\"slot_labels_ids\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                if self.args.use_crf:\n",
    "                    slot_preds = np.append(slot_preds, np.array(self.model.crf.decode(slot_logits)), axis=0)\n",
    "                else:\n",
    "                    slot_preds = np.append(slot_preds, slot_logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "                out_slot_labels_ids = np.append(out_slot_labels_ids, inputs[\"slot_labels_ids\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        results = {\n",
    "            \"loss\": eval_loss\n",
    "        }\n",
    "\n",
    "        # Intent result\n",
    "        intent_preds = np.argmax(intent_preds, axis=1)\n",
    "\n",
    "        # Slot result\n",
    "        if not self.args.use_crf:\n",
    "            slot_preds = np.argmax(slot_preds, axis=2)\n",
    "        slot_label_map = {i: label for i, label in enumerate(self.slot_label_lst)}\n",
    "        out_slot_label_list = [[] for _ in range(out_slot_labels_ids.shape[0])]\n",
    "        slot_preds_list = [[] for _ in range(out_slot_labels_ids.shape[0])]\n",
    "\n",
    "        for i in range(out_slot_labels_ids.shape[0]):\n",
    "            for j in range(out_slot_labels_ids.shape[1]):\n",
    "                if out_slot_labels_ids[i, j] != self.pad_token_label_id:\n",
    "                    out_slot_label_list[i].append(slot_label_map[out_slot_labels_ids[i][j]])\n",
    "                    slot_preds_list[i].append(slot_label_map[slot_preds[i][j]])\n",
    "\n",
    "        total_result = compute_metrics(intent_preds, out_intent_label_ids, slot_preds_list, out_slot_label_list)\n",
    "        results.update(total_result)\n",
    "\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(results.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(results[key]))\n",
    "\n",
    "        return results\n",
    "\n",
    "    def save_model(self):\n",
    "        # Save model checkpoint (Overwrite)\n",
    "        if not os.path.exists(self.args.model_dir):\n",
    "            os.makedirs(self.args.model_dir)\n",
    "        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "        model_to_save.save_pretrained(self.args.model_dir)\n",
    "\n",
    "        # Save training arguments together with the trained model\n",
    "        torch.save(self.args, os.path.join(self.args.model_dir, 'training_args.bin'))\n",
    "        logger.info(\"Saving model checkpoint to %s\", self.args.model_dir)\n",
    "\n",
    "    def load_model(self):\n",
    "        # Check whether model exists\n",
    "        if not os.path.exists(self.args.model_dir):\n",
    "            raise Exception(\"Model doesn't exists! Train first!\")\n",
    "\n",
    "        try:\n",
    "            self.model = self.model_class.from_pretrained(self.args.model_dir,\n",
    "                                                          args=self.args,\n",
    "                                                          intent_label_lst=self.intent_label_lst,\n",
    "                                                          slot_label_lst=self.slot_label_lst)\n",
    "            self.model.to(self.device)\n",
    "            logger.info(\"***** Model Loaded *****\")\n",
    "        except:\n",
    "            raise Exception(\"Some model files might be missing...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
