{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 26\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptim\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m random_split\n\u001B[0;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tune\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtune\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CLIReporter\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtune\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mschedulers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ASHAScheduler\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'ray'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertModel, BertConfig\n",
    "from transformers import BertConfig, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import random\n",
    "import time\n",
    "import argparse\n",
    "from utils import init_logger, load_tokenizer, read_prediction_text, set_seed, MODEL_CLASSES, MODEL_PATH_MAP, get_intent_labels, get_slot_labels, compute_metrics\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    time_wait = random.uniform(0, 10)\n",
    "    time.sleep(time_wait)\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--task\", default='mixatis', type=str, help=\"The name of the task to train\")\n",
    "\n",
    "#     parser.add_argument(\"--model_dir\", default='./gpsr_model', required=True, type=str, help=\"Path to save, load model\")\n",
    "    parser.add_argument(\"--model_dir\", default='./mixatis_model', type=str, help=\"Path to save, load model\")\n",
    "\n",
    "    parser.add_argument(\"--data_dir\", default=\"./data\", type=str, help=\"The input data dir\")\n",
    "    parser.add_argument(\"--intent_label_file\", default=\"intent_label.txt\", type=str, help=\"Intent Label file\")\n",
    "    parser.add_argument(\"--slot_label_file\", default=\"slot_label.txt\", type=str, help=\"Slot Label file\")\n",
    "    parser.add_argument(\"--model_type\", default=\"multibert\", type=str, help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()))\n",
    "#     parser.add_argument(\"--intent_seq\", type=int, default=0, help=\"whether we use intent seq setting\")\n",
    "    parser.add_argument(\"--intent_seq\", type=int, default=1, help=\"whether we use intent seq setting\")\n",
    "\n",
    "    parser.add_argument(\"--multi_intent\", type=int, default=1, help=\"whether we use multi intent setting\")\n",
    "    parser.add_argument(\"--tag_intent\", type=int, default=1, help=\"whether we can use tag to predict intent\")\n",
    "\n",
    "    parser.add_argument(\"--BI_tag\", type=int, default=1, help='use BI sum or just B')\n",
    "    parser.add_argument(\"--cls_token_cat\", type=int, default=1, help='whether we cat the cls to the slot output of bert')\n",
    "    parser.add_argument(\"--intent_attn\", type=int, default=1, help='whether we use attention mechanism on the CLS intent output')\n",
    "    parser.add_argument(\"--num_mask\", type=int, default=7, help=\"assumptive number of slot in one sentence\")\n",
    "                                           #max slot num = 7\n",
    "\n",
    "\n",
    "\n",
    "    parser.add_argument('--seed', type=int, default=25, help=\"random seed for initialization\")\n",
    "    parser.add_argument(\"--train_batch_size\", default=128, type=int, help=\"Batch size for training.\")\n",
    "#     parser.add_argument(\"--train_batch_size\", default=64, type=int, help=\"Batch size for training.\")\n",
    "\n",
    "    parser.add_argument(\"--eval_batch_size\", default=256, type=int, help=\"Batch size for evaluation.\")\n",
    "    # gpsr\n",
    "    # parser.add_argument(\"--max_seq_len\", default=32, type=int, help=\"The maximum total input sequence length after tokenization.\")\n",
    "\n",
    "    # SNIPS ATIS\n",
    "    # parser.add_argument(\"--max_seq_len\", default=64, type=int, help=\"The maximum total input sequence length after tokenization.\")#!!!!!!!!!!!! need toadd crop in unet!!!!\n",
    "    parser.add_argument(\"--max_seq_len\", default=50, type=int, help=\"The maximum total input sequence length after tokenization.\")#!!!!!!!!!!!! need toadd crop in unet!!!!\n",
    "\n",
    "    # parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
    "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
    "\n",
    "#     parser.add_argument(\"--num_train_epochs\", default=10.0, type=float, help=\"Total number of training epochs to perform.\")\n",
    "    parser.add_argument(\"--num_train_epochs\", default=15.0, type=float, help=\"Total number of training epochs to perform.\")\n",
    "                                            #####\n",
    "\n",
    "    parser.add_argument(\"--weight_decay\", default=1e-4, type=float, help=\"Weight decay if we apply some.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n",
    "                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--max_grad_norm\", default=1, type=float, help=\"Max gradient norm.\")\n",
    "    parser.add_argument(\"--max_steps\", default=-1, type=int, help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n",
    "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "    parser.add_argument(\"--dropout_rate\", default=0.1, type=float, help=\"Dropout for fully-connected layers\")\n",
    "    parser.add_argument('--logging_steps', type=int, default=500, help=\"Log every X updates steps.\")\n",
    "    parser.add_argument('--save_steps', type=int, default=300, help=\"Save checkpoint every X updates steps.\")\n",
    "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
    "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the test set.\")\n",
    "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "    parser.add_argument(\"--ignore_index\", default=0, type=int,\n",
    "                        help='Specifies a target value that is ignored and does not contribute to the input gradient')\n",
    "    parser.add_argument('--slot_loss_coef', type=float, default=2.0, help='Coefficient for the slot loss.')\n",
    "    parser.add_argument('--tag_intent_coef', type=float, default=1.0, help='Coefficient for the tag intent loss')\n",
    "\n",
    "    # CRF option\n",
    "    parser.add_argument(\"--use_crf\", action=\"store_true\", help=\"Whether to use CRF\")\n",
    "    parser.add_argument(\"--slot_pad_label\", default=\"PAD\", type=str, help=\"Pad token for slot label pad (to be ignore when calculate loss)\")\n",
    "    parser.add_argument(\"--patience\", default=0, type=int, help=\"The initial learning rate for Adam.\")\n",
    "\n",
    "    parser.add_argument('-f')#########################\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    args.model_name_or_path = MODEL_PATH_MAP[args.model_type]\n",
    "    args.model_name_or_path = MODEL_PATH_MAP[args.model_type]\n",
    "\n",
    "    tokenizer = load_tokenizer(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "a[::-1]\n",
    "b = [1,2,3]\n",
    "b[::-1][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "UNet(\n  (down_layers): ModuleList(\n    (0): Conv1d(768, 800, kernel_size=(12,), stride=(1,), padding=same)\n    (1): Conv1d(800, 900, kernel_size=(4,), stride=(1,), padding=same)\n    (2): Conv1d(900, 1024, kernel_size=(3,), stride=(1,), padding=same)\n  )\n  (bottle_neck): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=same)\n  (up_layers): ModuleList(\n    (0): Conv1d(1024, 900, kernel_size=(3,), stride=(1,), padding=same)\n    (1): Conv1d(1800, 800, kernel_size=(4,), stride=(1,), padding=same)\n    (2): Conv1d(1600, 768, kernel_size=(12,), stride=(1,), padding=same)\n  )\n  (conv_mask): ModuleList(\n    (0): Conv1d(768, 256, kernel_size=(8,), stride=(1,), padding=same)\n    (1): Conv1d(256, 145, kernel_size=(1,), stride=(1,))\n  )\n  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (up_conv_trans): ModuleList(\n    (0): ConvTranspose1d(1024, 1024, kernel_size=(7,), stride=(1,))\n    (1): ConvTranspose1d(900, 900, kernel_size=(14,), stride=(1,))\n    (2): ConvTranspose1d(800, 800, kernel_size=(26,), stride=(1,))\n  )\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, args,config, num_intent_labels, num_slot_labels,features = [800,900,1024]):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = config.hidden_size\n",
    "        self.max_seq_len = args.max_seq_len\n",
    "        self.output_dim = num_intent_labels + num_slot_labels\n",
    "\n",
    "        self.down_layers = nn.ModuleList([nn.Conv1d(in_channels = self.embedding_dim,out_channels = 800, kernel_size = 12,padding='same'),\n",
    "                                         nn.Conv1d(in_channels = 800,out_channels = 900, kernel_size = 4,padding='same'),\n",
    "                                         nn.Conv1d(in_channels = 900,out_channels = 1024, kernel_size = 3,padding='same')])\n",
    "\n",
    "        self.bottle_neck = nn.Conv1d(in_channels = 1024,out_channels = 1024, kernel_size = 3, padding='same')\n",
    "\n",
    "\n",
    "        self.up_layers = nn.ModuleList([nn.Conv1d(in_channels = 1024,out_channels = 900, kernel_size = 3, padding='same'),\n",
    "                                         nn.Conv1d(in_channels = 900*2,out_channels = 800, kernel_size = 4,padding='same'),\n",
    "                                         nn.Conv1d(in_channels = 800*2,out_channels = self.embedding_dim, kernel_size =12,padding='same')])\n",
    "\n",
    "        self.conv_mask = nn.ModuleList([nn.Conv1d(in_channels = self.embedding_dim,out_channels = 256, kernel_size = 8,padding='same'),\n",
    "                                         nn.Conv1d(in_channels = 256,out_channels = self.output_dim, kernel_size = 1)])\n",
    "\n",
    "        self.pool = nn.MaxPool1d(2, return_indices=False)\n",
    "        self.up_conv_trans = nn.ModuleList()\n",
    "        #self.unpool = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        lens = [self.max_seq_len]\n",
    "        for i in range(len(features)):\n",
    "            lens.append(lens[-1]//2) #floor, cuz max pool will floor\n",
    "\n",
    "        conv_trans_ks = []\n",
    "        cur_len = lens.pop()\n",
    "        for l in lens[::-1]:\n",
    "            conv_trans_ks.append(l - cur_len + 1)\n",
    "            cur_len = l\n",
    "\n",
    "        for i,ks in enumerate(conv_trans_ks):\n",
    "            feat = features[::-1][i]\n",
    "            self.up_conv_trans.append(nn.ConvTranspose1d(feat,feat, kernel_size=ks))\n",
    "\n",
    "\n",
    "    def forward(self, embeded):\n",
    "        x = embeded.permute(0,2,1)\n",
    "        #print('permute size: ',embeded.size())\n",
    "        skip_connections = []\n",
    "        indices = []\n",
    "        for i, layer in enumerate(self.down_layers):\n",
    "            x = F.relu(layer(x))\n",
    "            # print('x shape: ', x.size())\n",
    "\n",
    "            if i < 2:\n",
    "                skip_connections.append(x)\n",
    "                x = self.pool(x)\n",
    "                # print('small x size: ',x.size())\n",
    "        # print('-------------------------------------------------')\n",
    "        # bottle neck\n",
    "        x = F.relu(self.bottle_neck(x))\n",
    "        #print('-------------------------------------------------')\n",
    "        for i, layer in enumerate(self.up_layers):\n",
    "            if i > 0:\n",
    "                # x = self.unpool(x)\n",
    "                x = self.up_conv_trans[i](x)\n",
    "                # print('large x size: ',x.size())\n",
    "                sc = skip_connections.pop()\n",
    "                #print('pop size: ', sc.size())\n",
    "                #print('curr x size: ', x.size())\n",
    "                x = torch.cat((sc,x),dim = 1)\n",
    "                # print('!cat size: ',x.size())\n",
    "            x = F.relu(layer(x))\n",
    "            # if i < len(self.up_layers) - 1: x = F.relu(x)\n",
    "\n",
    "        for i, layer in enumerate(self.conv_mask):\n",
    "            x = layer(x)\n",
    "            if i < len(self.conv_mask) - 1: x = F.relu(x)\n",
    "        return (x)\n",
    "\n",
    "\n",
    "config_class, model_class, _ = MODEL_CLASSES[args.model_type]\n",
    "config = config_class.from_pretrained(args.model_name_or_path, finetuning_task=args.task)\n",
    "num_intent_labels = len(get_intent_labels(args))\n",
    "num_slot_labels = len(get_slot_labels(args))\n",
    "unet = UNet(args,config, num_intent_labels, num_slot_labels)\n",
    "unet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "JSF_Seg(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (unet): UNet(\n    (down_layers): ModuleList(\n      (0): Conv1d(768, 800, kernel_size=(12,), stride=(1,), padding=same)\n      (1): Conv1d(800, 900, kernel_size=(4,), stride=(1,), padding=same)\n      (2): Conv1d(900, 1024, kernel_size=(3,), stride=(1,), padding=same)\n    )\n    (bottle_neck): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=same)\n    (up_layers): ModuleList(\n      (0): Conv1d(1024, 900, kernel_size=(3,), stride=(1,), padding=same)\n      (1): Conv1d(1800, 800, kernel_size=(4,), stride=(1,), padding=same)\n      (2): Conv1d(1600, 768, kernel_size=(12,), stride=(1,), padding=same)\n    )\n    (conv_mask): ModuleList(\n      (0): Conv1d(768, 256, kernel_size=(8,), stride=(1,), padding=same)\n      (1): Conv1d(256, 145, kernel_size=(1,), stride=(1,))\n    )\n    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (up_conv_trans): ModuleList(\n      (0): ConvTranspose1d(1024, 1024, kernel_size=(7,), stride=(1,))\n      (1): ConvTranspose1d(900, 900, kernel_size=(14,), stride=(1,))\n      (2): ConvTranspose1d(800, 800, kernel_size=(26,), stride=(1,))\n    )\n  )\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_class, model_class, _ = MODEL_CLASSES[args.model_type]\n",
    "config = config_class.from_pretrained(args.model_name_or_path, finetuning_task=args.task)\n",
    "\n",
    "class JSF_Seg(nn.Module):\n",
    "    def __init__(self, args,config, num_intent_labels, num_slot_labels, froze_last = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = BertModel(config=config)\n",
    "        self.unet = UNet(args,config, num_intent_labels, num_slot_labels)\n",
    "\n",
    "        if froze_last:\n",
    "            for name, param in self.bert.named_parameters():\n",
    "                if name.startswith(\"encoder.layer.11\"): # choose whatever you like here\n",
    "                    param.requires_grad = True\n",
    "                elif name.startswith(\"encoder.layer.10\"):\n",
    "                    param.requires_grad = True\n",
    "                elif name.startswith(\"encoder.layer.9\"):\n",
    "                    param.requires_grad = True\n",
    "                # elif name.startswith(\"encoder.layer.8\"):\n",
    "                #     param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def forward(self,**inputs):\n",
    "        outputs = self.bert(**inputs)\n",
    "        sequence_output = outputs[0]\n",
    "        out = self.unet(sequence_output)\n",
    "        return out\n",
    "\n",
    "num_intent_labels = len(get_intent_labels(args))\n",
    "num_slot_labels = len(get_slot_labels(args))\n",
    "model = JSF_Seg(args,config, num_intent_labels, num_slot_labels)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Training Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "\n",
      "Iteration:   1%|          | 1/141 [00:01<03:03,  1.31s/it]\u001B[A\n",
      "Iteration:   1%|▏         | 2/141 [00:01<01:47,  1.29it/s]\u001B[A\n",
      "Iteration:   2%|▏         | 3/141 [00:02<01:23,  1.66it/s]\u001B[A\n",
      "Iteration:   3%|▎         | 4/141 [00:02<01:11,  1.91it/s]\u001B[A\n",
      "Iteration:   4%|▎         | 5/141 [00:02<01:04,  2.10it/s]\u001B[A\n",
      "Iteration:   4%|▍         | 6/141 [00:03<01:00,  2.22it/s]\u001B[A\n",
      "Iteration:   5%|▍         | 7/141 [00:03<00:58,  2.30it/s]\u001B[A\n",
      "Iteration:   6%|▌         | 8/141 [00:04<00:56,  2.36it/s]\u001B[A\n",
      "Iteration:   6%|▋         | 9/141 [00:04<00:54,  2.41it/s]\u001B[A\n",
      "Iteration:   7%|▋         | 10/141 [00:04<00:53,  2.44it/s]\u001B[A\n",
      "Iteration:   8%|▊         | 11/141 [00:05<00:53,  2.45it/s]\u001B[A\n",
      "Iteration:   9%|▊         | 12/141 [00:05<00:52,  2.47it/s]\u001B[A\n",
      "Iteration:   9%|▉         | 13/141 [00:06<00:51,  2.48it/s]\u001B[A\n",
      "Iteration:  10%|▉         | 14/141 [00:06<00:51,  2.49it/s]\u001B[A\n",
      "Iteration:  11%|█         | 15/141 [00:06<00:50,  2.50it/s]\u001B[A\n",
      "Iteration:  11%|█▏        | 16/141 [00:07<00:50,  2.50it/s]\u001B[A\n",
      "Iteration:  12%|█▏        | 17/141 [00:07<00:49,  2.50it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 18/141 [00:08<00:49,  2.51it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 19/141 [00:08<00:48,  2.50it/s]\u001B[A\n",
      "Iteration:  14%|█▍        | 20/141 [00:08<00:48,  2.50it/s]\u001B[A\n",
      "Iteration:  15%|█▍        | 21/141 [00:09<00:47,  2.51it/s]\u001B[A\n",
      "Iteration:  16%|█▌        | 22/141 [00:09<00:47,  2.51it/s]\u001B[A\n",
      "Iteration:  16%|█▋        | 23/141 [00:10<00:47,  2.51it/s]\u001B[A\n",
      "Iteration:  17%|█▋        | 24/141 [00:10<00:46,  2.51it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 25/141 [00:10<00:46,  2.51it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 26/141 [00:11<00:45,  2.51it/s]\u001B[A\n",
      "Iteration:  19%|█▉        | 27/141 [00:11<00:45,  2.51it/s]\u001B[A\n",
      "Iteration:  20%|█▉        | 28/141 [00:12<00:44,  2.51it/s]\u001B[A\n",
      "Iteration:  21%|██        | 29/141 [00:12<00:44,  2.51it/s]\u001B[A\n",
      "Iteration:  21%|██▏       | 30/141 [00:12<00:44,  2.51it/s]\u001B[A\n",
      "Iteration:  22%|██▏       | 31/141 [00:13<00:43,  2.51it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 32/141 [00:13<00:43,  2.51it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 33/141 [00:14<00:43,  2.51it/s]\u001B[A\n",
      "Iteration:  24%|██▍       | 34/141 [00:14<00:42,  2.51it/s]\u001B[A\n",
      "Iteration:  25%|██▍       | 35/141 [00:14<00:42,  2.51it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 36/141 [00:15<00:41,  2.51it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 37/141 [00:15<00:41,  2.51it/s]\u001B[A\n",
      "Iteration:  27%|██▋       | 38/141 [00:16<00:41,  2.50it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 39/141 [00:16<00:40,  2.50it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 40/141 [00:16<00:40,  2.50it/s]\u001B[A\n",
      "Iteration:  29%|██▉       | 41/141 [00:17<00:39,  2.51it/s]\u001B[A\n",
      "Iteration:  30%|██▉       | 42/141 [00:17<00:39,  2.50it/s]\u001B[A\n",
      "Iteration:  30%|███       | 43/141 [00:18<00:39,  2.50it/s]\u001B[A\n",
      "Iteration:  31%|███       | 44/141 [00:18<00:38,  2.50it/s]\u001B[A\n",
      "Iteration:  32%|███▏      | 45/141 [00:18<00:38,  2.50it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 46/141 [00:19<00:37,  2.50it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 47/141 [00:19<00:37,  2.50it/s]\u001B[A\n",
      "Iteration:  34%|███▍      | 48/141 [00:20<00:37,  2.50it/s]\u001B[A\n",
      "Iteration:  35%|███▍      | 49/141 [00:20<00:36,  2.50it/s]\u001B[A\n",
      "Iteration:  35%|███▌      | 50/141 [00:20<00:36,  2.50it/s]\u001B[A\n",
      "Iteration:  36%|███▌      | 51/141 [00:21<00:36,  2.50it/s]\u001B[A\n",
      "Iteration:  37%|███▋      | 52/141 [00:21<00:35,  2.50it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 53/141 [00:22<00:35,  2.50it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 54/141 [00:22<00:34,  2.50it/s]\u001B[A\n",
      "Iteration:  39%|███▉      | 55/141 [00:22<00:34,  2.50it/s]\u001B[A\n",
      "Iteration:  40%|███▉      | 56/141 [00:23<00:34,  2.50it/s]\u001B[A\n",
      "Iteration:  40%|████      | 57/141 [00:23<00:33,  2.50it/s]\u001B[A\n",
      "Iteration:  41%|████      | 58/141 [00:24<00:33,  2.50it/s]\u001B[A\n",
      "Iteration:  42%|████▏     | 59/141 [00:24<00:32,  2.50it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 60/141 [00:24<00:32,  2.50it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 61/141 [00:25<00:32,  2.50it/s]\u001B[A\n",
      "Iteration:  44%|████▍     | 62/141 [00:25<00:31,  2.50it/s]\u001B[A\n",
      "Iteration:  45%|████▍     | 63/141 [00:26<00:31,  2.50it/s]\u001B[A\n",
      "Iteration:  45%|████▌     | 64/141 [00:26<00:31,  2.44it/s]\u001B[A\n",
      "Iteration:  46%|████▌     | 65/141 [00:26<00:30,  2.46it/s]\u001B[A\n",
      "Iteration:  47%|████▋     | 66/141 [00:27<00:30,  2.46it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 67/141 [00:27<00:29,  2.48it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 68/141 [00:28<00:29,  2.48it/s]\u001B[A\n",
      "Iteration:  49%|████▉     | 69/141 [00:28<00:29,  2.48it/s]\u001B[A\n",
      "Iteration:  50%|████▉     | 70/141 [00:28<00:28,  2.49it/s]\u001B[A\n",
      "Iteration:  50%|█████     | 71/141 [00:29<00:28,  2.49it/s]\u001B[A\n",
      "Iteration:  51%|█████     | 72/141 [00:29<00:27,  2.49it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 73/141 [00:30<00:27,  2.49it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 74/141 [00:30<00:26,  2.49it/s]\u001B[A\n",
      "Iteration:  53%|█████▎    | 75/141 [00:30<00:26,  2.50it/s]\u001B[A\n",
      "Iteration:  54%|█████▍    | 76/141 [00:31<00:26,  2.50it/s]\u001B[A\n",
      "Iteration:  55%|█████▍    | 77/141 [00:31<00:25,  2.50it/s]\u001B[A\n",
      "Iteration:  55%|█████▌    | 78/141 [00:32<00:25,  2.49it/s]\u001B[A\n",
      "Iteration:  56%|█████▌    | 79/141 [00:32<00:24,  2.49it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 80/141 [00:32<00:24,  2.49it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 81/141 [00:33<00:24,  2.49it/s]\u001B[A\n",
      "Iteration:  58%|█████▊    | 82/141 [00:33<00:23,  2.49it/s]\u001B[A\n",
      "Iteration:  59%|█████▉    | 83/141 [00:34<00:23,  2.49it/s]\u001B[A\n",
      "Iteration:  60%|█████▉    | 84/141 [00:34<00:22,  2.49it/s]\u001B[A\n",
      "Iteration:  60%|██████    | 85/141 [00:34<00:22,  2.49it/s]\u001B[A\n",
      "Iteration:  61%|██████    | 86/141 [00:35<00:22,  2.49it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 87/141 [00:35<00:21,  2.49it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 88/141 [00:36<00:21,  2.48it/s]\u001B[A\n",
      "Iteration:  63%|██████▎   | 89/141 [00:36<00:20,  2.48it/s]\u001B[A\n",
      "Iteration:  64%|██████▍   | 90/141 [00:36<00:20,  2.48it/s]\u001B[A\n",
      "Iteration:  65%|██████▍   | 91/141 [00:37<00:20,  2.49it/s]\u001B[A\n",
      "Iteration:  65%|██████▌   | 92/141 [00:37<00:19,  2.49it/s]\u001B[A\n",
      "Iteration:  66%|██████▌   | 93/141 [00:38<00:19,  2.49it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 94/141 [00:38<00:18,  2.48it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 95/141 [00:38<00:18,  2.49it/s]\u001B[A\n",
      "Iteration:  68%|██████▊   | 96/141 [00:39<00:18,  2.48it/s]\u001B[A\n",
      "Iteration:  69%|██████▉   | 97/141 [00:39<00:17,  2.48it/s]\u001B[A\n",
      "Iteration:  70%|██████▉   | 98/141 [00:40<00:17,  2.48it/s]\u001B[A\n",
      "Iteration:  70%|███████   | 99/141 [00:40<00:16,  2.48it/s]\u001B[A\n",
      "Iteration:  71%|███████   | 100/141 [00:40<00:16,  2.48it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 101/141 [00:41<00:16,  2.48it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 102/141 [00:41<00:15,  2.48it/s]\u001B[A\n",
      "Iteration:  73%|███████▎  | 103/141 [00:42<00:15,  2.48it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 104/141 [00:42<00:14,  2.48it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 105/141 [00:42<00:14,  2.48it/s]\u001B[A\n",
      "Iteration:  75%|███████▌  | 106/141 [00:43<00:14,  2.48it/s]\u001B[A\n",
      "Iteration:  76%|███████▌  | 107/141 [00:43<00:13,  2.48it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 108/141 [00:44<00:13,  2.48it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 109/141 [00:44<00:12,  2.48it/s]\u001B[A\n",
      "Iteration:  78%|███████▊  | 110/141 [00:44<00:12,  2.48it/s]\u001B[A\n",
      "Iteration:  79%|███████▊  | 111/141 [00:45<00:12,  2.48it/s]\u001B[A\n",
      "Iteration:  79%|███████▉  | 112/141 [00:45<00:11,  2.48it/s]\u001B[A\n",
      "Iteration:  80%|████████  | 113/141 [00:46<00:11,  2.48it/s]\u001B[A\n",
      "Iteration:  81%|████████  | 114/141 [00:46<00:10,  2.48it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 115/141 [00:47<00:10,  2.48it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 116/141 [00:47<00:10,  2.48it/s]\u001B[A\n",
      "Iteration:  83%|████████▎ | 117/141 [00:47<00:09,  2.48it/s]\u001B[A\n",
      "Iteration:  84%|████████▎ | 118/141 [00:48<00:09,  2.48it/s]\u001B[A\n",
      "Iteration:  84%|████████▍ | 119/141 [00:48<00:08,  2.48it/s]\u001B[A\n",
      "Iteration:  85%|████████▌ | 120/141 [00:49<00:08,  2.48it/s]\u001B[A\n",
      "Iteration:  86%|████████▌ | 121/141 [00:49<00:08,  2.47it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 122/141 [00:49<00:07,  2.47it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 123/141 [00:50<00:07,  2.48it/s]\u001B[A\n",
      "Iteration:  88%|████████▊ | 124/141 [00:50<00:06,  2.48it/s]\u001B[A\n",
      "Iteration:  89%|████████▊ | 125/141 [00:51<00:06,  2.47it/s]\u001B[A\n",
      "Iteration:  89%|████████▉ | 126/141 [00:51<00:06,  2.47it/s]\u001B[A\n",
      "Iteration:  90%|█████████ | 127/141 [00:51<00:05,  2.47it/s]\u001B[A\n",
      "Iteration:  91%|█████████ | 128/141 [00:52<00:05,  2.48it/s]\u001B[A\n",
      "Iteration:  91%|█████████▏| 129/141 [00:52<00:04,  2.47it/s]\u001B[A\n",
      "Iteration:  92%|█████████▏| 130/141 [00:53<00:04,  2.47it/s]\u001B[A\n",
      "Iteration:  93%|█████████▎| 131/141 [00:53<00:04,  2.47it/s]\u001B[A\n",
      "Iteration:  94%|█████████▎| 132/141 [00:53<00:03,  2.47it/s]\u001B[A\n",
      "Iteration:  94%|█████████▍| 133/141 [00:54<00:03,  2.47it/s]\u001B[A\n",
      "Iteration:  95%|█████████▌| 134/141 [00:54<00:02,  2.47it/s]\u001B[A\n",
      "Iteration:  96%|█████████▌| 135/141 [00:55<00:02,  2.47it/s]\u001B[A\n",
      "Iteration:  96%|█████████▋| 136/141 [00:55<00:02,  2.47it/s]\u001B[A\n",
      "Iteration:  97%|█████████▋| 137/141 [00:55<00:01,  2.47it/s]\u001B[A\n",
      "Iteration:  98%|█████████▊| 138/141 [00:56<00:01,  2.47it/s]\u001B[A\n",
      "Iteration:  99%|█████████▊| 139/141 [00:56<00:00,  2.47it/s]\u001B[A\n",
      "Iteration:  99%|█████████▉| 140/141 [00:57<00:00,  2.47it/s]\u001B[A\n",
      "Iteration: 100%|██████████| 141/141 [00:57<00:00,  2.46it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch: 1 current training loss: 86.02952064351832\n",
      "---------------------- eval on dev -----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating:  25%|██▌       | 1/4 [00:00<00:01,  2.23it/s]\u001B[A\n",
      "Evaluating:  50%|█████     | 2/4 [00:00<00:00,  2.29it/s]\u001B[A\n",
      "Evaluating:  75%|███████▌  | 3/4 [00:01<00:00,  2.32it/s]\u001B[A\n",
      "Evaluating: 100%|██████████| 4/4 [00:01<00:00,  2.36it/s]\u001B[A\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: UNK seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_capacity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_flight seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_quantity seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_city seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_restriction seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_distance seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_ground_fare seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_airfare seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_airline seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_ground_service seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_aircraft seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_airport seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_abbreviation seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_flight_time seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_cheapest seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_flight_no seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: atis_meal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Epoch:   7%|▋         | 1/15 [00:59<13:56, 59.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 40.586341857910156, 'intent_precision': 0.40663436451733137, 'intent_recall': 0.34822853495052664, 'intent_f1': 0.375171939477304, 'slot_precision': 0.6099808061420345, 'slot_recall': 0.47221396731054976, 'slot_f1': 0.5323283082077052, 'sementic_frame_acc': 0.004}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Iteration:   1%|          | 1/141 [00:00<00:53,  2.62it/s]\u001B[A\n",
      "Iteration:   1%|▏         | 2/141 [00:00<00:54,  2.55it/s]\u001B[A\n",
      "Iteration:   2%|▏         | 3/141 [00:01<00:55,  2.48it/s]\u001B[A\n",
      "Iteration:   3%|▎         | 4/141 [00:01<00:55,  2.48it/s]\u001B[A\n",
      "Iteration:   4%|▎         | 5/141 [00:02<00:54,  2.48it/s]\u001B[A\n",
      "Iteration:   4%|▍         | 6/141 [00:02<00:54,  2.48it/s]\u001B[A\n",
      "Iteration:   5%|▍         | 7/141 [00:02<00:54,  2.47it/s]\u001B[A\n",
      "Iteration:   6%|▌         | 8/141 [00:03<00:53,  2.47it/s]\u001B[A\n",
      "Iteration:   6%|▋         | 9/141 [00:03<00:53,  2.47it/s]\u001B[A\n",
      "Iteration:   7%|▋         | 10/141 [00:04<00:52,  2.47it/s]\u001B[A\n",
      "Iteration:   8%|▊         | 11/141 [00:04<00:52,  2.46it/s]\u001B[A\n",
      "Iteration:   9%|▊         | 12/141 [00:04<00:52,  2.46it/s]\u001B[A\n",
      "Iteration:   9%|▉         | 13/141 [00:05<00:51,  2.47it/s]\u001B[A\n",
      "Iteration:  10%|▉         | 14/141 [00:05<00:51,  2.47it/s]\u001B[A\n",
      "Iteration:  11%|█         | 15/141 [00:06<00:51,  2.47it/s]\u001B[A\n",
      "Iteration:  11%|█▏        | 16/141 [00:06<00:50,  2.46it/s]\u001B[A\n",
      "Iteration:  12%|█▏        | 17/141 [00:06<00:50,  2.47it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 18/141 [00:07<00:49,  2.47it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 19/141 [00:07<00:49,  2.47it/s]\u001B[A\n",
      "Iteration:  14%|█▍        | 20/141 [00:08<00:49,  2.46it/s]\u001B[A\n",
      "Iteration:  15%|█▍        | 21/141 [00:08<00:48,  2.46it/s]\u001B[A\n",
      "Iteration:  16%|█▌        | 22/141 [00:08<00:48,  2.46it/s]\u001B[A\n",
      "Iteration:  16%|█▋        | 23/141 [00:09<00:47,  2.46it/s]\u001B[A\n",
      "Iteration:  17%|█▋        | 24/141 [00:09<00:47,  2.46it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 25/141 [00:10<00:47,  2.46it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 26/141 [00:10<00:46,  2.46it/s]\u001B[A\n",
      "Iteration:  19%|█▉        | 27/141 [00:10<00:46,  2.46it/s]\u001B[A\n",
      "Iteration:  20%|█▉        | 28/141 [00:11<00:45,  2.46it/s]\u001B[A\n",
      "Iteration:  21%|██        | 29/141 [00:11<00:45,  2.46it/s]\u001B[A\n",
      "Iteration:  21%|██▏       | 30/141 [00:12<00:45,  2.46it/s]\u001B[A\n",
      "Iteration:  22%|██▏       | 31/141 [00:12<00:44,  2.46it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 32/141 [00:12<00:44,  2.46it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 33/141 [00:13<00:43,  2.46it/s]\u001B[A\n",
      "Iteration:  24%|██▍       | 34/141 [00:13<00:43,  2.46it/s]\u001B[A\n",
      "Iteration:  25%|██▍       | 35/141 [00:14<00:43,  2.46it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 36/141 [00:14<00:42,  2.46it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 37/141 [00:15<00:42,  2.45it/s]\u001B[A\n",
      "Iteration:  27%|██▋       | 38/141 [00:15<00:41,  2.45it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 39/141 [00:15<00:41,  2.45it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 40/141 [00:16<00:41,  2.45it/s]\u001B[A\n",
      "Iteration:  29%|██▉       | 41/141 [00:16<00:40,  2.46it/s]\u001B[A\n",
      "Iteration:  30%|██▉       | 42/141 [00:17<00:40,  2.46it/s]\u001B[A\n",
      "Iteration:  30%|███       | 43/141 [00:17<00:39,  2.46it/s]\u001B[A\n",
      "Iteration:  31%|███       | 44/141 [00:17<00:39,  2.46it/s]\u001B[A\n",
      "Iteration:  32%|███▏      | 45/141 [00:18<00:39,  2.46it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 46/141 [00:18<00:38,  2.46it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 47/141 [00:19<00:38,  2.46it/s]\u001B[A\n",
      "Iteration:  34%|███▍      | 48/141 [00:19<00:37,  2.46it/s]\u001B[A\n",
      "Iteration:  35%|███▍      | 49/141 [00:19<00:37,  2.46it/s]\u001B[A\n",
      "Iteration:  35%|███▌      | 50/141 [00:20<00:37,  2.46it/s]\u001B[A\n",
      "Iteration:  36%|███▌      | 51/141 [00:20<00:36,  2.46it/s]\u001B[A\n",
      "Iteration:  37%|███▋      | 52/141 [00:21<00:36,  2.46it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 53/141 [00:21<00:35,  2.46it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 54/141 [00:21<00:35,  2.45it/s]\u001B[A\n",
      "Iteration:  39%|███▉      | 55/141 [00:22<00:35,  2.46it/s]\u001B[A\n",
      "Iteration:  40%|███▉      | 56/141 [00:22<00:34,  2.45it/s]\u001B[A\n",
      "Iteration:  40%|████      | 57/141 [00:23<00:34,  2.45it/s]\u001B[A\n",
      "Iteration:  41%|████      | 58/141 [00:23<00:33,  2.46it/s]\u001B[A\n",
      "Iteration:  42%|████▏     | 59/141 [00:23<00:33,  2.45it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 60/141 [00:24<00:32,  2.46it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 61/141 [00:24<00:32,  2.46it/s]\u001B[A\n",
      "Iteration:  44%|████▍     | 62/141 [00:25<00:32,  2.46it/s]\u001B[A\n",
      "Iteration:  45%|████▍     | 63/141 [00:25<00:31,  2.46it/s]\u001B[A\n",
      "Iteration:  45%|████▌     | 64/141 [00:25<00:31,  2.45it/s]\u001B[A\n",
      "Iteration:  46%|████▌     | 65/141 [00:26<00:30,  2.46it/s]\u001B[A\n",
      "Iteration:  47%|████▋     | 66/141 [00:26<00:30,  2.46it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 67/141 [00:27<00:30,  2.45it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 68/141 [00:27<00:29,  2.46it/s]\u001B[A\n",
      "Iteration:  49%|████▉     | 69/141 [00:28<00:29,  2.46it/s]\u001B[A\n",
      "Iteration:  50%|████▉     | 70/141 [00:28<00:28,  2.45it/s]\u001B[A\n",
      "Iteration:  50%|█████     | 71/141 [00:28<00:28,  2.45it/s]\u001B[A\n",
      "Iteration:  51%|█████     | 72/141 [00:29<00:28,  2.45it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 73/141 [00:29<00:27,  2.45it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 74/141 [00:30<00:27,  2.45it/s]\u001B[A\n",
      "Iteration:  53%|█████▎    | 75/141 [00:30<00:26,  2.45it/s]\u001B[A\n",
      "Iteration:  54%|█████▍    | 76/141 [00:30<00:26,  2.45it/s]\u001B[A\n",
      "Iteration:  55%|█████▍    | 77/141 [00:31<00:26,  2.45it/s]\u001B[A\n",
      "Iteration:  55%|█████▌    | 78/141 [00:31<00:25,  2.45it/s]\u001B[A\n",
      "Iteration:  56%|█████▌    | 79/141 [00:32<00:25,  2.45it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 80/141 [00:32<00:24,  2.45it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 81/141 [00:32<00:24,  2.45it/s]\u001B[A\n",
      "Iteration:  58%|█████▊    | 82/141 [00:33<00:24,  2.45it/s]\u001B[A\n",
      "Iteration:  59%|█████▉    | 83/141 [00:33<00:23,  2.45it/s]\u001B[A\n",
      "Iteration:  60%|█████▉    | 84/141 [00:34<00:23,  2.45it/s]\u001B[A\n",
      "Iteration:  60%|██████    | 85/141 [00:34<00:22,  2.45it/s]\u001B[A\n",
      "Iteration:  61%|██████    | 86/141 [00:34<00:22,  2.45it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 87/141 [00:35<00:22,  2.45it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 88/141 [00:35<00:21,  2.45it/s]\u001B[A\n",
      "Iteration:  63%|██████▎   | 89/141 [00:36<00:21,  2.45it/s]\u001B[A\n",
      "Iteration:  64%|██████▍   | 90/141 [00:36<00:20,  2.45it/s]\u001B[A\n",
      "Iteration:  65%|██████▍   | 91/141 [00:37<00:20,  2.44it/s]\u001B[A\n",
      "Iteration:  65%|██████▌   | 92/141 [00:37<00:20,  2.45it/s]\u001B[A\n",
      "Iteration:  66%|██████▌   | 93/141 [00:37<00:19,  2.45it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 94/141 [00:38<00:19,  2.45it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 95/141 [00:38<00:18,  2.45it/s]\u001B[A\n",
      "Iteration:  68%|██████▊   | 96/141 [00:39<00:18,  2.45it/s]\u001B[A\n",
      "Iteration:  69%|██████▉   | 97/141 [00:39<00:17,  2.45it/s]\u001B[A\n",
      "Iteration:  70%|██████▉   | 98/141 [00:39<00:17,  2.45it/s]\u001B[A\n",
      "Iteration:  70%|███████   | 99/141 [00:40<00:17,  2.45it/s]\u001B[A\n",
      "Iteration:  71%|███████   | 100/141 [00:40<00:16,  2.45it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 101/141 [00:41<00:16,  2.45it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 102/141 [00:41<00:15,  2.44it/s]\u001B[A\n",
      "Iteration:  73%|███████▎  | 103/141 [00:41<00:15,  2.45it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 104/141 [00:42<00:15,  2.45it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 105/141 [00:42<00:14,  2.44it/s]\u001B[A\n",
      "Iteration:  75%|███████▌  | 106/141 [00:43<00:14,  2.45it/s]\u001B[A\n",
      "Iteration:  76%|███████▌  | 107/141 [00:43<00:13,  2.45it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 108/141 [00:43<00:13,  2.44it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 109/141 [00:44<00:13,  2.44it/s]\u001B[A\n",
      "Iteration:  78%|███████▊  | 110/141 [00:44<00:12,  2.45it/s]\u001B[A\n",
      "Iteration:  79%|███████▊  | 111/141 [00:45<00:12,  2.45it/s]\u001B[A\n",
      "Iteration:  79%|███████▉  | 112/141 [00:45<00:11,  2.44it/s]\u001B[A\n",
      "Iteration:  80%|████████  | 113/141 [00:46<00:11,  2.45it/s]\u001B[A\n",
      "Iteration:  81%|████████  | 114/141 [00:46<00:11,  2.45it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 115/141 [00:46<00:10,  2.45it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 116/141 [00:47<00:10,  2.45it/s]\u001B[A\n",
      "Iteration:  83%|████████▎ | 117/141 [00:47<00:09,  2.45it/s]\u001B[A\n",
      "Iteration:  84%|████████▎ | 118/141 [00:48<00:09,  2.44it/s]\u001B[A\n",
      "Iteration:  84%|████████▍ | 119/141 [00:48<00:08,  2.45it/s]\u001B[A\n",
      "Iteration:  85%|████████▌ | 120/141 [00:48<00:08,  2.45it/s]\u001B[A\n",
      "Iteration:  86%|████████▌ | 121/141 [00:49<00:08,  2.44it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 122/141 [00:49<00:07,  2.44it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 123/141 [00:50<00:07,  2.44it/s]\u001B[A\n",
      "Iteration:  88%|████████▊ | 124/141 [00:50<00:06,  2.44it/s]\u001B[A\n",
      "Iteration:  89%|████████▊ | 125/141 [00:50<00:06,  2.44it/s]\u001B[A\n",
      "Iteration:  89%|████████▉ | 126/141 [00:51<00:06,  2.44it/s]\u001B[A\n",
      "Iteration:  90%|█████████ | 127/141 [00:51<00:05,  2.44it/s]\u001B[A\n",
      "Iteration:  91%|█████████ | 128/141 [00:52<00:05,  2.44it/s]\u001B[A\n",
      "Iteration:  91%|█████████▏| 129/141 [00:52<00:04,  2.44it/s]\u001B[A\n",
      "Iteration:  92%|█████████▏| 130/141 [00:52<00:04,  2.44it/s]\u001B[A\n",
      "Iteration:  93%|█████████▎| 131/141 [00:53<00:04,  2.44it/s]\u001B[A\n",
      "Iteration:  94%|█████████▎| 132/141 [00:53<00:03,  2.44it/s]\u001B[A\n",
      "Iteration:  94%|█████████▍| 133/141 [00:54<00:03,  2.44it/s]\u001B[A\n",
      "Iteration:  95%|█████████▌| 134/141 [00:54<00:02,  2.44it/s]\u001B[A\n",
      "Iteration:  96%|█████████▌| 135/141 [00:55<00:02,  2.44it/s]\u001B[A\n",
      "Iteration:  96%|█████████▋| 136/141 [00:55<00:02,  2.44it/s]\u001B[A\n",
      "Iteration:  97%|█████████▋| 137/141 [00:55<00:01,  2.44it/s]\u001B[A\n",
      "Iteration:  98%|█████████▊| 138/141 [00:56<00:01,  2.44it/s]\u001B[A\n",
      "Iteration:  99%|█████████▊| 139/141 [00:56<00:00,  2.44it/s]\u001B[A\n",
      "Iteration:  99%|█████████▉| 140/141 [00:57<00:00,  2.44it/s]\u001B[A\n",
      "Iteration: 100%|██████████| 141/141 [00:57<00:00,  2.46it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch: 2 current training loss: 25.80581077954448\n",
      "---------------------- eval on dev -----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating:  25%|██▌       | 1/4 [00:00<00:01,  2.22it/s]\u001B[A\n",
      "Evaluating:  50%|█████     | 2/4 [00:00<00:00,  2.26it/s]\u001B[A\n",
      "Evaluating:  75%|███████▌  | 3/4 [00:01<00:00,  2.29it/s]\u001B[A\n",
      "Evaluating: 100%|██████████| 4/4 [00:01<00:00,  2.33it/s]\u001B[A\n",
      "Epoch:  13%|█▎        | 2/15 [01:59<12:55, 59.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 26.069583892822266, 'intent_precision': 0.5399785965448708, 'intent_recall': 0.5636769869135014, 'intent_f1': 0.5515733583196689, 'slot_precision': 0.6337729270880703, 'slot_recall': 0.6212481426448737, 'slot_f1': 0.6274480378179635, 'sementic_frame_acc': 0.045}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Iteration:   1%|          | 1/141 [00:00<00:53,  2.59it/s]\u001B[A\n",
      "Iteration:   1%|▏         | 2/141 [00:00<00:55,  2.52it/s]\u001B[A\n",
      "Iteration:   2%|▏         | 3/141 [00:01<00:56,  2.45it/s]\u001B[A\n",
      "Iteration:   3%|▎         | 4/141 [00:01<00:55,  2.46it/s]\u001B[A\n",
      "Iteration:   4%|▎         | 5/141 [00:02<00:55,  2.45it/s]\u001B[A\n",
      "Iteration:   4%|▍         | 6/141 [00:02<00:55,  2.45it/s]\u001B[A\n",
      "Iteration:   5%|▍         | 7/141 [00:02<00:54,  2.45it/s]\u001B[A\n",
      "Iteration:   6%|▌         | 8/141 [00:03<00:54,  2.44it/s]\u001B[A\n",
      "Iteration:   6%|▋         | 9/141 [00:03<00:54,  2.44it/s]\u001B[A\n",
      "Iteration:   7%|▋         | 10/141 [00:04<00:53,  2.44it/s]\u001B[A\n",
      "Iteration:   8%|▊         | 11/141 [00:04<00:53,  2.44it/s]\u001B[A\n",
      "Iteration:   9%|▊         | 12/141 [00:04<00:52,  2.44it/s]\u001B[A\n",
      "Iteration:   9%|▉         | 13/141 [00:05<00:52,  2.44it/s]\u001B[A\n",
      "Iteration:  10%|▉         | 14/141 [00:05<00:52,  2.44it/s]\u001B[A\n",
      "Iteration:  11%|█         | 15/141 [00:06<00:51,  2.44it/s]\u001B[A\n",
      "Iteration:  11%|█▏        | 16/141 [00:06<00:51,  2.43it/s]\u001B[A\n",
      "Iteration:  12%|█▏        | 17/141 [00:06<00:50,  2.43it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 18/141 [00:07<00:50,  2.44it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 19/141 [00:07<00:50,  2.44it/s]\u001B[A\n",
      "Iteration:  14%|█▍        | 20/141 [00:08<00:49,  2.44it/s]\u001B[A\n",
      "Iteration:  15%|█▍        | 21/141 [00:08<00:49,  2.44it/s]\u001B[A\n",
      "Iteration:  16%|█▌        | 22/141 [00:09<00:48,  2.44it/s]\u001B[A\n",
      "Iteration:  16%|█▋        | 23/141 [00:09<00:48,  2.44it/s]\u001B[A\n",
      "Iteration:  17%|█▋        | 24/141 [00:09<00:48,  2.44it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 25/141 [00:10<00:47,  2.44it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 26/141 [00:10<00:47,  2.43it/s]\u001B[A\n",
      "Iteration:  19%|█▉        | 27/141 [00:11<00:46,  2.44it/s]\u001B[A\n",
      "Iteration:  20%|█▉        | 28/141 [00:11<00:46,  2.44it/s]\u001B[A\n",
      "Iteration:  21%|██        | 29/141 [00:11<00:45,  2.44it/s]\u001B[A\n",
      "Iteration:  21%|██▏       | 30/141 [00:12<00:45,  2.44it/s]\u001B[A\n",
      "Iteration:  22%|██▏       | 31/141 [00:12<00:45,  2.44it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 32/141 [00:13<00:44,  2.43it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 33/141 [00:13<00:44,  2.44it/s]\u001B[A\n",
      "Iteration:  24%|██▍       | 34/141 [00:13<00:43,  2.43it/s]\u001B[A\n",
      "Iteration:  25%|██▍       | 35/141 [00:14<00:43,  2.44it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 36/141 [00:14<00:43,  2.44it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 37/141 [00:15<00:42,  2.44it/s]\u001B[A\n",
      "Iteration:  27%|██▋       | 38/141 [00:15<00:42,  2.44it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 39/141 [00:15<00:41,  2.44it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 40/141 [00:16<00:41,  2.44it/s]\u001B[A\n",
      "Iteration:  29%|██▉       | 41/141 [00:16<00:41,  2.43it/s]\u001B[A\n",
      "Iteration:  30%|██▉       | 42/141 [00:17<00:40,  2.43it/s]\u001B[A\n",
      "Iteration:  30%|███       | 43/141 [00:17<00:40,  2.43it/s]\u001B[A\n",
      "Iteration:  31%|███       | 44/141 [00:18<00:39,  2.43it/s]\u001B[A\n",
      "Iteration:  32%|███▏      | 45/141 [00:18<00:39,  2.43it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 46/141 [00:18<00:39,  2.43it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 47/141 [00:19<00:38,  2.42it/s]\u001B[A\n",
      "Iteration:  34%|███▍      | 48/141 [00:19<00:38,  2.43it/s]\u001B[A\n",
      "Iteration:  35%|███▍      | 49/141 [00:20<00:37,  2.43it/s]\u001B[A\n",
      "Iteration:  35%|███▌      | 50/141 [00:20<00:37,  2.43it/s]\u001B[A\n",
      "Iteration:  36%|███▌      | 51/141 [00:20<00:37,  2.43it/s]\u001B[A\n",
      "Iteration:  37%|███▋      | 52/141 [00:21<00:36,  2.42it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 53/141 [00:21<00:36,  2.43it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 54/141 [00:22<00:35,  2.43it/s]\u001B[A\n",
      "Iteration:  39%|███▉      | 55/141 [00:22<00:35,  2.43it/s]\u001B[A\n",
      "Iteration:  40%|███▉      | 56/141 [00:22<00:34,  2.43it/s]\u001B[A\n",
      "Iteration:  40%|████      | 57/141 [00:23<00:34,  2.43it/s]\u001B[A\n",
      "Iteration:  41%|████      | 58/141 [00:23<00:34,  2.43it/s]\u001B[A\n",
      "Iteration:  42%|████▏     | 59/141 [00:24<00:33,  2.43it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 60/141 [00:24<00:33,  2.43it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 61/141 [00:25<00:32,  2.43it/s]\u001B[A\n",
      "Iteration:  44%|████▍     | 62/141 [00:25<00:32,  2.43it/s]\u001B[A\n",
      "Iteration:  45%|████▍     | 63/141 [00:25<00:32,  2.43it/s]\u001B[A\n",
      "Iteration:  45%|████▌     | 64/141 [00:26<00:31,  2.43it/s]\u001B[A\n",
      "Iteration:  46%|████▌     | 65/141 [00:26<00:31,  2.43it/s]\u001B[A\n",
      "Iteration:  47%|████▋     | 66/141 [00:27<00:30,  2.43it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 67/141 [00:27<00:30,  2.43it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 68/141 [00:27<00:29,  2.43it/s]\u001B[A\n",
      "Iteration:  49%|████▉     | 69/141 [00:28<00:29,  2.43it/s]\u001B[A\n",
      "Iteration:  50%|████▉     | 70/141 [00:28<00:29,  2.43it/s]\u001B[A\n",
      "Iteration:  50%|█████     | 71/141 [00:29<00:28,  2.43it/s]\u001B[A\n",
      "Iteration:  51%|█████     | 72/141 [00:29<00:28,  2.43it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 73/141 [00:29<00:27,  2.43it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 74/141 [00:30<00:27,  2.43it/s]\u001B[A\n",
      "Iteration:  53%|█████▎    | 75/141 [00:30<00:27,  2.43it/s]\u001B[A\n",
      "Iteration:  54%|█████▍    | 76/141 [00:31<00:26,  2.43it/s]\u001B[A\n",
      "Iteration:  55%|█████▍    | 77/141 [00:31<00:26,  2.43it/s]\u001B[A\n",
      "Iteration:  55%|█████▌    | 78/141 [00:32<00:25,  2.43it/s]\u001B[A\n",
      "Iteration:  56%|█████▌    | 79/141 [00:32<00:25,  2.44it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 80/141 [00:32<00:25,  2.43it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 81/141 [00:33<00:24,  2.43it/s]\u001B[A\n",
      "Iteration:  58%|█████▊    | 82/141 [00:33<00:24,  2.44it/s]\u001B[A\n",
      "Iteration:  59%|█████▉    | 83/141 [00:34<00:23,  2.43it/s]\u001B[A\n",
      "Iteration:  60%|█████▉    | 84/141 [00:34<00:23,  2.43it/s]\u001B[A\n",
      "Iteration:  60%|██████    | 85/141 [00:34<00:23,  2.43it/s]\u001B[A\n",
      "Iteration:  61%|██████    | 86/141 [00:35<00:22,  2.43it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 87/141 [00:35<00:22,  2.43it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 88/141 [00:36<00:21,  2.43it/s]\u001B[A\n",
      "Iteration:  63%|██████▎   | 89/141 [00:36<00:21,  2.43it/s]\u001B[A\n",
      "Iteration:  64%|██████▍   | 90/141 [00:36<00:21,  2.43it/s]\u001B[A\n",
      "Iteration:  65%|██████▍   | 91/141 [00:37<00:20,  2.43it/s]\u001B[A\n",
      "Iteration:  65%|██████▌   | 92/141 [00:37<00:20,  2.43it/s]\u001B[A\n",
      "Iteration:  66%|██████▌   | 93/141 [00:38<00:19,  2.43it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 94/141 [00:38<00:19,  2.43it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 95/141 [00:39<00:18,  2.43it/s]\u001B[A\n",
      "Iteration:  68%|██████▊   | 96/141 [00:39<00:18,  2.43it/s]\u001B[A\n",
      "Iteration:  69%|██████▉   | 97/141 [00:39<00:18,  2.43it/s]\u001B[A\n",
      "Iteration:  70%|██████▉   | 98/141 [00:40<00:17,  2.43it/s]\u001B[A\n",
      "Iteration:  70%|███████   | 99/141 [00:40<00:17,  2.43it/s]\u001B[A\n",
      "Iteration:  71%|███████   | 100/141 [00:41<00:16,  2.43it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 101/141 [00:41<00:16,  2.43it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 102/141 [00:41<00:16,  2.43it/s]\u001B[A\n",
      "Iteration:  73%|███████▎  | 103/141 [00:42<00:15,  2.43it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 104/141 [00:42<00:15,  2.43it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 105/141 [00:43<00:14,  2.42it/s]\u001B[A\n",
      "Iteration:  75%|███████▌  | 106/141 [00:43<00:14,  2.43it/s]\u001B[A\n",
      "Iteration:  76%|███████▌  | 107/141 [00:43<00:14,  2.43it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 108/141 [00:44<00:13,  2.43it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 109/141 [00:44<00:13,  2.43it/s]\u001B[A\n",
      "Iteration:  78%|███████▊  | 110/141 [00:45<00:12,  2.42it/s]\u001B[A\n",
      "Iteration:  79%|███████▊  | 111/141 [00:45<00:12,  2.42it/s]\u001B[A\n",
      "Iteration:  79%|███████▉  | 112/141 [00:46<00:11,  2.43it/s]\u001B[A\n",
      "Iteration:  80%|████████  | 113/141 [00:46<00:11,  2.42it/s]\u001B[A\n",
      "Iteration:  81%|████████  | 114/141 [00:46<00:11,  2.43it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 115/141 [00:47<00:10,  2.43it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 116/141 [00:47<00:10,  2.42it/s]\u001B[A\n",
      "Iteration:  83%|████████▎ | 117/141 [00:48<00:09,  2.42it/s]\u001B[A\n",
      "Iteration:  84%|████████▎ | 118/141 [00:48<00:09,  2.43it/s]\u001B[A\n",
      "Iteration:  84%|████████▍ | 119/141 [00:48<00:09,  2.42it/s]\u001B[A\n",
      "Iteration:  85%|████████▌ | 120/141 [00:49<00:08,  2.42it/s]\u001B[A\n",
      "Iteration:  86%|████████▌ | 121/141 [00:49<00:08,  2.42it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 122/141 [00:50<00:07,  2.42it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 123/141 [00:50<00:07,  2.42it/s]\u001B[A\n",
      "Iteration:  88%|████████▊ | 124/141 [00:50<00:07,  2.42it/s]\u001B[A\n",
      "Iteration:  89%|████████▊ | 125/141 [00:51<00:06,  2.42it/s]\u001B[A\n",
      "Iteration:  89%|████████▉ | 126/141 [00:51<00:06,  2.42it/s]\u001B[A\n",
      "Iteration:  90%|█████████ | 127/141 [00:52<00:05,  2.42it/s]\u001B[A\n",
      "Iteration:  91%|█████████ | 128/141 [00:52<00:05,  2.42it/s]\u001B[A\n",
      "Iteration:  91%|█████████▏| 129/141 [00:53<00:04,  2.42it/s]\u001B[A\n",
      "Iteration:  92%|█████████▏| 130/141 [00:53<00:04,  2.42it/s]\u001B[A\n",
      "Iteration:  93%|█████████▎| 131/141 [00:53<00:04,  2.42it/s]\u001B[A\n",
      "Iteration:  94%|█████████▎| 132/141 [00:54<00:03,  2.42it/s]\u001B[A\n",
      "Iteration:  94%|█████████▍| 133/141 [00:54<00:03,  2.42it/s]\u001B[A\n",
      "Iteration:  95%|█████████▌| 134/141 [00:55<00:02,  2.42it/s]\u001B[A\n",
      "Iteration:  96%|█████████▌| 135/141 [00:55<00:02,  2.42it/s]\u001B[A\n",
      "Iteration:  96%|█████████▋| 136/141 [00:55<00:02,  2.42it/s]\u001B[A\n",
      "Iteration:  97%|█████████▋| 137/141 [00:56<00:01,  2.42it/s]\u001B[A\n",
      "Iteration:  98%|█████████▊| 138/141 [00:56<00:01,  2.42it/s]\u001B[A\n",
      "Iteration:  99%|█████████▊| 139/141 [00:57<00:00,  2.42it/s]\u001B[A\n",
      "Iteration:  99%|█████████▉| 140/141 [00:57<00:00,  2.42it/s]\u001B[A\n",
      "Iteration: 100%|██████████| 141/141 [00:57<00:00,  2.44it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch: 3 current training loss: 12.941862802978948\n",
      "---------------------- eval on dev -----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating:  25%|██▌       | 1/4 [00:00<00:01,  2.02it/s]\u001B[A\n",
      "Evaluating:  50%|█████     | 2/4 [00:00<00:00,  2.17it/s]\u001B[A\n",
      "Evaluating:  75%|███████▌  | 3/4 [00:01<00:00,  2.23it/s]\u001B[A\n",
      "Evaluating: 100%|██████████| 4/4 [00:01<00:00,  2.26it/s]\u001B[A\n",
      "Epoch:  20%|██        | 3/15 [02:59<11:59, 59.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 20.983335494995117, 'intent_precision': 0.6150475902704337, 'intent_recall': 0.6496967762527929, 'intent_f1': 0.6318975552968569, 'slot_precision': 0.6757863935625458, 'slot_recall': 0.6863298662704309, 'slot_f1': 0.6810173239955769, 'sementic_frame_acc': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Iteration:   1%|          | 1/141 [00:00<00:54,  2.56it/s]\u001B[A\n",
      "Iteration:   1%|▏         | 2/141 [00:00<00:55,  2.49it/s]\u001B[A\n",
      "Iteration:   2%|▏         | 3/141 [00:01<00:56,  2.43it/s]\u001B[A\n",
      "Iteration:   3%|▎         | 4/141 [00:01<00:56,  2.43it/s]\u001B[A\n",
      "Iteration:   4%|▎         | 5/141 [00:02<00:56,  2.43it/s]\u001B[A\n",
      "Iteration:   4%|▍         | 6/141 [00:02<00:55,  2.43it/s]\u001B[A\n",
      "Iteration:   5%|▍         | 7/141 [00:02<00:55,  2.43it/s]\u001B[A\n",
      "Iteration:   6%|▌         | 8/141 [00:03<00:54,  2.42it/s]\u001B[A\n",
      "Iteration:   6%|▋         | 9/141 [00:03<00:54,  2.42it/s]\u001B[A\n",
      "Iteration:   7%|▋         | 10/141 [00:04<00:54,  2.42it/s]\u001B[A\n",
      "Iteration:   8%|▊         | 11/141 [00:04<00:53,  2.42it/s]\u001B[A\n",
      "Iteration:   9%|▊         | 12/141 [00:04<00:53,  2.42it/s]\u001B[A\n",
      "Iteration:   9%|▉         | 13/141 [00:05<00:52,  2.42it/s]\u001B[A\n",
      "Iteration:  10%|▉         | 14/141 [00:05<00:52,  2.42it/s]\u001B[A\n",
      "Iteration:  11%|█         | 15/141 [00:06<00:52,  2.42it/s]\u001B[A\n",
      "Iteration:  11%|█▏        | 16/141 [00:06<00:51,  2.42it/s]\u001B[A\n",
      "Iteration:  12%|█▏        | 17/141 [00:07<00:51,  2.42it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 18/141 [00:07<00:50,  2.42it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 19/141 [00:07<00:50,  2.42it/s]\u001B[A\n",
      "Iteration:  14%|█▍        | 20/141 [00:08<00:50,  2.42it/s]\u001B[A\n",
      "Iteration:  15%|█▍        | 21/141 [00:08<00:49,  2.42it/s]\u001B[A\n",
      "Iteration:  16%|█▌        | 22/141 [00:09<00:49,  2.42it/s]\u001B[A\n",
      "Iteration:  16%|█▋        | 23/141 [00:09<00:48,  2.42it/s]\u001B[A\n",
      "Iteration:  17%|█▋        | 24/141 [00:09<00:48,  2.41it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 25/141 [00:10<00:47,  2.42it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 26/141 [00:10<00:47,  2.42it/s]\u001B[A\n",
      "Iteration:  19%|█▉        | 27/141 [00:11<00:47,  2.42it/s]\u001B[A\n",
      "Iteration:  20%|█▉        | 28/141 [00:11<00:46,  2.42it/s]\u001B[A\n",
      "Iteration:  21%|██        | 29/141 [00:11<00:46,  2.42it/s]\u001B[A\n",
      "Iteration:  21%|██▏       | 30/141 [00:12<00:45,  2.42it/s]\u001B[A\n",
      "Iteration:  22%|██▏       | 31/141 [00:12<00:45,  2.42it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 32/141 [00:13<00:45,  2.42it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 33/141 [00:13<00:44,  2.42it/s]\u001B[A\n",
      "Iteration:  24%|██▍       | 34/141 [00:14<00:44,  2.42it/s]\u001B[A\n",
      "Iteration:  25%|██▍       | 35/141 [00:14<00:43,  2.42it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 36/141 [00:14<00:43,  2.42it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 37/141 [00:15<00:43,  2.42it/s]\u001B[A\n",
      "Iteration:  27%|██▋       | 38/141 [00:15<00:42,  2.42it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 39/141 [00:16<00:42,  2.42it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 40/141 [00:16<00:41,  2.42it/s]\u001B[A\n",
      "Iteration:  29%|██▉       | 41/141 [00:16<00:41,  2.42it/s]\u001B[A\n",
      "Iteration:  30%|██▉       | 42/141 [00:17<00:40,  2.42it/s]\u001B[A\n",
      "Iteration:  30%|███       | 43/141 [00:17<00:40,  2.42it/s]\u001B[A\n",
      "Iteration:  31%|███       | 44/141 [00:18<00:40,  2.42it/s]\u001B[A\n",
      "Iteration:  32%|███▏      | 45/141 [00:18<00:39,  2.42it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 46/141 [00:19<00:39,  2.42it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 47/141 [00:19<00:38,  2.42it/s]\u001B[A\n",
      "Iteration:  34%|███▍      | 48/141 [00:19<00:38,  2.42it/s]\u001B[A\n",
      "Iteration:  35%|███▍      | 49/141 [00:20<00:38,  2.42it/s]\u001B[A\n",
      "Iteration:  35%|███▌      | 50/141 [00:20<00:37,  2.42it/s]\u001B[A\n",
      "Iteration:  36%|███▌      | 51/141 [00:21<00:37,  2.42it/s]\u001B[A\n",
      "Iteration:  37%|███▋      | 52/141 [00:21<00:36,  2.41it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 53/141 [00:21<00:36,  2.42it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 54/141 [00:22<00:36,  2.42it/s]\u001B[A\n",
      "Iteration:  39%|███▉      | 55/141 [00:22<00:35,  2.41it/s]\u001B[A\n",
      "Iteration:  40%|███▉      | 56/141 [00:23<00:35,  2.42it/s]\u001B[A\n",
      "Iteration:  40%|████      | 57/141 [00:23<00:34,  2.42it/s]\u001B[A\n",
      "Iteration:  41%|████      | 58/141 [00:23<00:34,  2.42it/s]\u001B[A\n",
      "Iteration:  42%|████▏     | 59/141 [00:24<00:33,  2.42it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 60/141 [00:24<00:33,  2.41it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 61/141 [00:25<00:33,  2.42it/s]\u001B[A\n",
      "Iteration:  44%|████▍     | 62/141 [00:25<00:32,  2.42it/s]\u001B[A\n",
      "Iteration:  45%|████▍     | 63/141 [00:26<00:32,  2.42it/s]\u001B[A\n",
      "Iteration:  45%|████▌     | 64/141 [00:26<00:31,  2.42it/s]\u001B[A\n",
      "Iteration:  46%|████▌     | 65/141 [00:26<00:31,  2.42it/s]\u001B[A\n",
      "Iteration:  47%|████▋     | 66/141 [00:27<00:31,  2.42it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 67/141 [00:27<00:30,  2.42it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 68/141 [00:28<00:30,  2.41it/s]\u001B[A\n",
      "Iteration:  49%|████▉     | 69/141 [00:28<00:29,  2.41it/s]\u001B[A\n",
      "Iteration:  50%|████▉     | 70/141 [00:28<00:29,  2.41it/s]\u001B[A\n",
      "Iteration:  50%|█████     | 71/141 [00:29<00:29,  2.41it/s]\u001B[A\n",
      "Iteration:  51%|█████     | 72/141 [00:29<00:28,  2.41it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 73/141 [00:30<00:28,  2.41it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 74/141 [00:30<00:27,  2.41it/s]\u001B[A\n",
      "Iteration:  53%|█████▎    | 75/141 [00:31<00:27,  2.41it/s]\u001B[A\n",
      "Iteration:  54%|█████▍    | 76/141 [00:31<00:26,  2.41it/s]\u001B[A\n",
      "Iteration:  55%|█████▍    | 77/141 [00:31<00:26,  2.41it/s]\u001B[A\n",
      "Iteration:  55%|█████▌    | 78/141 [00:32<00:26,  2.41it/s]\u001B[A\n",
      "Iteration:  56%|█████▌    | 79/141 [00:32<00:25,  2.41it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 80/141 [00:33<00:25,  2.41it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 81/141 [00:33<00:24,  2.41it/s]\u001B[A\n",
      "Iteration:  58%|█████▊    | 82/141 [00:33<00:24,  2.41it/s]\u001B[A\n",
      "Iteration:  59%|█████▉    | 83/141 [00:34<00:24,  2.41it/s]\u001B[A\n",
      "Iteration:  60%|█████▉    | 84/141 [00:34<00:23,  2.41it/s]\u001B[A\n",
      "Iteration:  60%|██████    | 85/141 [00:35<00:23,  2.41it/s]\u001B[A\n",
      "Iteration:  61%|██████    | 86/141 [00:35<00:22,  2.41it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 87/141 [00:35<00:22,  2.41it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 88/141 [00:36<00:22,  2.41it/s]\u001B[A\n",
      "Iteration:  63%|██████▎   | 89/141 [00:36<00:21,  2.41it/s]\u001B[A\n",
      "Iteration:  64%|██████▍   | 90/141 [00:37<00:21,  2.41it/s]\u001B[A\n",
      "Iteration:  65%|██████▍   | 91/141 [00:37<00:20,  2.41it/s]\u001B[A\n",
      "Iteration:  65%|██████▌   | 92/141 [00:38<00:20,  2.41it/s]\u001B[A\n",
      "Iteration:  66%|██████▌   | 93/141 [00:38<00:19,  2.41it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 94/141 [00:38<00:19,  2.41it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 95/141 [00:39<00:19,  2.41it/s]\u001B[A\n",
      "Iteration:  68%|██████▊   | 96/141 [00:39<00:18,  2.41it/s]\u001B[A\n",
      "Iteration:  69%|██████▉   | 97/141 [00:40<00:18,  2.41it/s]\u001B[A\n",
      "Iteration:  70%|██████▉   | 98/141 [00:40<00:17,  2.41it/s]\u001B[A\n",
      "Iteration:  70%|███████   | 99/141 [00:40<00:17,  2.42it/s]\u001B[A\n",
      "Iteration:  71%|███████   | 100/141 [00:41<00:16,  2.41it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 101/141 [00:41<00:16,  2.41it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 102/141 [00:42<00:16,  2.42it/s]\u001B[A\n",
      "Iteration:  73%|███████▎  | 103/141 [00:42<00:15,  2.41it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 104/141 [00:43<00:15,  2.41it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 105/141 [00:43<00:14,  2.41it/s]\u001B[A\n",
      "Iteration:  75%|███████▌  | 106/141 [00:43<00:14,  2.41it/s]\u001B[A\n",
      "Iteration:  76%|███████▌  | 107/141 [00:44<00:14,  2.41it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 108/141 [00:44<00:13,  2.41it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 109/141 [00:45<00:13,  2.41it/s]\u001B[A\n",
      "Iteration:  78%|███████▊  | 110/141 [00:45<00:12,  2.41it/s]\u001B[A\n",
      "Iteration:  79%|███████▊  | 111/141 [00:45<00:12,  2.41it/s]\u001B[A\n",
      "Iteration:  79%|███████▉  | 112/141 [00:46<00:12,  2.41it/s]\u001B[A\n",
      "Iteration:  80%|████████  | 113/141 [00:46<00:11,  2.41it/s]\u001B[A\n",
      "Iteration:  81%|████████  | 114/141 [00:47<00:11,  2.41it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 115/141 [00:47<00:10,  2.41it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 116/141 [00:48<00:10,  2.41it/s]\u001B[A\n",
      "Iteration:  83%|████████▎ | 117/141 [00:48<00:09,  2.41it/s]\u001B[A\n",
      "Iteration:  84%|████████▎ | 118/141 [00:48<00:09,  2.41it/s]\u001B[A\n",
      "Iteration:  84%|████████▍ | 119/141 [00:49<00:09,  2.41it/s]\u001B[A\n",
      "Iteration:  85%|████████▌ | 120/141 [00:49<00:08,  2.41it/s]\u001B[A\n",
      "Iteration:  86%|████████▌ | 121/141 [00:50<00:08,  2.41it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 122/141 [00:50<00:07,  2.41it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 123/141 [00:50<00:07,  2.40it/s]\u001B[A\n",
      "Iteration:  88%|████████▊ | 124/141 [00:51<00:07,  2.41it/s]\u001B[A\n",
      "Iteration:  89%|████████▊ | 125/141 [00:51<00:06,  2.41it/s]\u001B[A\n",
      "Iteration:  89%|████████▉ | 126/141 [00:52<00:06,  2.40it/s]\u001B[A\n",
      "Iteration:  90%|█████████ | 127/141 [00:52<00:05,  2.40it/s]\u001B[A\n",
      "Iteration:  91%|█████████ | 128/141 [00:53<00:05,  2.41it/s]\u001B[A\n",
      "Iteration:  91%|█████████▏| 129/141 [00:53<00:04,  2.41it/s]\u001B[A\n",
      "Iteration:  92%|█████████▏| 130/141 [00:53<00:04,  2.41it/s]\u001B[A\n",
      "Iteration:  93%|█████████▎| 131/141 [00:54<00:04,  2.41it/s]\u001B[A\n",
      "Iteration:  94%|█████████▎| 132/141 [00:54<00:03,  2.41it/s]\u001B[A\n",
      "Iteration:  94%|█████████▍| 133/141 [00:55<00:03,  2.41it/s]\u001B[A\n",
      "Iteration:  95%|█████████▌| 134/141 [00:55<00:02,  2.40it/s]\u001B[A\n",
      "Iteration:  96%|█████████▌| 135/141 [00:55<00:02,  2.41it/s]\u001B[A\n",
      "Iteration:  96%|█████████▋| 136/141 [00:56<00:02,  2.41it/s]\u001B[A\n",
      "Iteration:  97%|█████████▋| 137/141 [00:56<00:01,  2.41it/s]\u001B[A\n",
      "Iteration:  98%|█████████▊| 138/141 [00:57<00:01,  2.41it/s]\u001B[A\n",
      "Iteration:  99%|█████████▊| 139/141 [00:57<00:00,  2.41it/s]\u001B[A\n",
      "Iteration:  99%|█████████▉| 140/141 [00:57<00:00,  2.41it/s]\u001B[A\n",
      "Iteration: 100%|██████████| 141/141 [00:58<00:00,  2.42it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch: 4 current training loss: 7.427716471624713\n",
      "---------------------- eval on dev -----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating:  25%|██▌       | 1/4 [00:00<00:01,  2.20it/s]\u001B[A\n",
      "Evaluating:  50%|█████     | 2/4 [00:00<00:00,  2.22it/s]\u001B[A\n",
      "Evaluating:  75%|███████▌  | 3/4 [00:01<00:00,  2.26it/s]\u001B[A\n",
      "Evaluating: 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]\u001B[A\n",
      "Epoch:  27%|██▋       | 4/15 [04:00<11:03, 60.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 17.019968032836914, 'intent_precision': 0.7098021026592455, 'intent_recall': 0.7326843281200127, 'intent_f1': 0.721061724517041, 'slot_precision': 0.7471876850207223, 'slot_recall': 0.750074294205052, 'slot_f1': 0.7486282070295122, 'sementic_frame_acc': 0.122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Iteration:   1%|          | 1/141 [00:00<00:55,  2.54it/s]\u001B[A\n",
      "Iteration:   1%|▏         | 2/141 [00:00<00:56,  2.48it/s]\u001B[A\n",
      "Iteration:   2%|▏         | 3/141 [00:01<00:57,  2.41it/s]\u001B[A\n",
      "Iteration:   3%|▎         | 4/141 [00:01<00:56,  2.41it/s]\u001B[A\n",
      "Iteration:   4%|▎         | 5/141 [00:02<00:56,  2.41it/s]\u001B[A\n",
      "Iteration:   4%|▍         | 6/141 [00:02<00:55,  2.41it/s]\u001B[A\n",
      "Iteration:   5%|▍         | 7/141 [00:02<00:55,  2.42it/s]\u001B[A\n",
      "Iteration:   6%|▌         | 8/141 [00:03<00:55,  2.41it/s]\u001B[A\n",
      "Iteration:   6%|▋         | 9/141 [00:03<00:54,  2.41it/s]\u001B[A\n",
      "Iteration:   7%|▋         | 10/141 [00:04<00:54,  2.41it/s]\u001B[A\n",
      "Iteration:   8%|▊         | 11/141 [00:04<00:53,  2.41it/s]\u001B[A\n",
      "Iteration:   9%|▊         | 12/141 [00:04<00:53,  2.41it/s]\u001B[A\n",
      "Iteration:   9%|▉         | 13/141 [00:05<00:52,  2.42it/s]\u001B[A\n",
      "Iteration:  10%|▉         | 14/141 [00:05<00:52,  2.41it/s]\u001B[A\n",
      "Iteration:  11%|█         | 15/141 [00:06<00:52,  2.42it/s]\u001B[A\n",
      "Iteration:  11%|█▏        | 16/141 [00:06<00:51,  2.41it/s]\u001B[A\n",
      "Iteration:  12%|█▏        | 17/141 [00:07<00:51,  2.41it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 18/141 [00:07<00:51,  2.41it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 19/141 [00:07<00:50,  2.41it/s]\u001B[A\n",
      "Iteration:  14%|█▍        | 20/141 [00:08<00:50,  2.41it/s]\u001B[A\n",
      "Iteration:  15%|█▍        | 21/141 [00:08<00:49,  2.41it/s]\u001B[A\n",
      "Iteration:  16%|█▌        | 22/141 [00:09<00:49,  2.41it/s]\u001B[A\n",
      "Iteration:  16%|█▋        | 23/141 [00:09<00:48,  2.41it/s]\u001B[A\n",
      "Iteration:  17%|█▋        | 24/141 [00:09<00:48,  2.41it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 25/141 [00:10<00:48,  2.41it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 26/141 [00:10<00:47,  2.41it/s]\u001B[A\n",
      "Iteration:  19%|█▉        | 27/141 [00:11<00:47,  2.41it/s]\u001B[A\n",
      "Iteration:  20%|█▉        | 28/141 [00:11<00:46,  2.41it/s]\u001B[A\n",
      "Iteration:  21%|██        | 29/141 [00:12<00:46,  2.41it/s]\u001B[A\n",
      "Iteration:  21%|██▏       | 30/141 [00:12<00:46,  2.41it/s]\u001B[A\n",
      "Iteration:  22%|██▏       | 31/141 [00:12<00:45,  2.41it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 32/141 [00:13<00:45,  2.41it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 33/141 [00:13<00:44,  2.41it/s]\u001B[A\n",
      "Iteration:  24%|██▍       | 34/141 [00:14<00:44,  2.41it/s]\u001B[A\n",
      "Iteration:  25%|██▍       | 35/141 [00:14<00:43,  2.42it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 36/141 [00:14<00:43,  2.41it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 37/141 [00:15<00:43,  2.41it/s]\u001B[A\n",
      "Iteration:  27%|██▋       | 38/141 [00:15<00:42,  2.41it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 39/141 [00:16<00:42,  2.41it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 40/141 [00:16<00:41,  2.41it/s]\u001B[A\n",
      "Iteration:  29%|██▉       | 41/141 [00:16<00:41,  2.41it/s]\u001B[A\n",
      "Iteration:  30%|██▉       | 42/141 [00:17<00:41,  2.41it/s]\u001B[A\n",
      "Iteration:  30%|███       | 43/141 [00:17<00:40,  2.41it/s]\u001B[A\n",
      "Iteration:  31%|███       | 44/141 [00:18<00:40,  2.41it/s]\u001B[A\n",
      "Iteration:  32%|███▏      | 45/141 [00:18<00:39,  2.41it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 46/141 [00:19<00:39,  2.41it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 47/141 [00:19<00:38,  2.41it/s]\u001B[A\n",
      "Iteration:  34%|███▍      | 48/141 [00:19<00:38,  2.41it/s]\u001B[A\n",
      "Iteration:  35%|███▍      | 49/141 [00:20<00:38,  2.41it/s]\u001B[A\n",
      "Iteration:  35%|███▌      | 50/141 [00:20<00:37,  2.41it/s]\u001B[A\n",
      "Iteration:  36%|███▌      | 51/141 [00:21<00:37,  2.41it/s]\u001B[A\n",
      "Iteration:  37%|███▋      | 52/141 [00:21<00:36,  2.41it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 53/141 [00:21<00:36,  2.41it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 54/141 [00:22<00:36,  2.41it/s]\u001B[A\n",
      "Iteration:  39%|███▉      | 55/141 [00:22<00:35,  2.41it/s]\u001B[A\n",
      "Iteration:  40%|███▉      | 56/141 [00:23<00:35,  2.41it/s]\u001B[A\n",
      "Iteration:  40%|████      | 57/141 [00:23<00:34,  2.41it/s]\u001B[A\n",
      "Iteration:  41%|████      | 58/141 [00:24<00:34,  2.41it/s]\u001B[A\n",
      "Iteration:  42%|████▏     | 59/141 [00:24<00:34,  2.41it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 60/141 [00:24<00:33,  2.41it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 61/141 [00:25<00:33,  2.41it/s]\u001B[A\n",
      "Iteration:  44%|████▍     | 62/141 [00:25<00:32,  2.41it/s]\u001B[A\n",
      "Iteration:  45%|████▍     | 63/141 [00:26<00:32,  2.41it/s]\u001B[A\n",
      "Iteration:  45%|████▌     | 64/141 [00:26<00:31,  2.41it/s]\u001B[A\n",
      "Iteration:  46%|████▌     | 65/141 [00:26<00:32,  2.35it/s]\u001B[A\n",
      "Iteration:  47%|████▋     | 66/141 [00:27<00:31,  2.38it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 67/141 [00:27<00:31,  2.37it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 68/141 [00:28<00:30,  2.38it/s]\u001B[A\n",
      "Iteration:  49%|████▉     | 69/141 [00:28<00:30,  2.39it/s]\u001B[A\n",
      "Iteration:  50%|████▉     | 70/141 [00:29<00:29,  2.39it/s]\u001B[A\n",
      "Iteration:  50%|█████     | 71/141 [00:29<00:29,  2.40it/s]\u001B[A\n",
      "Iteration:  51%|█████     | 72/141 [00:29<00:28,  2.40it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 73/141 [00:30<00:28,  2.40it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 74/141 [00:30<00:27,  2.41it/s]\u001B[A\n",
      "Iteration:  53%|█████▎    | 75/141 [00:31<00:27,  2.40it/s]\u001B[A\n",
      "Iteration:  54%|█████▍    | 76/141 [00:31<00:27,  2.41it/s]\u001B[A\n",
      "Iteration:  55%|█████▍    | 77/141 [00:31<00:26,  2.41it/s]\u001B[A\n",
      "Iteration:  55%|█████▌    | 78/141 [00:32<00:26,  2.41it/s]\u001B[A\n",
      "Iteration:  56%|█████▌    | 79/141 [00:32<00:25,  2.41it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 80/141 [00:33<00:25,  2.40it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 81/141 [00:33<00:24,  2.41it/s]\u001B[A\n",
      "Iteration:  58%|█████▊    | 82/141 [00:34<00:24,  2.41it/s]\u001B[A\n",
      "Iteration:  59%|█████▉    | 83/141 [00:34<00:24,  2.41it/s]\u001B[A\n",
      "Iteration:  60%|█████▉    | 84/141 [00:34<00:23,  2.41it/s]\u001B[A\n",
      "Iteration:  60%|██████    | 85/141 [00:35<00:23,  2.41it/s]\u001B[A\n",
      "Iteration:  61%|██████    | 86/141 [00:35<00:22,  2.40it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 87/141 [00:36<00:22,  2.41it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 88/141 [00:36<00:22,  2.41it/s]\u001B[A\n",
      "Iteration:  63%|██████▎   | 89/141 [00:36<00:21,  2.41it/s]\u001B[A\n",
      "Iteration:  64%|██████▍   | 90/141 [00:37<00:21,  2.41it/s]\u001B[A\n",
      "Iteration:  65%|██████▍   | 91/141 [00:37<00:20,  2.41it/s]\u001B[A\n",
      "Iteration:  65%|██████▌   | 92/141 [00:38<00:20,  2.41it/s]\u001B[A\n",
      "Iteration:  66%|██████▌   | 93/141 [00:38<00:19,  2.41it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 94/141 [00:39<00:19,  2.41it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 95/141 [00:39<00:19,  2.41it/s]\u001B[A\n",
      "Iteration:  68%|██████▊   | 96/141 [00:39<00:18,  2.41it/s]\u001B[A\n",
      "Iteration:  69%|██████▉   | 97/141 [00:40<00:18,  2.41it/s]\u001B[A\n",
      "Iteration:  70%|██████▉   | 98/141 [00:40<00:17,  2.41it/s]\u001B[A\n",
      "Iteration:  70%|███████   | 99/141 [00:41<00:17,  2.41it/s]\u001B[A\n",
      "Iteration:  71%|███████   | 100/141 [00:41<00:17,  2.41it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 101/141 [00:41<00:16,  2.41it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 102/141 [00:42<00:16,  2.41it/s]\u001B[A\n",
      "Iteration:  73%|███████▎  | 103/141 [00:42<00:15,  2.41it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 104/141 [00:43<00:15,  2.41it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 105/141 [00:43<00:14,  2.41it/s]\u001B[A\n",
      "Iteration:  75%|███████▌  | 106/141 [00:44<00:14,  2.41it/s]\u001B[A\n",
      "Iteration:  76%|███████▌  | 107/141 [00:44<00:14,  2.41it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 108/141 [00:44<00:13,  2.41it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 109/141 [00:45<00:13,  2.41it/s]\u001B[A\n",
      "Iteration:  78%|███████▊  | 110/141 [00:45<00:12,  2.41it/s]\u001B[A\n",
      "Iteration:  79%|███████▊  | 111/141 [00:46<00:12,  2.41it/s]\u001B[A\n",
      "Iteration:  79%|███████▉  | 112/141 [00:46<00:12,  2.41it/s]\u001B[A\n",
      "Iteration:  80%|████████  | 113/141 [00:46<00:11,  2.41it/s]\u001B[A\n",
      "Iteration:  81%|████████  | 114/141 [00:47<00:11,  2.41it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 115/141 [00:47<00:10,  2.41it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 116/141 [00:48<00:10,  2.41it/s]\u001B[A\n",
      "Iteration:  83%|████████▎ | 117/141 [00:48<00:09,  2.41it/s]\u001B[A\n",
      "Iteration:  84%|████████▎ | 118/141 [00:48<00:09,  2.41it/s]\u001B[A\n",
      "Iteration:  84%|████████▍ | 119/141 [00:49<00:09,  2.41it/s]\u001B[A\n",
      "Iteration:  85%|████████▌ | 120/141 [00:49<00:08,  2.41it/s]\u001B[A\n",
      "Iteration:  86%|████████▌ | 121/141 [00:50<00:08,  2.41it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 122/141 [00:50<00:07,  2.41it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 123/141 [00:51<00:07,  2.41it/s]\u001B[A\n",
      "Iteration:  88%|████████▊ | 124/141 [00:51<00:07,  2.41it/s]\u001B[A\n",
      "Iteration:  89%|████████▊ | 125/141 [00:51<00:06,  2.41it/s]\u001B[A\n",
      "Iteration:  89%|████████▉ | 126/141 [00:52<00:06,  2.41it/s]\u001B[A\n",
      "Iteration:  90%|█████████ | 127/141 [00:52<00:05,  2.41it/s]\u001B[A\n",
      "Iteration:  91%|█████████ | 128/141 [00:53<00:05,  2.41it/s]\u001B[A\n",
      "Iteration:  91%|█████████▏| 129/141 [00:53<00:04,  2.41it/s]\u001B[A\n",
      "Iteration:  92%|█████████▏| 130/141 [00:53<00:04,  2.41it/s]\u001B[A\n",
      "Iteration:  93%|█████████▎| 131/141 [00:54<00:04,  2.41it/s]\u001B[A\n",
      "Iteration:  94%|█████████▎| 132/141 [00:54<00:03,  2.41it/s]\u001B[A\n",
      "Iteration:  94%|█████████▍| 133/141 [00:55<00:03,  2.40it/s]\u001B[A\n",
      "Iteration:  95%|█████████▌| 134/141 [00:55<00:02,  2.40it/s]\u001B[A\n",
      "Iteration:  96%|█████████▌| 135/141 [00:56<00:02,  2.41it/s]\u001B[A\n",
      "Iteration:  96%|█████████▋| 136/141 [00:56<00:02,  2.41it/s]\u001B[A\n",
      "Iteration:  97%|█████████▋| 137/141 [00:56<00:01,  2.41it/s]\u001B[A\n",
      "Iteration:  98%|█████████▊| 138/141 [00:57<00:01,  2.41it/s]\u001B[A\n",
      "Iteration:  99%|█████████▊| 139/141 [00:57<00:00,  2.41it/s]\u001B[A\n",
      "Iteration:  99%|█████████▉| 140/141 [00:58<00:00,  2.41it/s]\u001B[A\n",
      "Iteration: 100%|██████████| 141/141 [00:58<00:00,  2.41it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch: 5 current training loss: 4.784399238884026\n",
      "---------------------- eval on dev -----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating:  25%|██▌       | 1/4 [00:00<00:01,  2.19it/s]\u001B[A\n",
      "Evaluating:  50%|█████     | 2/4 [00:00<00:00,  2.23it/s]\u001B[A\n",
      "Evaluating:  75%|███████▌  | 3/4 [00:01<00:00,  2.27it/s]\u001B[A\n",
      "Evaluating: 100%|██████████| 4/4 [00:01<00:00,  2.30it/s]\u001B[A\n",
      "Epoch:  33%|███▎      | 5/15 [05:01<10:04, 60.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 15.86423110961914, 'intent_precision': 0.728520746567947, 'intent_recall': 0.7537503989786147, 'intent_f1': 0.7409208565377675, 'slot_precision': 0.7726475745178258, 'slot_recall': 0.7857355126300148, 'slot_f1': 0.7791365846471195, 'sementic_frame_acc': 0.151}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Iteration:   1%|          | 1/141 [00:00<00:54,  2.56it/s]\u001B[A\n",
      "Iteration:   1%|▏         | 2/141 [00:00<00:55,  2.49it/s]\u001B[A\n",
      "Iteration:   2%|▏         | 3/141 [00:01<00:57,  2.42it/s]\u001B[A\n",
      "Iteration:   3%|▎         | 4/141 [00:01<00:56,  2.42it/s]\u001B[A\n",
      "Iteration:   4%|▎         | 5/141 [00:02<00:56,  2.42it/s]\u001B[A\n",
      "Iteration:   4%|▍         | 6/141 [00:02<00:55,  2.42it/s]\u001B[A\n",
      "Iteration:   5%|▍         | 7/141 [00:02<00:55,  2.42it/s]\u001B[A\n",
      "Iteration:   6%|▌         | 8/141 [00:03<00:55,  2.42it/s]\u001B[A\n",
      "Iteration:   6%|▋         | 9/141 [00:03<00:54,  2.41it/s]\u001B[A\n",
      "Iteration:   7%|▋         | 10/141 [00:04<00:54,  2.41it/s]\u001B[A\n",
      "Iteration:   8%|▊         | 11/141 [00:04<00:54,  2.41it/s]\u001B[A\n",
      "Iteration:   9%|▊         | 12/141 [00:04<00:53,  2.41it/s]\u001B[A\n",
      "Iteration:   9%|▉         | 13/141 [00:05<00:53,  2.41it/s]\u001B[A\n",
      "Iteration:  10%|▉         | 14/141 [00:05<00:52,  2.41it/s]\u001B[A\n",
      "Iteration:  11%|█         | 15/141 [00:06<00:52,  2.41it/s]\u001B[A\n",
      "Iteration:  11%|█▏        | 16/141 [00:06<00:51,  2.41it/s]\u001B[A\n",
      "Iteration:  12%|█▏        | 17/141 [00:07<00:51,  2.41it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 18/141 [00:07<00:50,  2.41it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 19/141 [00:07<00:50,  2.41it/s]\u001B[A\n",
      "Iteration:  14%|█▍        | 20/141 [00:08<00:50,  2.41it/s]\u001B[A\n",
      "Iteration:  15%|█▍        | 21/141 [00:08<00:49,  2.42it/s]\u001B[A\n",
      "Iteration:  16%|█▌        | 22/141 [00:09<00:49,  2.42it/s]\u001B[A\n",
      "Iteration:  16%|█▋        | 23/141 [00:09<00:48,  2.41it/s]\u001B[A\n",
      "Iteration:  17%|█▋        | 24/141 [00:09<00:48,  2.41it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 25/141 [00:10<00:48,  2.41it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 26/141 [00:10<00:47,  2.41it/s]\u001B[A\n",
      "Iteration:  19%|█▉        | 27/141 [00:11<00:47,  2.41it/s]\u001B[A\n",
      "Iteration:  20%|█▉        | 28/141 [00:11<00:46,  2.42it/s]\u001B[A\n",
      "Iteration:  21%|██        | 29/141 [00:11<00:46,  2.42it/s]\u001B[A\n",
      "Iteration:  21%|██▏       | 30/141 [00:12<00:45,  2.41it/s]\u001B[A\n",
      "Iteration:  22%|██▏       | 31/141 [00:12<00:45,  2.42it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 32/141 [00:13<00:45,  2.42it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 33/141 [00:13<00:44,  2.42it/s]\u001B[A\n",
      "Iteration:  24%|██▍       | 34/141 [00:14<00:44,  2.41it/s]\u001B[A\n",
      "Iteration:  25%|██▍       | 35/141 [00:14<00:43,  2.41it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 36/141 [00:14<00:43,  2.42it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 37/141 [00:15<00:43,  2.41it/s]\u001B[A\n",
      "Iteration:  27%|██▋       | 38/141 [00:15<00:42,  2.41it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 39/141 [00:16<00:42,  2.41it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 40/141 [00:16<00:41,  2.41it/s]\u001B[A\n",
      "Iteration:  29%|██▉       | 41/141 [00:16<00:41,  2.41it/s]\u001B[A\n",
      "Iteration:  30%|██▉       | 42/141 [00:17<00:40,  2.42it/s]\u001B[A\n",
      "Iteration:  30%|███       | 43/141 [00:17<00:40,  2.41it/s]\u001B[A\n",
      "Iteration:  31%|███       | 44/141 [00:18<00:40,  2.42it/s]\u001B[A\n",
      "Iteration:  32%|███▏      | 45/141 [00:18<00:39,  2.41it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 46/141 [00:19<00:39,  2.41it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 47/141 [00:19<00:38,  2.42it/s]\u001B[A\n",
      "Iteration:  34%|███▍      | 48/141 [00:19<00:38,  2.42it/s]\u001B[A\n",
      "Iteration:  35%|███▍      | 49/141 [00:20<00:38,  2.42it/s]\u001B[A\n",
      "Iteration:  35%|███▌      | 50/141 [00:20<00:37,  2.41it/s]\u001B[A\n",
      "Iteration:  36%|███▌      | 51/141 [00:21<00:37,  2.42it/s]\u001B[A\n",
      "Iteration:  37%|███▋      | 52/141 [00:21<00:36,  2.41it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 53/141 [00:21<00:36,  2.42it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 54/141 [00:22<00:36,  2.41it/s]\u001B[A\n",
      "Iteration:  39%|███▉      | 55/141 [00:22<00:35,  2.41it/s]\u001B[A\n",
      "Iteration:  40%|███▉      | 56/141 [00:23<00:35,  2.41it/s]\u001B[A\n",
      "Iteration:  40%|████      | 57/141 [00:23<00:34,  2.41it/s]\u001B[A\n",
      "Iteration:  41%|████      | 58/141 [00:24<00:34,  2.41it/s]\u001B[A\n",
      "Iteration:  42%|████▏     | 59/141 [00:24<00:33,  2.41it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 60/141 [00:24<00:33,  2.42it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 61/141 [00:25<00:33,  2.41it/s]\u001B[A\n",
      "Iteration:  44%|████▍     | 62/141 [00:25<00:32,  2.41it/s]\u001B[A\n",
      "Iteration:  45%|████▍     | 63/141 [00:26<00:32,  2.41it/s]\u001B[A\n",
      "Iteration:  45%|████▌     | 64/141 [00:26<00:31,  2.41it/s]\u001B[A\n",
      "Iteration:  46%|████▌     | 65/141 [00:26<00:31,  2.41it/s]\u001B[A\n",
      "Iteration:  47%|████▋     | 66/141 [00:27<00:31,  2.41it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 67/141 [00:27<00:30,  2.41it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 68/141 [00:28<00:30,  2.40it/s]\u001B[A\n",
      "Iteration:  49%|████▉     | 69/141 [00:28<00:29,  2.41it/s]\u001B[A\n",
      "Iteration:  50%|████▉     | 70/141 [00:28<00:29,  2.41it/s]\u001B[A\n",
      "Iteration:  50%|█████     | 71/141 [00:29<00:29,  2.40it/s]\u001B[A\n",
      "Iteration:  51%|█████     | 72/141 [00:29<00:28,  2.40it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 73/141 [00:30<00:28,  2.41it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 74/141 [00:30<00:27,  2.41it/s]\u001B[A\n",
      "Iteration:  53%|█████▎    | 75/141 [00:31<00:27,  2.41it/s]\u001B[A\n",
      "Iteration:  54%|█████▍    | 76/141 [00:31<00:27,  2.41it/s]\u001B[A\n",
      "Iteration:  55%|█████▍    | 77/141 [00:31<00:26,  2.41it/s]\u001B[A\n",
      "Iteration:  55%|█████▌    | 78/141 [00:32<00:26,  2.41it/s]\u001B[A\n",
      "Iteration:  56%|█████▌    | 79/141 [00:32<00:25,  2.41it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 80/141 [00:33<00:25,  2.41it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 81/141 [00:33<00:24,  2.41it/s]\u001B[A\n",
      "Iteration:  58%|█████▊    | 82/141 [00:33<00:24,  2.41it/s]\u001B[A\n",
      "Iteration:  59%|█████▉    | 83/141 [00:34<00:24,  2.41it/s]\u001B[A\n",
      "Iteration:  60%|█████▉    | 84/141 [00:34<00:23,  2.40it/s]\u001B[A\n",
      "Iteration:  60%|██████    | 85/141 [00:35<00:23,  2.41it/s]\u001B[A\n",
      "Iteration:  61%|██████    | 86/141 [00:35<00:22,  2.41it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 87/141 [00:36<00:22,  2.41it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 88/141 [00:36<00:22,  2.41it/s]\u001B[A\n",
      "Iteration:  63%|██████▎   | 89/141 [00:36<00:21,  2.41it/s]\u001B[A\n",
      "Iteration:  64%|██████▍   | 90/141 [00:37<00:21,  2.41it/s]\u001B[A\n",
      "Iteration:  65%|██████▍   | 91/141 [00:37<00:20,  2.40it/s]\u001B[A\n",
      "Iteration:  65%|██████▌   | 92/141 [00:38<00:20,  2.40it/s]\u001B[A\n",
      "Iteration:  66%|██████▌   | 93/141 [00:38<00:19,  2.40it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 94/141 [00:38<00:19,  2.40it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 95/141 [00:39<00:19,  2.40it/s]\u001B[A\n",
      "Iteration:  68%|██████▊   | 96/141 [00:39<00:18,  2.40it/s]\u001B[A\n",
      "Iteration:  69%|██████▉   | 97/141 [00:40<00:18,  2.40it/s]\u001B[A\n",
      "Iteration:  70%|██████▉   | 98/141 [00:40<00:17,  2.40it/s]\u001B[A\n",
      "Iteration:  70%|███████   | 99/141 [00:41<00:17,  2.41it/s]\u001B[A\n",
      "Iteration:  71%|███████   | 100/141 [00:41<00:17,  2.41it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 101/141 [00:41<00:16,  2.41it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 102/141 [00:42<00:16,  2.41it/s]\u001B[A\n",
      "Iteration:  73%|███████▎  | 103/141 [00:42<00:15,  2.41it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 104/141 [00:43<00:15,  2.41it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 105/141 [00:43<00:14,  2.41it/s]\u001B[A\n",
      "Iteration:  75%|███████▌  | 106/141 [00:43<00:14,  2.41it/s]\u001B[A\n",
      "Iteration:  76%|███████▌  | 107/141 [00:44<00:14,  2.41it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 108/141 [00:44<00:13,  2.41it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 109/141 [00:45<00:13,  2.40it/s]\u001B[A\n",
      "Iteration:  78%|███████▊  | 110/141 [00:45<00:12,  2.40it/s]\u001B[A\n",
      "Iteration:  79%|███████▊  | 111/141 [00:46<00:12,  2.40it/s]\u001B[A\n",
      "Iteration:  79%|███████▉  | 112/141 [00:46<00:12,  2.40it/s]\u001B[A\n",
      "Iteration:  80%|████████  | 113/141 [00:46<00:11,  2.40it/s]\u001B[A\n",
      "Iteration:  81%|████████  | 114/141 [00:47<00:11,  2.40it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 115/141 [00:47<00:10,  2.40it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 116/141 [00:48<00:10,  2.40it/s]\u001B[A\n",
      "Iteration:  83%|████████▎ | 117/141 [00:48<00:09,  2.40it/s]\u001B[A\n",
      "Iteration:  84%|████████▎ | 118/141 [00:48<00:09,  2.40it/s]\u001B[A\n",
      "Iteration:  84%|████████▍ | 119/141 [00:49<00:09,  2.40it/s]\u001B[A\n",
      "Iteration:  85%|████████▌ | 120/141 [00:49<00:08,  2.40it/s]\u001B[A\n",
      "Iteration:  86%|████████▌ | 121/141 [00:50<00:08,  2.40it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 122/141 [00:50<00:07,  2.40it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 123/141 [00:51<00:07,  2.40it/s]\u001B[A\n",
      "Iteration:  88%|████████▊ | 124/141 [00:51<00:07,  2.40it/s]\u001B[A\n",
      "Iteration:  89%|████████▊ | 125/141 [00:51<00:06,  2.40it/s]\u001B[A\n",
      "Iteration:  89%|████████▉ | 126/141 [00:52<00:06,  2.40it/s]\u001B[A\n",
      "Iteration:  90%|█████████ | 127/141 [00:52<00:05,  2.40it/s]\u001B[A\n",
      "Iteration:  91%|█████████ | 128/141 [00:53<00:05,  2.40it/s]\u001B[A\n",
      "Iteration:  91%|█████████▏| 129/141 [00:53<00:04,  2.40it/s]\u001B[A\n",
      "Iteration:  92%|█████████▏| 130/141 [00:53<00:04,  2.40it/s]\u001B[A\n",
      "Iteration:  93%|█████████▎| 131/141 [00:54<00:04,  2.40it/s]\u001B[A\n",
      "Iteration:  94%|█████████▎| 132/141 [00:54<00:03,  2.40it/s]\u001B[A\n",
      "Iteration:  94%|█████████▍| 133/141 [00:55<00:03,  2.40it/s]\u001B[A\n",
      "Iteration:  95%|█████████▌| 134/141 [00:55<00:02,  2.40it/s]\u001B[A\n",
      "Iteration:  96%|█████████▌| 135/141 [00:56<00:02,  2.40it/s]\u001B[A\n",
      "Iteration:  96%|█████████▋| 136/141 [00:56<00:02,  2.40it/s]\u001B[A\n",
      "Iteration:  97%|█████████▋| 137/141 [00:56<00:01,  2.40it/s]\u001B[A\n",
      "Iteration:  98%|█████████▊| 138/141 [00:57<00:01,  2.40it/s]\u001B[A\n",
      "Iteration:  99%|█████████▊| 139/141 [00:57<00:00,  2.40it/s]\u001B[A\n",
      "Iteration:  99%|█████████▉| 140/141 [00:58<00:00,  2.40it/s]\u001B[A\n",
      "Iteration: 100%|██████████| 141/141 [00:58<00:00,  2.41it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch: 6 current training loss: 3.455097612759746\n",
      "---------------------- eval on dev -----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating:  25%|██▌       | 1/4 [00:00<00:01,  2.18it/s]\u001B[A\n",
      "Evaluating:  50%|█████     | 2/4 [00:00<00:00,  2.21it/s]\u001B[A\n",
      "Evaluating:  75%|███████▌  | 3/4 [00:01<00:00,  2.25it/s]\u001B[A\n",
      "Evaluating: 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]\u001B[A\n",
      "Epoch:  40%|████      | 6/15 [06:02<09:05, 60.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 14.722254753112793, 'intent_precision': 0.7628526645768025, 'intent_recall': 0.7767315671879987, 'intent_f1': 0.7697295587537561, 'slot_precision': 0.7785683171192102, 'slot_recall': 0.7967310549777117, 'slot_f1': 0.7875449805390321, 'sementic_frame_acc': 0.161}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Iteration:   1%|          | 1/141 [00:00<00:54,  2.58it/s]\u001B[A\n",
      "Iteration:   1%|▏         | 2/141 [00:00<00:55,  2.49it/s]\u001B[A\n",
      "Iteration:   2%|▏         | 3/141 [00:01<00:57,  2.41it/s]\u001B[A\n",
      "Iteration:   3%|▎         | 4/141 [00:01<00:56,  2.42it/s]\u001B[A\n",
      "Iteration:   4%|▎         | 5/141 [00:02<00:56,  2.41it/s]\u001B[A\n",
      "Iteration:   4%|▍         | 6/141 [00:02<00:56,  2.41it/s]\u001B[A\n",
      "Iteration:   5%|▍         | 7/141 [00:02<00:57,  2.35it/s]\u001B[A\n",
      "Iteration:   6%|▌         | 8/141 [00:03<00:56,  2.37it/s]\u001B[A\n",
      "Iteration:   6%|▋         | 9/141 [00:03<00:55,  2.36it/s]\u001B[A\n",
      "Iteration:   7%|▋         | 10/141 [00:04<00:54,  2.38it/s]\u001B[A\n",
      "Iteration:   8%|▊         | 11/141 [00:04<00:54,  2.39it/s]\u001B[A\n",
      "Iteration:   9%|▊         | 12/141 [00:05<00:53,  2.39it/s]\u001B[A\n",
      "Iteration:   9%|▉         | 13/141 [00:05<00:53,  2.40it/s]\u001B[A\n",
      "Iteration:  10%|▉         | 14/141 [00:05<00:53,  2.40it/s]\u001B[A\n",
      "Iteration:  11%|█         | 15/141 [00:06<00:52,  2.40it/s]\u001B[A\n",
      "Iteration:  11%|█▏        | 16/141 [00:06<00:52,  2.40it/s]\u001B[A\n",
      "Iteration:  12%|█▏        | 17/141 [00:07<00:51,  2.40it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 18/141 [00:07<00:51,  2.40it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 19/141 [00:07<00:50,  2.40it/s]\u001B[A\n",
      "Iteration:  14%|█▍        | 20/141 [00:08<00:50,  2.40it/s]\u001B[A\n",
      "Iteration:  15%|█▍        | 21/141 [00:08<00:50,  2.40it/s]\u001B[A\n",
      "Iteration:  16%|█▌        | 22/141 [00:09<00:49,  2.40it/s]\u001B[A\n",
      "Iteration:  16%|█▋        | 23/141 [00:09<00:49,  2.40it/s]\u001B[A\n",
      "Iteration:  17%|█▋        | 24/141 [00:10<00:48,  2.40it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 25/141 [00:10<00:48,  2.40it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 26/141 [00:10<00:48,  2.40it/s]\u001B[A\n",
      "Iteration:  19%|█▉        | 27/141 [00:11<00:47,  2.40it/s]\u001B[A\n",
      "Iteration:  20%|█▉        | 28/141 [00:11<00:47,  2.40it/s]\u001B[A\n",
      "Iteration:  21%|██        | 29/141 [00:12<00:46,  2.40it/s]\u001B[A\n",
      "Iteration:  21%|██▏       | 30/141 [00:12<00:46,  2.40it/s]\u001B[A\n",
      "Iteration:  22%|██▏       | 31/141 [00:12<00:45,  2.40it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 32/141 [00:13<00:45,  2.40it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 33/141 [00:13<00:44,  2.40it/s]\u001B[A\n",
      "Iteration:  24%|██▍       | 34/141 [00:14<00:44,  2.40it/s]\u001B[A\n",
      "Iteration:  25%|██▍       | 35/141 [00:14<00:44,  2.40it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 36/141 [00:15<00:43,  2.40it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 37/141 [00:15<00:43,  2.40it/s]\u001B[A\n",
      "Iteration:  27%|██▋       | 38/141 [00:15<00:42,  2.40it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 39/141 [00:16<00:42,  2.41it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 40/141 [00:16<00:41,  2.41it/s]\u001B[A\n",
      "Iteration:  29%|██▉       | 41/141 [00:17<00:41,  2.41it/s]\u001B[A\n",
      "Iteration:  30%|██▉       | 42/141 [00:17<00:41,  2.40it/s]\u001B[A\n",
      "Iteration:  30%|███       | 43/141 [00:17<00:40,  2.40it/s]\u001B[A\n",
      "Iteration:  31%|███       | 44/141 [00:18<00:40,  2.40it/s]\u001B[A\n",
      "Iteration:  32%|███▏      | 45/141 [00:18<00:39,  2.40it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 46/141 [00:19<00:39,  2.40it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 47/141 [00:19<00:39,  2.40it/s]\u001B[A\n",
      "Iteration:  34%|███▍      | 48/141 [00:19<00:38,  2.40it/s]\u001B[A\n",
      "Iteration:  35%|███▍      | 49/141 [00:20<00:38,  2.40it/s]\u001B[A\n",
      "Iteration:  35%|███▌      | 50/141 [00:20<00:37,  2.40it/s]\u001B[A\n",
      "Iteration:  36%|███▌      | 51/141 [00:21<00:37,  2.40it/s]\u001B[A\n",
      "Iteration:  37%|███▋      | 52/141 [00:21<00:37,  2.40it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 53/141 [00:22<00:36,  2.40it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 54/141 [00:22<00:36,  2.40it/s]\u001B[A\n",
      "Iteration:  39%|███▉      | 55/141 [00:22<00:35,  2.40it/s]\u001B[A\n",
      "Iteration:  40%|███▉      | 56/141 [00:23<00:35,  2.40it/s]\u001B[A\n",
      "Iteration:  40%|████      | 57/141 [00:23<00:35,  2.40it/s]\u001B[A\n",
      "Iteration:  41%|████      | 58/141 [00:24<00:34,  2.40it/s]\u001B[A\n",
      "Iteration:  42%|████▏     | 59/141 [00:24<00:34,  2.40it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 60/141 [00:24<00:33,  2.40it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 61/141 [00:25<00:33,  2.40it/s]\u001B[A\n",
      "Iteration:  44%|████▍     | 62/141 [00:25<00:32,  2.40it/s]\u001B[A\n",
      "Iteration:  45%|████▍     | 63/141 [00:26<00:32,  2.40it/s]\u001B[A\n",
      "Iteration:  45%|████▌     | 64/141 [00:26<00:32,  2.40it/s]\u001B[A\n",
      "Iteration:  46%|████▌     | 65/141 [00:27<00:31,  2.40it/s]\u001B[A\n",
      "Iteration:  47%|████▋     | 66/141 [00:27<00:31,  2.40it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 67/141 [00:27<00:30,  2.40it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 68/141 [00:28<00:30,  2.40it/s]\u001B[A\n",
      "Iteration:  49%|████▉     | 69/141 [00:28<00:29,  2.40it/s]\u001B[A\n",
      "Iteration:  50%|████▉     | 70/141 [00:29<00:29,  2.40it/s]\u001B[A\n",
      "Iteration:  50%|█████     | 71/141 [00:29<00:29,  2.40it/s]\u001B[A\n",
      "Iteration:  51%|█████     | 72/141 [00:29<00:28,  2.40it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 73/141 [00:30<00:28,  2.40it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 74/141 [00:30<00:27,  2.40it/s]\u001B[A\n",
      "Iteration:  53%|█████▎    | 75/141 [00:31<00:27,  2.40it/s]\u001B[A\n",
      "Iteration:  54%|█████▍    | 76/141 [00:31<00:27,  2.40it/s]\u001B[A\n",
      "Iteration:  55%|█████▍    | 77/141 [00:32<00:26,  2.41it/s]\u001B[A\n",
      "Iteration:  55%|█████▌    | 78/141 [00:32<00:26,  2.41it/s]\u001B[A\n",
      "Iteration:  56%|█████▌    | 79/141 [00:32<00:25,  2.40it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 80/141 [00:33<00:25,  2.40it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 81/141 [00:33<00:24,  2.40it/s]\u001B[A\n",
      "Iteration:  58%|█████▊    | 82/141 [00:34<00:24,  2.40it/s]\u001B[A\n",
      "Iteration:  59%|█████▉    | 83/141 [00:34<00:24,  2.41it/s]\u001B[A\n",
      "Iteration:  60%|█████▉    | 84/141 [00:34<00:23,  2.40it/s]\u001B[A\n",
      "Iteration:  60%|██████    | 85/141 [00:35<00:23,  2.40it/s]\u001B[A\n",
      "Iteration:  61%|██████    | 86/141 [00:35<00:22,  2.40it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 87/141 [00:36<00:22,  2.40it/s]\u001B[A\n",
      "Iteration:  62%|██████▏   | 88/141 [00:36<00:22,  2.40it/s]\u001B[A\n",
      "Iteration:  63%|██████▎   | 89/141 [00:37<00:21,  2.40it/s]\u001B[A\n",
      "Iteration:  64%|██████▍   | 90/141 [00:37<00:21,  2.40it/s]\u001B[A\n",
      "Iteration:  65%|██████▍   | 91/141 [00:37<00:20,  2.40it/s]\u001B[A\n",
      "Iteration:  65%|██████▌   | 92/141 [00:38<00:20,  2.40it/s]\u001B[A\n",
      "Iteration:  66%|██████▌   | 93/141 [00:38<00:19,  2.40it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 94/141 [00:39<00:19,  2.40it/s]\u001B[A\n",
      "Iteration:  67%|██████▋   | 95/141 [00:39<00:19,  2.41it/s]\u001B[A\n",
      "Iteration:  68%|██████▊   | 96/141 [00:39<00:18,  2.41it/s]\u001B[A\n",
      "Iteration:  69%|██████▉   | 97/141 [00:40<00:18,  2.40it/s]\u001B[A\n",
      "Iteration:  70%|██████▉   | 98/141 [00:40<00:17,  2.40it/s]\u001B[A\n",
      "Iteration:  70%|███████   | 99/141 [00:41<00:17,  2.40it/s]\u001B[A\n",
      "Iteration:  71%|███████   | 100/141 [00:41<00:17,  2.40it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 101/141 [00:42<00:16,  2.40it/s]\u001B[A\n",
      "Iteration:  72%|███████▏  | 102/141 [00:42<00:16,  2.41it/s]\u001B[A\n",
      "Iteration:  73%|███████▎  | 103/141 [00:42<00:15,  2.40it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 104/141 [00:43<00:15,  2.40it/s]\u001B[A\n",
      "Iteration:  74%|███████▍  | 105/141 [00:43<00:14,  2.40it/s]\u001B[A\n",
      "Iteration:  75%|███████▌  | 106/141 [00:44<00:14,  2.40it/s]\u001B[A\n",
      "Iteration:  76%|███████▌  | 107/141 [00:44<00:14,  2.40it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 108/141 [00:44<00:13,  2.40it/s]\u001B[A\n",
      "Iteration:  77%|███████▋  | 109/141 [00:45<00:13,  2.40it/s]\u001B[A\n",
      "Iteration:  78%|███████▊  | 110/141 [00:45<00:12,  2.40it/s]\u001B[A\n",
      "Iteration:  79%|███████▊  | 111/141 [00:46<00:12,  2.40it/s]\u001B[A\n",
      "Iteration:  79%|███████▉  | 112/141 [00:46<00:12,  2.40it/s]\u001B[A\n",
      "Iteration:  80%|████████  | 113/141 [00:47<00:11,  2.40it/s]\u001B[A\n",
      "Iteration:  81%|████████  | 114/141 [00:47<00:11,  2.40it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 115/141 [00:47<00:10,  2.40it/s]\u001B[A\n",
      "Iteration:  82%|████████▏ | 116/141 [00:48<00:10,  2.40it/s]\u001B[A\n",
      "Iteration:  83%|████████▎ | 117/141 [00:48<00:09,  2.40it/s]\u001B[A\n",
      "Iteration:  84%|████████▎ | 118/141 [00:49<00:09,  2.40it/s]\u001B[A\n",
      "Iteration:  84%|████████▍ | 119/141 [00:49<00:09,  2.40it/s]\u001B[A\n",
      "Iteration:  85%|████████▌ | 120/141 [00:49<00:08,  2.40it/s]\u001B[A\n",
      "Iteration:  86%|████████▌ | 121/141 [00:50<00:08,  2.40it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 122/141 [00:50<00:07,  2.40it/s]\u001B[A\n",
      "Iteration:  87%|████████▋ | 123/141 [00:51<00:07,  2.40it/s]\u001B[A\n",
      "Iteration:  88%|████████▊ | 124/141 [00:51<00:07,  2.40it/s]\u001B[A\n",
      "Iteration:  89%|████████▊ | 125/141 [00:52<00:06,  2.40it/s]\u001B[A\n",
      "Iteration:  89%|████████▉ | 126/141 [00:52<00:06,  2.40it/s]\u001B[A\n",
      "Iteration:  90%|█████████ | 127/141 [00:52<00:05,  2.40it/s]\u001B[A\n",
      "Iteration:  91%|█████████ | 128/141 [00:53<00:05,  2.40it/s]\u001B[A\n",
      "Iteration:  91%|█████████▏| 129/141 [00:53<00:05,  2.40it/s]\u001B[A\n",
      "Iteration:  92%|█████████▏| 130/141 [00:54<00:04,  2.40it/s]\u001B[A\n",
      "Iteration:  93%|█████████▎| 131/141 [00:54<00:04,  2.40it/s]\u001B[A\n",
      "Iteration:  94%|█████████▎| 132/141 [00:54<00:03,  2.41it/s]\u001B[A\n",
      "Iteration:  94%|█████████▍| 133/141 [00:55<00:03,  2.40it/s]\u001B[A\n",
      "Iteration:  95%|█████████▌| 134/141 [00:55<00:02,  2.40it/s]\u001B[A\n",
      "Iteration:  96%|█████████▌| 135/141 [00:56<00:02,  2.40it/s]\u001B[A\n",
      "Iteration:  96%|█████████▋| 136/141 [00:56<00:02,  2.40it/s]\u001B[A\n",
      "Iteration:  97%|█████████▋| 137/141 [00:57<00:01,  2.40it/s]\u001B[A\n",
      "Iteration:  98%|█████████▊| 138/141 [00:57<00:01,  2.40it/s]\u001B[A\n",
      "Iteration:  99%|█████████▊| 139/141 [00:57<00:00,  2.40it/s]\u001B[A\n",
      "Iteration:  99%|█████████▉| 140/141 [00:58<00:00,  2.40it/s]\u001B[A\n",
      "Iteration: 100%|██████████| 141/141 [00:58<00:00,  2.41it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch: 7 current training loss: 2.5793861573469554\n",
      "---------------------- eval on dev -----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      "Evaluating:  25%|██▌       | 1/4 [00:00<00:01,  2.18it/s]\u001B[A\n",
      "Evaluating:  50%|█████     | 2/4 [00:00<00:00,  2.21it/s]\u001B[A\n",
      "Evaluating:  75%|███████▌  | 3/4 [00:01<00:00,  2.25it/s]\u001B[A\n",
      "Evaluating: 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]\u001B[A\n",
      "Epoch:  47%|████▋     | 7/15 [07:03<08:06, 60.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.053539276123047, 'intent_precision': 0.7946875, 'intent_recall': 0.8116820938397702, 'intent_f1': 0.8030948997315649, 'slot_precision': 0.8066968855095774, 'slot_recall': 0.8197622585438336, 'slot_f1': 0.8131770948485518, 'sementic_frame_acc': 0.212}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Iteration:   1%|          | 1/141 [00:00<00:54,  2.56it/s]\u001B[A\n",
      "Iteration:   1%|▏         | 2/141 [00:00<00:56,  2.48it/s]\u001B[A\n",
      "Iteration:   2%|▏         | 3/141 [00:01<00:57,  2.41it/s]\u001B[A\n",
      "Iteration:   3%|▎         | 4/141 [00:01<00:56,  2.41it/s]\u001B[A\n",
      "Iteration:   4%|▎         | 5/141 [00:02<00:56,  2.40it/s]\u001B[A\n",
      "Iteration:   4%|▍         | 6/141 [00:02<00:56,  2.40it/s]\u001B[A\n",
      "Iteration:   5%|▍         | 7/141 [00:02<00:55,  2.40it/s]\u001B[A\n",
      "Iteration:   6%|▌         | 8/141 [00:03<00:55,  2.40it/s]\u001B[A\n",
      "Iteration:   6%|▋         | 9/141 [00:03<00:54,  2.40it/s]\u001B[A\n",
      "Iteration:   7%|▋         | 10/141 [00:04<00:54,  2.40it/s]\u001B[A\n",
      "Iteration:   8%|▊         | 11/141 [00:04<00:54,  2.40it/s]\u001B[A\n",
      "Iteration:   9%|▊         | 12/141 [00:04<00:53,  2.40it/s]\u001B[A\n",
      "Iteration:   9%|▉         | 13/141 [00:05<00:53,  2.40it/s]\u001B[A\n",
      "Iteration:  10%|▉         | 14/141 [00:05<00:52,  2.40it/s]\u001B[A\n",
      "Iteration:  11%|█         | 15/141 [00:06<00:52,  2.40it/s]\u001B[A\n",
      "Iteration:  11%|█▏        | 16/141 [00:06<00:52,  2.40it/s]\u001B[A\n",
      "Iteration:  12%|█▏        | 17/141 [00:07<00:51,  2.40it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 18/141 [00:07<00:51,  2.40it/s]\u001B[A\n",
      "Iteration:  13%|█▎        | 19/141 [00:07<00:50,  2.40it/s]\u001B[A\n",
      "Iteration:  14%|█▍        | 20/141 [00:08<00:50,  2.41it/s]\u001B[A\n",
      "Iteration:  15%|█▍        | 21/141 [00:08<00:49,  2.40it/s]\u001B[A\n",
      "Iteration:  16%|█▌        | 22/141 [00:09<00:49,  2.40it/s]\u001B[A\n",
      "Iteration:  16%|█▋        | 23/141 [00:09<00:49,  2.40it/s]\u001B[A\n",
      "Iteration:  17%|█▋        | 24/141 [00:09<00:48,  2.40it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 25/141 [00:10<00:48,  2.40it/s]\u001B[A\n",
      "Iteration:  18%|█▊        | 26/141 [00:10<00:47,  2.40it/s]\u001B[A\n",
      "Iteration:  19%|█▉        | 27/141 [00:11<00:47,  2.40it/s]\u001B[A\n",
      "Iteration:  20%|█▉        | 28/141 [00:11<00:47,  2.40it/s]\u001B[A\n",
      "Iteration:  21%|██        | 29/141 [00:12<00:46,  2.40it/s]\u001B[A\n",
      "Iteration:  21%|██▏       | 30/141 [00:12<00:46,  2.40it/s]\u001B[A\n",
      "Iteration:  22%|██▏       | 31/141 [00:12<00:45,  2.40it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 32/141 [00:13<00:45,  2.41it/s]\u001B[A\n",
      "Iteration:  23%|██▎       | 33/141 [00:13<00:44,  2.40it/s]\u001B[A\n",
      "Iteration:  24%|██▍       | 34/141 [00:14<00:44,  2.40it/s]\u001B[A\n",
      "Iteration:  25%|██▍       | 35/141 [00:14<00:44,  2.40it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 36/141 [00:14<00:43,  2.40it/s]\u001B[A\n",
      "Iteration:  26%|██▌       | 37/141 [00:15<00:43,  2.40it/s]\u001B[A\n",
      "Iteration:  27%|██▋       | 38/141 [00:15<00:42,  2.40it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 39/141 [00:16<00:42,  2.40it/s]\u001B[A\n",
      "Iteration:  28%|██▊       | 40/141 [00:16<00:42,  2.40it/s]\u001B[A\n",
      "Iteration:  29%|██▉       | 41/141 [00:17<00:41,  2.40it/s]\u001B[A\n",
      "Iteration:  30%|██▉       | 42/141 [00:17<00:41,  2.40it/s]\u001B[A\n",
      "Iteration:  30%|███       | 43/141 [00:17<00:40,  2.40it/s]\u001B[A\n",
      "Iteration:  31%|███       | 44/141 [00:18<00:40,  2.40it/s]\u001B[A\n",
      "Iteration:  32%|███▏      | 45/141 [00:18<00:39,  2.40it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 46/141 [00:19<00:39,  2.40it/s]\u001B[A\n",
      "Iteration:  33%|███▎      | 47/141 [00:19<00:39,  2.40it/s]\u001B[A\n",
      "Iteration:  34%|███▍      | 48/141 [00:19<00:38,  2.40it/s]\u001B[A\n",
      "Iteration:  35%|███▍      | 49/141 [00:20<00:38,  2.41it/s]\u001B[A\n",
      "Iteration:  35%|███▌      | 50/141 [00:20<00:37,  2.40it/s]\u001B[A\n",
      "Iteration:  36%|███▌      | 51/141 [00:21<00:37,  2.40it/s]\u001B[A\n",
      "Iteration:  37%|███▋      | 52/141 [00:21<00:37,  2.40it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 53/141 [00:22<00:36,  2.40it/s]\u001B[A\n",
      "Iteration:  38%|███▊      | 54/141 [00:22<00:36,  2.40it/s]\u001B[A\n",
      "Iteration:  39%|███▉      | 55/141 [00:22<00:35,  2.40it/s]\u001B[A\n",
      "Iteration:  40%|███▉      | 56/141 [00:23<00:35,  2.40it/s]\u001B[A\n",
      "Iteration:  40%|████      | 57/141 [00:23<00:34,  2.40it/s]\u001B[A\n",
      "Iteration:  41%|████      | 58/141 [00:24<00:34,  2.40it/s]\u001B[A\n",
      "Iteration:  42%|████▏     | 59/141 [00:24<00:34,  2.40it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 60/141 [00:24<00:33,  2.40it/s]\u001B[A\n",
      "Iteration:  43%|████▎     | 61/141 [00:25<00:33,  2.40it/s]\u001B[A\n",
      "Iteration:  44%|████▍     | 62/141 [00:25<00:32,  2.40it/s]\u001B[A\n",
      "Iteration:  45%|████▍     | 63/141 [00:26<00:32,  2.40it/s]\u001B[A\n",
      "Iteration:  45%|████▌     | 64/141 [00:26<00:32,  2.40it/s]\u001B[A\n",
      "Iteration:  46%|████▌     | 65/141 [00:27<00:31,  2.40it/s]\u001B[A\n",
      "Iteration:  47%|████▋     | 66/141 [00:27<00:31,  2.40it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 67/141 [00:27<00:30,  2.40it/s]\u001B[A\n",
      "Iteration:  48%|████▊     | 68/141 [00:28<00:30,  2.40it/s]\u001B[A\n",
      "Iteration:  49%|████▉     | 69/141 [00:28<00:30,  2.40it/s]\u001B[A\n",
      "Iteration:  50%|████▉     | 70/141 [00:29<00:29,  2.40it/s]\u001B[A\n",
      "Iteration:  50%|█████     | 71/141 [00:29<00:29,  2.40it/s]\u001B[A\n",
      "Iteration:  51%|█████     | 72/141 [00:29<00:28,  2.40it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 73/141 [00:30<00:28,  2.40it/s]\u001B[A\n",
      "Iteration:  52%|█████▏    | 74/141 [00:30<00:27,  2.40it/s]\u001B[A\n",
      "Iteration:  53%|█████▎    | 75/141 [00:31<00:27,  2.40it/s]\u001B[A\n",
      "Iteration:  54%|█████▍    | 76/141 [00:31<00:27,  2.40it/s]\u001B[A\n",
      "Iteration:  55%|█████▍    | 77/141 [00:32<00:26,  2.39it/s]\u001B[A\n",
      "Iteration:  55%|█████▌    | 78/141 [00:32<00:26,  2.40it/s]\u001B[A\n",
      "Iteration:  56%|█████▌    | 79/141 [00:32<00:25,  2.40it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 80/141 [00:33<00:25,  2.40it/s]\u001B[A\n",
      "Iteration:  57%|█████▋    | 81/141 [00:33<00:25,  2.40it/s]\u001B[A\n",
      "Iteration:  58%|█████▊    | 82/141 [00:34<00:24,  2.40it/s]\u001B[A\n",
      "Iteration:  59%|█████▉    | 83/141 [00:34<00:24,  2.40it/s]\u001B[A\n",
      "Iteration:  60%|█████▉    | 84/141 [00:34<00:23,  2.40it/s]\u001B[A"
     ]
    }
   ],
   "source": [
    "from data_loader import load_and_cache_examples\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, args, train_dataset=None, dev_dataset=None, test_dataset=None):\n",
    "        self.args = args\n",
    "        self.train_dataset = train_dataset\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "        config_class, model_class, _ = MODEL_CLASSES[args.model_type]\n",
    "        config = config_class.from_pretrained(args.model_name_or_path, finetuning_task=args.task)\n",
    "\n",
    "        self.intent_dict = {i:label for i,label in enumerate(get_intent_labels(args))}\n",
    "        self.slot_dict = {i:label for i,label in enumerate(get_slot_labels(args))}\n",
    "\n",
    "        self.num_intent_labels = len(self.intent_dict)\n",
    "        self.num_slot_labels = len(self.slot_dict)\n",
    "\n",
    "        self.model = JSF_Seg(self.args,config, self.num_intent_labels, self.num_slot_labels)\n",
    "\n",
    "        # GPU or CPU\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # self.loss_function = nn.CrossEntropyLoss(ignore_index=self.args.ignore_index)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def get_losses(self, outputs,slot_label,intent_label):\n",
    "        loss = 0\n",
    "        for token_idx in range(outputs.shape[2]): # shape[2]: iterate through token level\n",
    "            # true\n",
    "            intent_true = intent_label[:,token_idx]\n",
    "            slot_true = slot_label[:,token_idx]\n",
    "\n",
    "            # preds\n",
    "            intent_pred_one_hot = self.get_token_preds(outputs,token_idx, one_hot = True)['token_intent_pred']\n",
    "            slot_pred_one_hot = self.get_token_preds(outputs,token_idx, one_hot = True)['token_slot_pred']\n",
    "\n",
    "            # seperate losses\n",
    "            intent_loss = self.loss_function(intent_pred_one_hot.float(),intent_true.long())\n",
    "            slot_loss = self.loss_function(slot_pred_one_hot.float(),slot_true.long())\n",
    "\n",
    "            # accumulate them to total loss\n",
    "            loss += intent_loss + slot_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    # get the token level prediction of the slot and\n",
    "    def get_token_preds(self,outputs,token_idx, one_hot = True):\n",
    "        token_pred = outputs[:,:,token_idx] #token_pred in shape: 64x17\n",
    "\n",
    "        # get current token intention one-hot pred\n",
    "        out_intent_pos = self.num_intent_labels\n",
    "        token_intent_pred = token_pred[:,:out_intent_pos]\n",
    "\n",
    "        start_slot_pos = self.num_intent_labels\n",
    "        token_slot_pred = token_pred[:,start_slot_pos:]\n",
    "\n",
    "        if one_hot:\n",
    "            # size of BATCH_SIZE * MAX_SEN_LEN\n",
    "            return {'token_intent_pred':token_intent_pred, 'token_slot_pred':token_slot_pred}\n",
    "\n",
    "        else:\n",
    "            prediction_intent = torch.argmax(token_intent_pred, dim = 1)\n",
    "            prediction_slot = torch.argmax(token_slot_pred, dim = 1)\n",
    "            return {'token_intent_pred':prediction_intent, 'token_slot_pred':prediction_slot}\n",
    "\n",
    "\n",
    "    # get the setence level prediction of all the slots and intents\n",
    "    # output: dict of sentence slot and intent labels lst\n",
    "    def get_sentence_preds(self, outputs):\n",
    "        # print(outputs[:,:self.num_intent_labels,:].shape)\n",
    "        # print(outputs[:,self.num_intent_labels:,:].shape)\n",
    "        batch_intent_pred = torch.argmax(outputs[:,:self.num_intent_labels,:], dim = 1).detach().cpu().tolist()# size 64 * 32\n",
    "        start_slot_pos = self.num_intent_labels\n",
    "\n",
    "        # print(f'outputs[:,start_slot_pos:,:][0]: {outputs[:,start_slot_pos:,:][0]}')\n",
    "        batch_slot_pred = torch.argmax(outputs[:,start_slot_pos:,:], dim = 1).detach().cpu().tolist()# size 64 * 32\n",
    "        # print(f'batch_slot_pred[0]:  {batch_slot_pred[0]}')\n",
    "        # print(f'batch_slot_pred shape: {len(batch_slot_pred)} x {len(batch_slot_pred[0])}')\n",
    "\n",
    "\n",
    "        intent_pred_labels = [[self.intent_dict[id] for id in sentence] for sentence in batch_intent_pred]\n",
    "        slot_pred_labels = [[self.slot_dict[id] for id in sentence] for sentence in batch_slot_pred]\n",
    "\n",
    "        return {'slot_sentence_pred':slot_pred_labels, 'intent_sentence_pred':intent_pred_labels}\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        train_sampler = RandomSampler(self.train_dataset)\n",
    "        train_dataloader = DataLoader(self.train_dataset, sampler=train_sampler, batch_size=self.args.train_batch_size)\n",
    "\n",
    "        if self.args.max_steps > 0:\n",
    "            t_total = self.args.max_steps\n",
    "            self.args.num_train_epochs = self.args.max_steps // (len(train_dataloader) // self.args.gradient_accumulation_steps) + 1\n",
    "        else:\n",
    "            t_total = len(train_dataloader) // self.args.gradient_accumulation_steps * self.args.num_train_epochs\n",
    "\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': self.args.weight_decay},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate, eps=self.args.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=self.args.warmup_steps, num_training_steps=t_total)\n",
    "\n",
    "        # Train!\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(self.train_dataset))\n",
    "        logger.info(\"  Num Epochs = %d\", self.args.num_train_epochs)\n",
    "        logger.info(\"  Total train batch size = %d\", self.args.train_batch_size)\n",
    "        logger.info(\"  Gradient Accumulation steps = %d\", self.args.gradient_accumulation_steps)\n",
    "        logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "        logger.info(\"  Logging steps = %d\", self.args.logging_steps)\n",
    "        logger.info(\"  Save steps = %d\", self.args.save_steps)\n",
    "\n",
    "\n",
    "        global_step = 0\n",
    "        tr_loss = 0.0\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        train_iterator = trange(int(self.args.num_train_epochs), desc=\"Epoch\")\n",
    "\n",
    "        for n_ep,_ in enumerate(train_iterator):\n",
    "            ep_loss = 0.0\n",
    "            ep_step = 0\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "            for step, batch in enumerate(epoch_iterator):\n",
    "                ep_step += 1\n",
    "                self.model.train()\n",
    "                batch = tuple(t.to(self.device) for t in batch)  # GPU or CPU\n",
    "\n",
    "                inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'token_type_ids' : batch[2]}\n",
    "\n",
    "                outputs = self.model(**inputs) #outpus size: [64, 17, 32]\n",
    "                ################################ define loss ################################\n",
    "                #could do a token-level CE loss or a sentence mask level IoU or DIce score or fiscal\n",
    "\n",
    "                #intent loss\n",
    "                loss = 0\n",
    "\n",
    "                slot_label = batch[4]\n",
    "                intent_label = batch[5]\n",
    "\n",
    "                # accumulate current loss to total loss\n",
    "                loss += self.get_losses(outputs,slot_label,intent_label)\n",
    "\n",
    "                if self.args.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "                loss.backward()\n",
    "                tr_loss += loss.item()\n",
    "                ep_loss += loss.item()\n",
    "\n",
    "                if (step + 1) % self.args.gradient_accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()  # Update learning rate schedule\n",
    "                    self.model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "\n",
    "                    # if self.args.logging_steps > 0 and global_step % self.args.logging_steps == 0:\n",
    "                    #     continue\n",
    "                    #     self.evaluate(\"dev\")\n",
    "\n",
    "                    # if self.args.save_steps > 0 and global_step % self.args.save_steps == 0:\n",
    "                    #     self.save_model()\n",
    "\n",
    "                if 0 < self.args.max_steps < global_step:\n",
    "                    epoch_iterator.close()\n",
    "                    break\n",
    "\n",
    "            if 0 < self.args.max_steps < global_step:\n",
    "                train_iterator.close()\n",
    "                break\n",
    "\n",
    "            print(f'training epoch: {n_ep + 1} current training loss: {ep_loss / ep_step}')\n",
    "            print('---------------------- eval on dev -----------------------------')\n",
    "            print(self.evaluate(\"dev\"))\n",
    "        return global_step, tr_loss / global_step\n",
    "\n",
    "    ######################################################################## EVAL ########################################################################\n",
    "    def evaluate(self, mode):\n",
    "        if mode == 'test':\n",
    "            dataset = self.test_dataset\n",
    "        elif mode == 'dev':\n",
    "            dataset = self.dev_dataset\n",
    "        else:\n",
    "            raise Exception(\"Only dev and test dataset available\")\n",
    "\n",
    "        eval_sampler = SequentialSampler(dataset)\n",
    "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.args.eval_batch_size)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation on %s dataset *****\", mode)\n",
    "        logger.info(\"  Num examples = %d\", len(dataset))\n",
    "        logger.info(\"  Batch size = %d\", self.args.eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        #self.model.eval()\n",
    "\n",
    "        # init pred/true lists\n",
    "        slot_sentence_pred = []\n",
    "        intent_sentence_pred = []\n",
    "        true_slot_label = []\n",
    "        true_intent_label  = []\n",
    "\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            batch = tuple(t.to(self.device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {'input_ids': batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids' : batch[2]}\n",
    "                outputs = self.model(**inputs)\n",
    "\n",
    "                slot_label = batch[4]\n",
    "                intent_label = batch[5]\n",
    "                eval_loss += self.get_losses(outputs,slot_label,intent_label)\n",
    "\n",
    "                #print pred labels\n",
    "                sentence_pred_dict = self.get_sentence_preds(outputs)\n",
    "\n",
    "                slot_sentence_pred.extend(sentence_pred_dict['slot_sentence_pred'])\n",
    "                intent_sentence_pred.extend(sentence_pred_dict['intent_sentence_pred'])\n",
    "\n",
    "                true_slot_label.extend( [[self.slot_dict[id] for id in sentence]for sentence in slot_label.tolist()])\n",
    "                true_intent_label.extend( [[self.intent_dict[id] for id in sentence]for sentence in intent_label.tolist()])\n",
    "\n",
    "                # print(f'true_slot_label: {true_slot_label[0]}')\n",
    "                # print(f'slot_sentence_pred: {slot_sentence_pred[0]}\\n')\n",
    "                #\n",
    "                # print(f'true_intent_label: {true_intent_label[0]}')\n",
    "                # print(f'intent_sentence_pred: {intent_sentence_pred[0]}\\n')\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        eval_loss = eval_loss.item() / nb_eval_steps\n",
    "        results = {\n",
    "            \"loss\": eval_loss\n",
    "        }\n",
    "\n",
    "        #string labels\n",
    "        slot_preds_list = slot_sentence_pred\n",
    "        out_slot_label_list = true_slot_label\n",
    "\n",
    "        intent_preds_list = intent_sentence_pred\n",
    "        out_intent_label_list = true_intent_label\n",
    "\n",
    "        # compute metrics\n",
    "        the_results = compute_metrics(intent_preds_list, out_intent_label_list,slot_preds_list, out_slot_label_list)\n",
    "\n",
    "        results.update(the_results)\n",
    "\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(results.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(results[key]))\n",
    "\n",
    "        return results\n",
    "\n",
    "train_dataset = load_and_cache_examples(args, tokenizer, mode=\"train\")\n",
    "dev_dataset = load_and_cache_examples(args, tokenizer, mode=\"dev\")\n",
    "test_dataset = load_and_cache_examples(args, tokenizer, mode=\"test\")\n",
    "trainer = Trainer(args,  train_dataset, dev_dataset,  test_dataset)\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.evaluate('test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "jointbert",
   "language": "python",
   "display_name": "jointbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
