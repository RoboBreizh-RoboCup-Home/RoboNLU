{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from transformers.modeling_bert import BertPreTrainedModel, BertModel, BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertModel, BertConfig\n",
    "# from torchcrf import CRF\n",
    "from TorchCRF import CRF\n",
    "from module import IntentClassifier, SlotClassifier, IntentTokenClassifier, MultiIntentClassifier, TagIntentClassifier\n",
    "import logging\n",
    "\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import argparse\n",
    "from utils import init_logger, load_tokenizer, read_prediction_text, set_seed, MODEL_CLASSES, MODEL_PATH_MAP, get_intent_labels, get_slot_labels\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "\n",
    "# logger = logging.getLogger()\n",
    "logging.basicConfig(filename='log.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointBERTMultiIntent(BertPreTrainedModel):\n",
    "    # multi_intent: 1,\n",
    "    # intent_seq: 1,\n",
    "    # tag_intent: 1,\n",
    "    # bi_tag: 1,\n",
    "    # cls_token_cat: 1,\n",
    "    # intent_attn: 1,\n",
    "    # num_mask: 4\n",
    "    def __init__(self, config, args, intent_label_lst, slot_label_lst):\n",
    "        super().__init__(config)\n",
    "        self.args = args\n",
    "        self.max_seq_len = args.max_seq_len\n",
    "        self.num_intent_labels = len(intent_label_lst)\n",
    "        self.num_slot_labels = len(slot_label_lst)\n",
    "        # load pretrain bert\n",
    "        self.bert = BertModel(config=config)\n",
    "        \n",
    "        self.slot_label_lst = slot_label_lst\n",
    "        self.intent_label_lst = intent_label_lst\n",
    "        \n",
    "        self.slot_label_map = {i: label for i, label in enumerate(self.slot_label_lst)}\n",
    "        \n",
    "        # Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later\n",
    "        self.pad_token_label_id = args.ignore_index\n",
    "\n",
    "        # self.intent_classifier = IntentClassifier(config.hidden_size, self.num_intent_labels, args.dropout_rate)\n",
    "        self.multi_intent_classifier = MultiIntentClassifier(config.hidden_size, self.num_intent_labels, args.dropout_rate)\n",
    "        self.slot_classifier = SlotClassifier(config.hidden_size, self.num_slot_labels, args.dropout_rate)\n",
    "        if args.intent_seq:\n",
    "            self.intent_token_classifier = IntentTokenClassifier(config.hidden_size, self.num_intent_labels, args.dropout_rate)\n",
    "        \n",
    "        if args.tag_intent:\n",
    "            if args.cls_token_cat:\n",
    "                self.tag_intent_classifier = TagIntentClassifier(2 * config.hidden_size, self.num_intent_labels, args.dropout_rate)\n",
    "            else:\n",
    "                self.tag_intent_classifier = TagIntentClassifier(config.hidden_size, self.num_intent_labels, args.dropout_rate)\n",
    "        \n",
    "        if args.use_crf:\n",
    "            self.crf = CRF(num_tags=self.num_slot_labels, batch_first=True)\n",
    "            \n",
    "    def slot_pred(self, slot_preds, slot_logits):\n",
    "        if slot_preds is None:\n",
    "            if self.args.use_crf:\n",
    "                # decode() in `torchcrf` returns list with best index directly\n",
    "                slot_preds = np.array(self.model.crf.decode(slot_logits))\n",
    "            else:\n",
    "                slot_preds = slot_logits.detach().cpu().numpy()\n",
    "\n",
    "        else:\n",
    "            if self.args.use_crf:\n",
    "                slot_preds = np.append(slot_preds, np.array(self.model.crf.decode(slot_logits)), axis=0)\n",
    "            else:\n",
    "                slot_preds = np.append(slot_preds, slot_logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        if not self.args.use_crf:\n",
    "            slot_preds = np.argmax(slot_preds, axis=2)\n",
    "            \n",
    "        return slot_preds\n",
    "\n",
    "    \n",
    "    def intent_pred(self,intent_preds,intent_logits):\n",
    "        if intent_preds is None:\n",
    "            intent_preds = intent_logits.detach().cpu().numpy()\n",
    "        else:\n",
    "            intent_preds = np.append(intent_preds, intent_logits.detach().cpu().numpy(), axis=0)\n",
    "            \n",
    "        return  intent_preds\n",
    "    \n",
    "    def intent_token_pred(self,intent_token_preds, intent_token_logits):\n",
    "        if self.args.intent_seq:\n",
    "            if intent_token_preds is None:\n",
    "                if self.args.use_crf:\n",
    "                    intent_token_preds = np.array(self.model.crf.decode(intent_token_logits))\n",
    "                else:\n",
    "                    intent_token_preds = intent_token_logits.detach().cpu().numpy()\n",
    "\n",
    "            else:\n",
    "                if self.args.use_crf:\n",
    "                    intent_token_preds = np.append(intent_token_preds, np.array(self.model.crf.decode(intent_token_logits)), axis=0)\n",
    "                else:\n",
    "                    intent_token_preds = np.append(intent_token_preds, intent_token_logits.detach().cpu().numpy(), axis=0)\n",
    "                \n",
    "        return intent_token_preds\n",
    "        \n",
    "\n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                token_type_ids,\n",
    "                B_tag_mask = None,\n",
    "                BI_tag_mask = None):#,\n",
    "                # B_tag_mask,\n",
    "                # BI_tag_mask,\n",
    "                # tag_intent_label):\n",
    "        \"\"\"\n",
    "            Args: B: batch_size; L: sequence length; I: the number of intents; M: number of mask; D: the output dim of Bert\n",
    "            input_ids: B * L\n",
    "            token_type_ids: B * L\n",
    "            token_type_ids: B * L\n",
    "            intent_label_ids: B * I\n",
    "            slot_labels_ids: B * L\n",
    "            intent_token_ids: B * L\n",
    "            B_tag_mask: B * M * L\n",
    "            BI_tag_mask: B * M * L\n",
    "            tag_intent_label: B * M\n",
    "        \"\"\"\n",
    "        # input_ids:  torch.Size([32, 50])\n",
    "        # attention_mask:  torch.Size([32, 50])\n",
    "        # token_type_ids:  torch.Size([32, 50])\n",
    "        # intent_label_ids:  torch.Size([32, 10])\n",
    "        # slot_labels_ids:  torch.Size([32, 50])\n",
    "        # intent_token_ids:  torch.Size([32, 50])\n",
    "        # B_tag_mask:  torch.Size([32, 4, 50])\n",
    "        # BI_tag_mask:  torch.Size([32, 4, 50])\n",
    "        # tag_intent_label:  torch.Size([32, 4])\n",
    "        \n",
    "        # (len_seq, batch_size, hidden_dim), (batch_size, hidden_dim)\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        # B * L * D\n",
    "        sequence_output = outputs[0]\n",
    "        # B * D\n",
    "        pooled_output = outputs[1]  # [CLS]\n",
    "\n",
    "\n",
    "        #====================================== get logits for 3 classifiers ======================================\n",
    "        # (batch_size, num_intents)\n",
    "        intent_logits = self.multi_intent_classifier(pooled_output)\n",
    "        \n",
    "        # (batch_size, seq_len, num_slots)\n",
    "        slot_logits = self.slot_classifier(sequence_output)\n",
    "\n",
    "        # (batch_size, seq_len, num_intents)\n",
    "        intent_token_logits = self.intent_token_classifier(sequence_output)\n",
    "        \n",
    "        # ====================================== generate mask ======================================\n",
    "\n",
    "        # 1.-------------------------------------- get preds from logits for mask ------------------------------------------\n",
    "        intent_preds = None\n",
    "        intent_preds = self.intent_pred(intent_preds,intent_logits)\n",
    "        # intent_preds = torch.as_tensor(intent_preds > 0.5, dtype=torch.int32)\n",
    "        \n",
    "        slot_preds = None\n",
    "        slot_preds= self.slot_pred(slot_preds, slot_logits) # 64x35\n",
    "\n",
    "        intent_token_preds = None\n",
    "        intent_token_preds = self.intent_token_pred(intent_token_preds, intent_token_logits)\n",
    "\n",
    "        # 2.-------------------------------------- get masks from preds or true labels(training) ------------------------------------------\n",
    "        # Slot result\n",
    "        # (batch_size, seq_len)\n",
    "        out_slot_label_list = [[] for _ in range(slot_preds.shape[0])]\n",
    "        slot_preds_list = [[] for _ in range(slot_preds.shape[0])]\n",
    "        \n",
    "        slot_label_map = self.slot_label_map\n",
    "                \n",
    "        #mask\n",
    "        B_tag_mask_pred = []\n",
    "        BI_tag_mask_pred = []\n",
    "        \n",
    "        out_slot_labels_ids = slot_preds\n",
    "        for i in range(out_slot_labels_ids.shape[0]): # for all samples\n",
    "            # record the padding position\n",
    "            pos_offset = [0 for _ in range(out_slot_labels_ids.shape[1])] # in shape of max_seq_len\n",
    "            pos_cnt = 0\n",
    "            padding_recording = [0 for _ in range(out_slot_labels_ids.shape[1])] # in shape of max_seq_len\n",
    "            \n",
    "            for j in range(out_slot_labels_ids.shape[1]): # for all token in seq\n",
    "                if out_slot_labels_ids[i, j] != self.pad_token_label_id:\n",
    "                    out_slot_label_list[i].append(slot_label_map[out_slot_labels_ids[i][j]]) # append word label if not pad\n",
    "                    slot_preds_list[i].append(slot_label_map[slot_preds[i][j]]) # append word label if not pad\n",
    "                    pos_offset[pos_cnt+1] = pos_offset[pos_cnt]\n",
    "                    pos_cnt += 1\n",
    "                else:\n",
    "                    pos_offset[pos_cnt] = pos_offset[pos_cnt] + 1\n",
    "                    padding_recording[j] = 1\n",
    "                    \n",
    "                # print('pos_offset: ',pos_offset)\n",
    "                # print('pos_cnt; ',pos_cnt)\n",
    "                # print('padding_recording: ',padding_recording)\n",
    "                    \n",
    "\n",
    "            entities = get_entities(slot_preds_list[i])\n",
    "            entities = [tag for entity_idx, tag in enumerate(entities) if slot_preds_list[i][tag[1]].startswith('B')]\n",
    "            #print(entities)\n",
    "            \n",
    "            if len(entities) > self.args.num_mask:\n",
    "                entities = entities[:self.args.num_mask]\n",
    "            \n",
    "            entity_masks = []\n",
    "            \n",
    "            \n",
    "            for entity_idx, entity in enumerate(entities):\n",
    "                entity_mask = [0 for _ in range(out_slot_labels_ids.shape[1])]\n",
    "                start_idx = entity[1] + pos_offset[entity[1]]\n",
    "                end_idx = entity[2] + pos_offset[entity[2]] + 1\n",
    "                if self.args.BI_tag:\n",
    "                    entity_mask[start_idx:end_idx] = [1] * (end_idx - start_idx)\n",
    "                    for padding_idx in range(start_idx, end_idx):\n",
    "                        \n",
    "                        #print('len(padding_recording): ',len(padding_recording))\n",
    "                        #print('padding_idx: ',padding_idx)\n",
    "                        \n",
    "                        if padding_recording[padding_idx]:\n",
    "                            entity_mask[padding_idx] = 0\n",
    "                else:\n",
    "                    entity_mask[start_idx] = 1\n",
    "                    \n",
    "                entity_masks.append(entity_mask)\n",
    "            \n",
    "            for extra_idx in range(self.args.num_mask - len(entity_masks)):\n",
    "                entity_masks.append([\n",
    "                    0 for _ in range(out_slot_labels_ids.shape[1])\n",
    "                ])\n",
    "\n",
    "            #print('entity mask: ', entity_masks)\n",
    "            if self.args.BI_tag:\n",
    "                BI_tag_mask_pred.append(entity_masks)\n",
    "            else:\n",
    "                B_tag_mask_pred.append(entity_masks)\n",
    "                \n",
    "        if self.args.BI_tag:\n",
    "            BI_tag_mask_pred_tensor = torch.FloatTensor(BI_tag_mask_pred)\n",
    "        else:\n",
    "            B_tag_mask_pred_tensor = torch.FloatTensor(B_tag_mask_pred)\n",
    "        \n",
    "        BI_tag_mask_pred_input = None\n",
    "        B_tag_mask_pred_input = None\n",
    "        \n",
    "        #============================================================================\n",
    "        \n",
    "        # after softmax\n",
    "        tag_intent_logits = self.tag_intent_classifier(tag_intent_vec)\n",
    "        \n",
    "        \n",
    "        total_loss = 0  \n",
    "        \n",
    "        # ==================================== 1. Intent Softmax ========================================\n",
    "        # (batch_size, num_intents)\n",
    "        intent_logits = self.multi_intent_classifier(pooled_output)\n",
    "        intent_logits_cpu = intent_logits.data.cpu().numpy()\n",
    "        \n",
    "        if intent_label_ids is not None:\n",
    "            if self.num_intent_labels == 1:\n",
    "                intent_loss_fct = nn.MSELoss()\n",
    "                intent_loss = intent_loss_fct(intent_logits.view(-1), intent_label_ids.view(-1, self.num_intent_labels))\n",
    "            else:\n",
    "                # intent_loss_fct = nn.CrossEntropyLoss()\n",
    "                # default reduction is mean\n",
    "                intent_loss_fct = nn.BCELoss()\n",
    "                intent_loss = intent_loss_fct(intent_logits.view(-1, self.num_intent_labels) + 1e-10, intent_label_ids.view(-1, self.num_intent_labels))\n",
    "            # Question: do we need to add weight here\n",
    "            total_loss += intent_loss\n",
    "            \n",
    "        if intent_label_ids.type() != torch.cuda.FloatTensor:\n",
    "            intent_label_ids = intent_label_ids.type(torch.cuda.FloatTensor)\n",
    "            \n",
    "        # ==================================== 2. Slot Softmax ========================================\n",
    "        # (batch_size, seq_len, num_slots)\n",
    "        print('len sequence_output: ',sequence_output.size)\n",
    "        slot_logits = self.slot_classifier(sequence_output)\n",
    "        print('len slot_logits: ', slot_logits.size)\n",
    "        \n",
    "        if slot_labels_ids is not None:\n",
    "            if self.args.use_crf:\n",
    "                slot_loss = self.crf(slot_logits, slot_labels_ids, mask=attention_mask.byte(), reduction='mean')\n",
    "                slot_loss = -1 * slot_loss  # negative log-likelihood\n",
    "            else:\n",
    "                slot_loss_fct = nn.CrossEntropyLoss(ignore_index=self.args.ignore_index)\n",
    "                # Only keep active parts of the loss\n",
    "                if attention_mask is not None:\n",
    "                    try:\n",
    "                        active_loss = attention_mask.view(-1) == 1\n",
    "                        attention_mask_cpu = attention_mask.data.cpu().numpy()\n",
    "                        active_loss_cpu = active_loss.data.cpu().numpy()\n",
    "                        active_logits = slot_logits.view(-1, self.num_slot_labels)[active_loss]\n",
    "                        active_labels = slot_labels_ids.view(-1)[active_loss]\n",
    "                        slot_loss = slot_loss_fct(active_logits, active_labels)\n",
    "                    except:\n",
    "                        print('intent_logits: ', intent_logits_cpu)\n",
    "                        print('attention_mask: ', attention_mask_cpu)\n",
    "                        print('active_loss: ', active_loss_cpu)\n",
    "                        logger.info('intent_logits: ', intent_logits_cpu)\n",
    "                        logger.info('attention_mask: ', attention_mask_cpu)\n",
    "                        logger.info('active_loss: ', active_loss_cpu)\n",
    "                else:\n",
    "                    slot_loss = slot_loss_fct(slot_logits.view(-1, self.num_slot_labels), slot_labels_ids.view(-1))\n",
    "\n",
    "            total_loss += self.args.slot_loss_coef * slot_loss\n",
    "        \n",
    "        \n",
    "        # ==================================== 3. Intent Token Softmax ========================================\n",
    "        intent_token_loss = 0.0\n",
    "        if self.args.intent_seq:\n",
    "            # (batch_size, seq_len, num_intents)\n",
    "            intent_token_logits = self.intent_token_classifier(sequence_output)\n",
    "\n",
    "            if intent_token_ids is not None:\n",
    "                if self.args.use_crf:\n",
    "                    intent_token_loss = self.crf(intent_token_logits, intent_token_ids, mask=attention_mask.byte, reduction='mean')\n",
    "                    intent_token_loss = -1 * intent_token_loss\n",
    "                else:\n",
    "                    intent_token_loss_fct = nn.CrossEntropyLoss(ignore_index=self.args.ignore_index)\n",
    "                    if attention_mask is not None:\n",
    "                        active_intent_loss = attention_mask.view(-1) == 1\n",
    "                        active_intent_logits = intent_token_logits.view(-1, self.num_intent_labels)[active_intent_loss]\n",
    "                        active_intent_tokens = intent_token_ids.view(-1)[active_intent_loss]\n",
    "                        intent_token_loss = intent_token_loss_fct(active_intent_logits, active_intent_tokens)\n",
    "                    else:\n",
    "                        intent_token_loss = intent_token_loss_fct(intent_token_logits.view(-1, self.num_intent_labels), intent_token_ids.view(-1))\n",
    "                \n",
    "                total_loss += self.args.slot_loss_coef * intent_token_loss\n",
    "        \n",
    "        # convert the sequence_out to long\n",
    "        if BI_tag_mask != None and  BI_tag_mask.type() != torch.cuda.FloatTensor:\n",
    "            BI_tag_mask = BI_tag_mask.type(torch.cuda.FloatTensor)\n",
    "\n",
    "        if B_tag_mask != None and B_tag_mask.type() != torch.cuda.FloatTensor:\n",
    "            B_tag_mask = B_tag_mask.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        tag_intent_loss = 0.0\n",
    "        if self.args.tag_intent:\n",
    "            # B * M * D\n",
    "            if self.args.BI_tag:\n",
    "                tag_intent_vec = torch.einsum('bml,bld->bmd', BI_tag_mask, sequence_output)\n",
    "            else:\n",
    "                tag_intent_vec = torch.einsum('bml,bld->bmd', B_tag_mask, sequence_output)\n",
    "            \n",
    "            if self.args.cls_token_cat:\n",
    "                cls_token = pooled_output.unsqueeze(1)\n",
    "                # B * M * D\n",
    "                cls_token = cls_token.repeat(1, self.args.num_mask, 1)\n",
    "                # B * M * 2D\n",
    "                tag_intent_vec = torch.cat((cls_token, tag_intent_vec), dim=2)\n",
    "            \n",
    "            tag_intent_vec = tag_intent_vec.view(tag_intent_vec.size(0) * tag_intent_vec.size(1), -1)\n",
    "            \n",
    "            # after softmax\n",
    "            tag_intent_logits = self.tag_intent_classifier(tag_intent_vec)\n",
    "\n",
    "            if self.args.intent_attn:\n",
    "                # (batch_size, num_intent) => (batch_size * num_mask, num_intent) sigmoid [0, 1]\n",
    "                intent_probs = intent_logits.unsqueeze(1)\n",
    "                intent_probs = intent_probs.repeat(1, self.args.num_mask, 1)\n",
    "                intent_probs = intent_probs.view(intent_probs.size(0) * intent_probs.size(1), -1)\n",
    "                # (batch_size * num_mask, num_intent)\n",
    "                tag_intent_logits = tag_intent_logits * intent_probs\n",
    "                tag_intent_logits = tag_intent_logits.div(tag_intent_logits.sum(dim=1, keepdim=True))\n",
    "            \n",
    "            # tag_intent_loss_fct = nn.CrossEntropyLoss(ignore_index=self.args.ignore_index)\n",
    "\n",
    "            # tag_intent_loss = tag_intent_loss_fct(tag_intent_logits, tag_intent_label.view(-1))\n",
    "\n",
    "            nll_fct = nn.NLLLoss(ignore_index=self.args.ignore_index)\n",
    "            \n",
    "            tag_intent_loss = nll_fct(torch.log(tag_intent_logits + 1e-10), tag_intent_label.view(-1))\n",
    "            \n",
    "            total_loss += self.args.tag_intent_coef * tag_intent_loss\n",
    "            \n",
    "        if self.args.intent_seq and self.args.tag_intent:\n",
    "            outputs = ((intent_logits, slot_logits, intent_token_logits, tag_intent_logits),) + outputs[2:]  # add hidden states and attention if they are here\n",
    "        elif self.args.intent_seq:\n",
    "            outputs = ((intent_logits, slot_logits, intent_token_logits),) + outputs[2:]\n",
    "        elif self.args.tag_intent:\n",
    "            outputs = ((intent_logits, slot_logits, tag_intent_logits),) + outputs[2:]\n",
    "        else:\n",
    "            outputs = ((intent_logits, slot_logits),) + outputs[2:]\n",
    "        \n",
    "        outputs = ([total_loss, intent_loss, slot_loss, intent_token_loss, tag_intent_loss],) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions) # Logits is a tuple of intent and slot logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    time_wait = random.uniform(0, 10)\n",
    "    time.sleep(time_wait)\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "    parser.add_argument(\"--task\", default='gpsr', type=str, help=\"The name of the task to train\")\n",
    "\n",
    "#     parser.add_argument(\"--model_dir\", default='./gpsr_model', required=True, type=str, help=\"Path to save, load model\")\n",
    "    parser.add_argument(\"--model_dir\", default='./test_model', type=str, help=\"Path to save, load model\")\n",
    "\n",
    "    parser.add_argument(\"--data_dir\", default=\"./data\", type=str, help=\"The input data dir\")\n",
    "    parser.add_argument(\"--intent_label_file\", default=\"intent_label.txt\", type=str, help=\"Intent Label file\")\n",
    "    parser.add_argument(\"--slot_label_file\", default=\"slot_label.txt\", type=str, help=\"Slot Label file\")\n",
    "    parser.add_argument(\"--model_type\", default=\"multibert\", type=str, help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()))\n",
    "#     parser.add_argument(\"--intent_seq\", type=int, default=0, help=\"whether we use intent seq setting\")\n",
    "    parser.add_argument(\"--intent_seq\", type=int, default=1, help=\"whether we use intent seq setting\")\n",
    "\n",
    "    parser.add_argument(\"--multi_intent\", type=int, default=1, help=\"whether we use multi intent setting\")\n",
    "    parser.add_argument(\"--tag_intent\", type=int, default=1, help=\"whether we can use tag to predict intent\")\n",
    "\n",
    "    parser.add_argument(\"--BI_tag\", type=int, default=1, help='use BI sum or just B')\n",
    "    parser.add_argument(\"--cls_token_cat\", type=int, default=1, help='whether we cat the cls to the slot output of bert')\n",
    "    parser.add_argument(\"--intent_attn\", type=int, default=1, help='whether we use attention mechanism on the CLS intent output')\n",
    "    parser.add_argument(\"--num_mask\", type=int, default=7, help=\"assumptive number of slot in one sentence\")\n",
    "                                           #max slot num = 7\n",
    "\n",
    "\n",
    "    parser.add_argument('--seed', type=int, default=25, help=\"random seed for initialization\")\n",
    "    parser.add_argument(\"--train_batch_size\", default=64, type=int, help=\"Batch size for training.\")\n",
    "#     parser.add_argument(\"--train_batch_size\", default=64, type=int, help=\"Batch size for training.\")\n",
    "\n",
    "    parser.add_argument(\"--eval_batch_size\", default=128, type=int, help=\"Batch size for evaluation.\")\n",
    "    parser.add_argument(\"--max_seq_len\", default=35, type=int, help=\"The maximum total input sequence length after tokenization.\")\n",
    "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
    "#     parser.add_argument(\"--num_train_epochs\", default=10.0, type=float, help=\"Total number of training epochs to perform.\")\n",
    "    parser.add_argument(\"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\")\n",
    "                                            #####\n",
    "\n",
    "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
    "    parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n",
    "                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--max_grad_norm\", default=1, type=float, help=\"Max gradient norm.\")\n",
    "    parser.add_argument(\"--max_steps\", default=-1, type=int, help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n",
    "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "    parser.add_argument(\"--dropout_rate\", default=0.1, type=float, help=\"Dropout for fully-connected layers\")\n",
    "    parser.add_argument('--logging_steps', type=int, default=500, help=\"Log every X updates steps.\")\n",
    "    parser.add_argument('--save_steps', type=int, default=300, help=\"Save checkpoint every X updates steps.\")\n",
    "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
    "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the test set.\")\n",
    "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "    parser.add_argument(\"--ignore_index\", default=0, type=int,\n",
    "                        help='Specifies a target value that is ignored and does not contribute to the input gradient')\n",
    "    parser.add_argument('--slot_loss_coef', type=float, default=2.0, help='Coefficient for the slot loss.')\n",
    "    parser.add_argument('--tag_intent_coef', type=float, default=1.0, help='Coefficient for the tag intent loss')\n",
    "\n",
    "    # CRF option\n",
    "    parser.add_argument(\"--use_crf\", action=\"store_true\", help=\"Whether to use CRF\")\n",
    "    parser.add_argument(\"--slot_pad_label\", default=\"PAD\", type=str, help=\"Pad token for slot label pad (to be ignore when calculate loss)\")\n",
    "    parser.add_argument(\"--patience\", default=0, type=int, help=\"The initial learning rate for Adam.\")\n",
    "\n",
    "    parser.add_argument('-f')#########################\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    args.model_name_or_path = MODEL_PATH_MAP[args.model_type]\n",
    "    args.model_name_or_path = MODEL_PATH_MAP[args.model_type]\n",
    "\n",
    "    tokenizer = load_tokenizer(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_and_cache_examples, processors\n",
    "\n",
    "train_dataset = load_and_cache_examples(args, tokenizer, mode=\"train\")\n",
    "dev_dataset = load_and_cache_examples(args, tokenizer, mode=\"dev\")\n",
    "test_dataset = load_and_cache_examples(args, tokenizer, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "JointBERTMultiIntent(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (multi_intent_classifier): MultiIntentClassifier(\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linear): Linear(in_features=768, out_features=9, bias=True)\n    (sigmoid): Sigmoid()\n  )\n  (slot_classifier): SlotClassifier(\n    (dropout): Dropout(p=0.1, inplace=False)\n    (activation): ReLU()\n    (linear): Linear(in_features=768, out_features=10, bias=True)\n  )\n  (intent_token_classifier): IntentTokenClassifier(\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linear): Linear(in_features=768, out_features=9, bias=True)\n  )\n  (tag_intent_classifier): TagIntentClassifier(\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linear): Linear(in_features=1536, out_features=9, bias=True)\n    (softmax): Softmax(dim=1)\n  )\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "config_class, model_class, _ = MODEL_CLASSES[args.model_type]\n",
    "\n",
    "config = config_class.from_pretrained(args.model_name_or_path, finetuning_task=args.task)\n",
    "\n",
    "# model = model_class.from_pretrained(args.model_name_or_path,\n",
    "#                                               config=config,\n",
    "#                                               args=args,\n",
    "#                                               intent_label_lst=get_intent_labels(args),\n",
    "#                                               slot_label_lst=get_slot_labels(args))\n",
    "\n",
    "model = JointBERTMultiIntent(config, args, get_intent_labels(args), get_slot_labels(args))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 22\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mmodel_type \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdistilbert\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     21\u001B[0m     inputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m---> 22\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m     losses \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     25\u001B[0m     loss \u001B[38;5;241m=\u001B[39m losses[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[2], line 168\u001B[0m, in \u001B[0;36mJointBERTMultiIntent.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, intent_label_ids, slot_labels_ids, intent_token_ids)\u001B[0m\n\u001B[1;32m    165\u001B[0m slot_preds, out_slot_labels_ids\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mslot_pred(slot_preds, slot_logits, slot_labels_ids)\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28mprint\u001B[39m(slot_preds\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m--> 168\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mout_slot_labels_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m)\n\u001B[1;32m    171\u001B[0m intent_token_preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    172\u001B[0m intent_token_preds, out_intent_token_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintent_token_pred(intent_token_preds, intent_token_logits, intent_label_ids)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
    "\n",
    "for _ in train_iterator:\n",
    "    #epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=False )\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        print('train:  ')\n",
    "        model.train()\n",
    "        batch = tuple(t.to('cuda') for t in batch)  # GPU or CPU\n",
    "\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1]}#,\n",
    "                  # 'intent_label_ids': batch[3],\n",
    "                  # 'slot_labels_ids': batch[4],\n",
    "                  # 'intent_token_ids': batch[5],\n",
    "                  # 'B_tag_mask': batch[6],\n",
    "                  # 'BI_tag_mask': batch[7],\n",
    "                  # 'tag_intent_label': batch[8]}\n",
    "        if args.model_type != 'distilbert':\n",
    "            inputs['token_type_ids'] = batch[2]\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            losses = outputs[0]\n",
    "            loss = losses[0]\n",
    "            intent_loss = losses[1]\n",
    "            slot_loss = losses[2]\n",
    "            intent_token_loss = losses[3]\n",
    "            tag_intent_loss = losses[4]\n",
    "            #print(tag_intent_loss)\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jointbert",
   "language": "python",
   "name": "jointbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
