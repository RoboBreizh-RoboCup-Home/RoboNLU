{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crossing/miniconda3/envs/jointbert/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from utils import init_logger, load_tokenizer, get_intent_labels, get_slot_labels, MODEL_CLASSES, MODEL_PATH_MAP\n",
    "# from utils import init_logger, load_tokenizer, read_prediction_text, set_seed, MODEL_CLASSES, MODEL_PATH_MAP, get_intent_labels, get_slot_labels\n",
    "\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(pred_config):\n",
    "    return \"cuda\" if torch.cuda.is_available() and not pred_config.no_cuda else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(pred_config):\n",
    "    return torch.load(os.path.join(pred_config.model_dir, 'training_args.pt'))\n",
    "    # return torch.load(os.path.join(pred_config.model_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args, device):\n",
    "    # Check whether model exists\n",
    "    if not os.path.exists(pred_config.model_dir):\n",
    "        raise Exception(\"Model doesn't exists! Train first!\")\n",
    "    try:\n",
    "        intent_label_lst = get_intent_labels(args)\n",
    "        slot_label_lst=get_slot_labels(args)\n",
    "        model = MODEL_CLASSES[args.model_type][1].from_pretrained(args.model_dir,\n",
    "                                                                  intent_label_lst=intent_label_lst,\n",
    "                                                                  slot_label_lst=slot_label_lst)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        logger.info(\"***** Model Loaded *****\")\n",
    "    except:\n",
    "        raise Exception(\"Some model files might be missing...\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_file(pred_config):\n",
    "    lines = []\n",
    "    with open(pred_config.input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            words = line.split()\n",
    "            lines.append(words)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_file_to_tensor_dataset(lines,\n",
    "                                         pred_config,\n",
    "                                         tokenizer,\n",
    "                                         pad_token_label_id,\n",
    "                                         cls_token_segment_id=0,\n",
    "                                         pad_token_segment_id=0,\n",
    "                                         sequence_a_segment_id=0,\n",
    "                                         mask_padding_with_zero=True):\n",
    "\n",
    "    max_seq_len = 32\n",
    "    pro_lst = ['him','her','it','its']\n",
    "    # Setting based on the current model type\n",
    "    cls_token = tokenizer.cls_token\n",
    "    sep_token = tokenizer.sep_token\n",
    "    unk_token = tokenizer.unk_token\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    all_token_type_ids = []\n",
    "    all_slot_label_mask = []\n",
    "    all_pro_labels_ids = []\n",
    "    for words in lines:\n",
    "        tokens = []\n",
    "        slot_label_mask = []\n",
    "        pro_labels_ids = []\n",
    "        for word in words:\n",
    "            word_tokens = tokenizer.tokenize(word)\n",
    "            if not word_tokens:\n",
    "                word_tokens = [unk_token]  # For handling the bad-encoded word\n",
    "            if word in pro_lst:\n",
    "                pro_label = 1\n",
    "            else:\n",
    "                pro_label = 0\n",
    "            tokens.extend(word_tokens)\n",
    "            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
    "            slot_label_mask.extend([pad_token_label_id + 1] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
    "            pro_labels_ids.extend([pro_label] + [pad_token_label_id] * (len(word_tokens) - 1)) #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "        # Account for [CLS] and [SEP]\n",
    "        special_tokens_count = 2\n",
    "        if len(tokens) > max_seq_len - special_tokens_count:\n",
    "            tokens = tokens[: (max_seq_len - special_tokens_count)]\n",
    "            slot_label_mask = slot_label_mask[:(max_seq_len - special_tokens_count)]\n",
    "            pro_labels_ids = pro_labels_ids[:(max_seq_len - special_tokens_count)] #!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        # Add [SEP] token\n",
    "        tokens += [sep_token]\n",
    "        token_type_ids = [sequence_a_segment_id] * len(tokens)\n",
    "        slot_label_mask += [pad_token_label_id]\n",
    "        pro_labels_ids += [pad_token_label_id]#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        # Add [CLS] token\n",
    "        tokens = [cls_token] + tokens\n",
    "        token_type_ids = [cls_token_segment_id] + token_type_ids\n",
    "        slot_label_mask = [pad_token_label_id] + slot_label_mask\n",
    "        pro_labels_ids = [pad_token_label_id] + pro_labels_ids#!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n",
    "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_seq_len - len(input_ids)\n",
    "        input_ids = input_ids + ([pad_token_id] * padding_length)\n",
    "        attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "        slot_label_mask = slot_label_mask + ([pad_token_label_id] * padding_length)\n",
    "        pro_labels_ids = pro_labels_ids + ([pad_token_label_id] * padding_length) #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        all_input_ids.append(input_ids)\n",
    "        all_attention_mask.append(attention_mask)\n",
    "        all_token_type_ids.append(token_type_ids)\n",
    "        all_slot_label_mask.append(slot_label_mask)\n",
    "        all_pro_labels_ids.append(pro_labels_ids) #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        # print('padding_length: \\n',padding_length,'\\n')\n",
    "        # print('input_ids: \\n',input_ids,'\\n')\n",
    "        # print('slot_label_mask: \\n',slot_label_mask,'\\n')\n",
    "        # print(f'attention_mask: \\n{attention_mask}\\n')\n",
    "\n",
    "    # Change to Tensor\n",
    "    all_input_ids = torch.tensor(all_input_ids, dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor(all_attention_mask, dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor(all_token_type_ids, dtype=torch.long)\n",
    "    all_slot_label_mask = torch.tensor(all_slot_label_mask, dtype=torch.long)\n",
    "    all_pro_labels_ids = torch.tensor(all_pro_labels_ids, dtype=torch.long) #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    # dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_slot_label_mask)\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids,all_slot_label_mask, all_pro_labels_ids)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def predict(pred_config):\n",
    "    args = pred_config\n",
    "    device = get_device(pred_config)\n",
    "    model = load_model(pred_config, device)\n",
    "\n",
    "    intent_label_lst = get_intent_labels(pred_config)\n",
    "    slot_label_lst = get_slot_labels(pred_config)\n",
    "\n",
    "    ignore_index = 0\n",
    "    # Convert input file to TensorDataset\n",
    "    pad_token_label_id = ignore_index\n",
    "    tokenizer = load_tokenizer(args)\n",
    "    lines = read_input_file(pred_config)\n",
    "    dataset = convert_input_file_to_tensor_dataset(lines, pred_config, tokenizer, pad_token_label_id)\n",
    "\n",
    "    # Predict\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    data_loader = DataLoader(dataset, sampler=sampler, batch_size=pred_config.batch_size)\n",
    "\n",
    "    intent_token_preds = None\n",
    "    all_referee_preds = None\n",
    "    slot_preds = None\n",
    "\n",
    "    for batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            inputs = {\"input_ids\": batch[0],\n",
    "                      \"attention_mask\": batch[1],\n",
    "                      \"pro_labels_ids\": batch[4]}\n",
    "            if args.model_type != \"distilbert\":\n",
    "                inputs[\"token_type_ids\"] = batch[2]\n",
    "\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            slot_logits, intent_token_logits, referee_token_logits,all_referee_token_logits = outputs\n",
    "\n",
    "\n",
    "             # ============================= Slot prediction ==============================\n",
    "            if slot_preds is None:\n",
    "                slot_preds = slot_logits.detach().cpu().numpy()\n",
    "                all_slot_label_mask = batch[3].detach().cpu().numpy()\n",
    "\n",
    "                #out_slot_labels_ids = slot_labels_ids.detach().cpu().numpy()\n",
    "            else:\n",
    "                slot_preds = np.append(slot_preds, slot_logits.detach().cpu().numpy(), axis=0)\n",
    "                all_slot_label_mask = np.append(all_slot_label_mask, batch[3].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "                #out_slot_labels_ids = np.append(out_slot_labels_ids, slot_labels_ids.detach().cpu().numpy(),axis=0)\n",
    "\n",
    "\n",
    "            # ============================= Pronoun referee prediction ==============================\n",
    "            if all_referee_preds is None:\n",
    "                all_referee_preds = all_referee_token_logits.detach().cpu().numpy()\n",
    "                referee_preds = referee_token_logits.detach().cpu().numpy()\n",
    "\n",
    "                pro_sample_mask_np = (torch.max(inputs[\"pro_labels_ids\"],dim = 1)[0] ==1 ).detach().cpu().numpy()\n",
    "\n",
    "                # all_out_referee_labels_ids = referee_labels_ids.detach().cpu().numpy()\n",
    "                # out_referee_labels_ids = all_out_referee_labels_ids[pro_sample_mask_np]\n",
    "\n",
    "\n",
    "            else:\n",
    "                all_referee_preds = np.append(all_referee_preds,all_referee_token_logits.detach().cpu().numpy(), axis = 0)\n",
    "                referee_preds = np.append(referee_preds, referee_token_logits.detach().cpu().numpy(), axis = 0)\n",
    "\n",
    "                # pro_sample_mask_np = (torch.max(inputs[\"pro_labels_ids\"],dim = 1)[0] == 1).detach().cpu().numpy()\n",
    "                # new_all_out_referee_labels_ids = referee_labels_ids.detach().cpu().numpy()\n",
    "                # all_out_referee_labels_ids = np.append(all_out_referee_labels_ids,new_all_out_referee_labels_ids,axis = 0)\n",
    "                # small_new_out_referee_labels_ids = new_all_out_referee_labels_ids[pro_sample_mask_np]\n",
    "                # out_referee_labels_ids = np.append(out_referee_labels_ids, small_new_out_referee_labels_ids, axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # ============================== Intent Token Seq =============================\n",
    "            if intent_token_preds is None:\n",
    "                intent_token_preds = intent_token_logits.detach().cpu().numpy()\n",
    "                # out_intent_token_ids = intent_token_ids.detach().cpu().numpy()\n",
    "            else:\n",
    "                intent_token_preds = np.append(intent_token_preds, intent_token_logits.detach().cpu().numpy(),axis=0)\n",
    "                # out_intent_token_ids = np.append(out_intent_token_ids,intent_token_ids.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "\n",
    "    slot_preds = np.argmax(slot_preds, axis=2)\n",
    "    slot_label_map = {i: label for i, label in enumerate(slot_label_lst)}\n",
    "    # out_slot_label_list = [[] for _ in range(out_slot_labels_ids.shape[0])]\n",
    "    slot_preds_list = [[] for _ in range(slot_preds.shape[0])]\n",
    "\n",
    "    # generate mask\n",
    "    for i in range(slot_preds.shape[0]):\n",
    "        for j in range(slot_preds.shape[1]):\n",
    "            if all_slot_label_mask[i, j] != pad_token_label_id:\n",
    "                # out_slot_label_list[i].append(slot_label_map[out_slot_labels_ids[i][j]])\n",
    "                slot_preds_list[i].append(slot_label_map[slot_preds[i][j]])\n",
    "\n",
    "\n",
    "\n",
    "    referee_token_map = {0:'PAD', 1:'O' ,2: 'B-referee'} # All referee are just one word in EGPSR\n",
    "\n",
    "    referee_preds = np.argmax(referee_preds, axis=2)\n",
    "    all_referee_preds = np.argmax(all_referee_preds, axis=2)\n",
    "\n",
    "\n",
    "    referee_preds_list = [[] for _ in range(referee_preds.shape[0])]\n",
    "    all_referee_preds_list = [[] for _ in range(all_referee_preds.shape[0])]\n",
    "\n",
    "\n",
    "    # for i in range(referee_preds.shape[0]):\n",
    "    #     for j in range(referee_preds.shape[1]):\n",
    "    #         if all_slot_label_mask[i, j] != pad_token_label_id: #out_slot_labels_ids,out_referee_labels_ids\n",
    "    #             referee_preds_list[i].append(referee_token_map[referee_preds[i][j]])\n",
    "\n",
    "    for i in range(all_referee_preds.shape[0]):\n",
    "        for j in range(all_referee_preds.shape[1]):\n",
    "            if all_slot_label_mask[i, j] != pad_token_label_id: #all_out_referee_labels_ids\n",
    "                all_referee_preds_list[i].append(referee_token_map[all_referee_preds[i][j]])\n",
    "\n",
    "\n",
    "\n",
    "    # ============================= Intent Seq Prediction ============================\n",
    "    intent_token_map = {i: label for i, label in enumerate(intent_label_lst)}\n",
    "\n",
    "    intent_token_preds = np.argmax(intent_token_preds, axis=2)\n",
    "    # out_intent_token_list = [[] for _ in range(out_intent_token_ids.shape[0])]\n",
    "    intent_token_preds_list = [[] for _ in range(intent_token_preds.shape[0])]\n",
    "\n",
    "    for i in range(intent_token_preds.shape[0]):\n",
    "        for j in range(intent_token_preds.shape[1]):\n",
    "            if all_slot_label_mask[i, j] != pad_token_label_id:\n",
    "                # out_intent_token_list[i].append(intent_token_map[out_intent_token_ids[i][j]])\n",
    "                intent_token_preds_list[i].append(intent_token_map[intent_token_preds[i][j]])\n",
    "\n",
    "\n",
    "    # print('slot_preds_list: ',len(slot_preds_list),len(slot_preds_list[0]))\n",
    "    # print('intent_token_preds_list: ',len(intent_token_preds_list),len(intent_token_preds_list[0]))\n",
    "    # print('all_referee_preds_list: ',len(all_referee_preds_list),len(all_referee_preds_list[0]))\n",
    "\n",
    "\n",
    "    # Write to output file\n",
    "    pronouns = ['him','her','it','its']\n",
    "    with open(pred_config.output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx,(words, slot_preds, intent_preds,referee_preds) in enumerate(zip(lines, slot_preds_list, intent_token_preds_list,all_referee_preds_list)):\n",
    "            if idx <= 10:\n",
    "                print('words:              ',words, len(words))\n",
    "                print('slot_preds:         ',slot_preds, len(slot_preds))\n",
    "                print('referee_preds:      ',referee_preds, len(referee_preds))\n",
    "                print('intent_preds:       ',intent_preds, len(intent_preds))\n",
    "\n",
    "            line = \"\"\n",
    "            if 'B-referee' not in referee_preds:#all([word not in pronouns for word in words]):\n",
    "                for word, i_pred, s_pred in zip(words, intent_preds, slot_preds):\n",
    "                    if s_pred == 'O' and i_pred == 'O':\n",
    "                        line = line + word + \" \"\n",
    "                    else:\n",
    "                        line = line + \"[{}:{}:{}] \".format(word, i_pred,s_pred)\n",
    "                f.write(line.strip()+'\\n')\n",
    "            else:\n",
    "                r_idx = referee_preds.index('B-referee')\n",
    "                for word, i_pred, s_pred, r_pred in zip(words, intent_preds, slot_preds,referee_preds):\n",
    "                    if s_pred == 'O' and i_pred == 'O':\n",
    "                        line = line + word + \" \"\n",
    "                    else:\n",
    "                        if word not in pronouns:\n",
    "                            line = line + \"[{}:{}:{}] \".format(word, i_pred,s_pred)\n",
    "                            if r_pred == 'B-referee':\n",
    "                                ref = word\n",
    "                        else:\n",
    "                            line = line + \"[{}:{}:{}:{}] \".format(word,words[r_idx], i_pred,s_pred)\n",
    "\n",
    "                f.write('\\n')\n",
    "                f.write('---------------------------------------------------------------------\\n')\n",
    "                f.write('* Pro Case: \\n')\n",
    "                f.write(line.strip()+'\\n')\n",
    "                f.write('---------------------------------------------------------------------\\n \\n')\n",
    "            print(line)\n",
    "            print('=====================================')\n",
    "\n",
    "\n",
    "    logger.info(\"Prediction Done!\")\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words:               ['find', 'jack', ',', 'and', 'follow', 'him'] 6\n",
      "slot_preds:          ['O', 'B-per', 'O', 'O', 'O', 'B-per'] 6\n",
      "referee_preds:       ['O', 'B-referee', 'O', 'O', 'O', 'O'] 6\n",
      "intent_preds:        ['B-find', 'I-find', 'O', 'O', 'B-follow', 'I-follow'] 6\n",
      "[find:B-find:O] [jack:I-find:B-per] , and [follow:B-follow:O] [him:jack:I-follow:B-per] \n",
      "=====================================\n",
      "words:               ['fine', 'the', 'apple', 'from', 'the', 'table', 'and', 'give', 'it', 'to', 'me'] 11\n",
      "slot_preds:          ['O', 'O', 'B-obj', 'O', 'O', 'B-sour', 'O', 'O', 'B-obj', 'O', 'B-dest'] 11\n",
      "referee_preds:       ['O', 'O', 'B-referee', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] 11\n",
      "intent_preds:        ['B-take', 'I-take', 'I-take', 'I-take', 'I-take', 'I-take', 'O', 'B-take', 'I-take', 'I-take', 'I-take'] 11\n",
      "[fine:B-take:O] [the:I-take:O] [apple:I-take:B-obj] [from:I-take:O] [the:I-take:O] [table:I-take:B-sour] and [give:B-take:O] [it:apple:I-take:B-obj] [to:I-take:O] [me:I-take:B-dest] \n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data_loader import load_and_cache_examples\n",
    "\n",
    "# train_dataset = load_and_cache_examples(args, tokenizer, mode=\"train\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input_file\", default=\"sample_pred_in.txt\", type=str, help=\"Input file for prediction\")\n",
    "    # parser.add_argument(\"--input_file\", default=\"data/gpsr_pro_instance/test/seq.in\", type=str, help=\"Input file for prediction\")\n",
    "\n",
    "    parser.add_argument(\"--task\", default='gpsr_pro_instance', type=str, help=\"The name of the task to train\")\n",
    "    parser.add_argument(\"--model_type\", default=\"multibert\", type=str,\n",
    "                        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()))\n",
    "    parser.add_argument(\"--data_dir\", default=\"./data\", type=str, help=\"The input data dir\")\n",
    "    parser.add_argument(\"--intent_label_file\", default=\"intent_label.txt\", type=str, help=\"Intent Label file\")\n",
    "    parser.add_argument(\"--slot_label_file\", default=\"slot_label.txt\", type=str, help=\"Slot Label file\")\n",
    "    parser.add_argument(\"--intent_seq\", type=int, default=1, help=\"whether we use intent seq setting\")\n",
    "\n",
    "\n",
    "    parser.add_argument(\"--pro\", type=int, default=1, help=\"support pronoun disambiguition\")#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "\n",
    "    parser.add_argument(\"--num_mask\", type=int, default=7, help=\"assumptive number of slot in one sentence\")\n",
    "    parser.add_argument(\"--ignore_index\", default=0, type=int,\n",
    "                        help='Specifies a target value that is ignored and does not contribute to the input gradient')\n",
    "\n",
    "    parser.add_argument(\"--output_file\", default=\"final_predict.txt\", type=str, help=\"Output file for prediction\")\n",
    "    parser.add_argument(\"--model_dir\", default=\"./trained_model\", type=str, help=\"Path to save, load model\")\n",
    "    parser.add_argument(\"--max_seq_len\", default=32, type=int,\n",
    "                        help=\"The maximum total input sequence length after tokenization.\")\n",
    "    parser.add_argument(\"--batch_size\", default=128, type=int, help=\"Batch size for prediction\")\n",
    "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "    parser.add_argument('-f')  #########################\n",
    "\n",
    "    pred_config = parser.parse_args()\n",
    "\n",
    "    pred_config.model_name_or_path = MODEL_PATH_MAP[pred_config.model_type]\n",
    "    pred_config.model_name_or_path = MODEL_PATH_MAP[pred_config.model_type]\n",
    "\n",
    "    tokenizer = load_tokenizer(pred_config)\n",
    "\n",
    "    model =  predict(pred_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "JointBERTMultiIntent(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (multi_intent_classifier): MultiIntentClassifier(\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linear): Linear(in_features=768, out_features=16, bias=True)\n    (sigmoid): Sigmoid()\n  )\n  (slot_classifier): SlotClassifier(\n    (dropout): Dropout(p=0.1, inplace=False)\n    (activation): ReLU()\n    (linear): Linear(in_features=768, out_features=10, bias=True)\n  )\n  (intent_token_classifier): IntentTokenClassifier(\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linear): Linear(in_features=768, out_features=16, bias=True)\n  )\n  (pro_classifier): ProClassifier(\n    (dropout): Dropout(p=0.1, inplace=False)\n    (linear1): Linear(in_features=1536, out_features=768, bias=True)\n    (linear2): Linear(in_features=768, out_features=3, bias=True)\n  )\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[ 101, 2986, 1996, 6207, 2013, 1996, 2795, 1998, 2507, 2009, 2000, 2033,\n           102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n             0,    0,    0,    0,    0,    0,    0,    0]]),\n 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]]),\n 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]])}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device(pred_config)\n",
    "# model = load_model(pred_config, device)\n",
    "\n",
    "ignore_index = 0\n",
    "pad_token_label_id = ignore_index\n",
    "tokenizer = load_tokenizer(pred_config)\n",
    "lines = read_input_file(pred_config)\n",
    "dataset = convert_input_file_to_tensor_dataset(lines, pred_config, tokenizer, pad_token_label_id)\n",
    "batch = dataset[1]\n",
    "\n",
    "\n",
    "# sampler = SequentialSampler(dataset)\n",
    "# data_loader = DataLoader(dataset, sampler=sampler, batch_size=pred_config.batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# inputs = {\"input_ids\": np.array(batch[0][None,:]),\n",
    "#           \"attention_mask\": np.array(batch[1][None,:]),\n",
    "#           \"pro_labels_ids\": np.array(batch[4][None,:]),\n",
    "#           'token_type_ids':np.array(batch[2][None,:])}\n",
    "\n",
    "inputs = {\"input_ids\": batch[0][None,:],\n",
    "          \"attention_mask\": batch[1][None,:],\n",
    "          'token_type_ids':batch[2][None,:]}\n",
    "\n",
    "\n",
    "# inputs = {\"input_ids\": batch[0],\n",
    "#           \"attention_mask\": batch[1],\n",
    "#           \"pro_labels_ids\": batch[4],\n",
    "#           'token_type_ids':batch[2]}\n",
    "\n",
    "\n",
    "# for batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "#     batch = tuple(t.to(device) for t in batch)\n",
    "#     with torch.no_grad():\n",
    "#         inputs = {\"input_ids\": batch[0],\n",
    "#                   \"attention_mask\": batch[1],\n",
    "#                   \"pro_labels_ids\": batch[4]}\n",
    "#         if pred_config.model_type != \"distilbert\":\n",
    "#             inputs[\"token_type_ids\"] = batch[2]\n",
    "#\n",
    "#\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# torch.onnx.export(model,               # model being run\n",
    "#                 dummy_input,               # model input (or a tuple for multiple inputs)\n",
    "#                 \"normal_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "#                 export_params=True,        # store the trained parameter weights inside the model file\n",
    "#                 opset_version=11,          # the ONNX version to export the model to\n",
    "#                 do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "#                 input_names = ['input_ids','attention_mask','pro_labels_ids','token_type_ids'],   # the model's input names\n",
    "#                 output_names = ['slot_logits', 'intent_token_logits', 'referee_token_logits','all_referee_token_logits'], # the model's output names\n",
    "#               dynamic_axes={'input' : {0: batch[0].shape,\n",
    "#                      1: batch[1].shape,\n",
    "#                      2: batch[2].shape,\n",
    "#                      3:batch[10].shape},    # variable length axes\n",
    "#                 'output' : {0 : 'batch_size'}}\n",
    "#                 )\n",
    "inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'pro_labels_ids'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 7\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# import onnx\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# import onnxruntime\u001B[39;00m\n\u001B[1;32m      6\u001B[0m dummy_input \u001B[38;5;241m=\u001B[39m inputs\n\u001B[0;32m----> 7\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43monnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m               \u001B[49m\u001B[38;5;66;43;03m# model being run\u001B[39;49;00m\n\u001B[1;32m      8\u001B[0m \u001B[43m                \u001B[49m\u001B[43mdummy_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m               \u001B[49m\u001B[38;5;66;43;03m# model input (or a tuple for multiple inputs)\u001B[39;49;00m\n\u001B[1;32m      9\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnormal_resolution.onnx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m   \u001B[49m\u001B[38;5;66;43;03m# where to save the model (can be a file or file-like object)\u001B[39;49;00m\n\u001B[1;32m     10\u001B[0m \u001B[43m                \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# store the trained parameter weights inside the model file\u001B[39;49;00m\n\u001B[1;32m     11\u001B[0m \u001B[43m                \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m11\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m          \u001B[49m\u001B[38;5;66;43;03m# the ONNX version to export the model to\u001B[39;49;00m\n\u001B[1;32m     12\u001B[0m \u001B[43m                \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# whether to execute constant folding for optimization\u001B[39;49;00m\n\u001B[1;32m     13\u001B[0m \u001B[43m                \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_ids\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mattention_mask\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpro_labels_ids\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtoken_type_ids\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m   \u001B[49m\u001B[38;5;66;43;03m# the model's input names\u001B[39;49;00m\n\u001B[1;32m     14\u001B[0m \u001B[43m                \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mslot_logits\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mintent_token_logits\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mreferee_token_logits\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mall_referee_token_logits\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m##['all_logits','other'],\u001B[39;49;00m\n\u001B[1;32m     15\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# ['slot_logits', 'intent_token_logits', 'referee_token_logits','all_referee_token_logits']\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01monnxruntime\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mquantization\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m quantize_dynamic, QuantType\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/onnx/__init__.py:350\u001B[0m, in \u001B[0;36mexport\u001B[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03mExports a model into ONNX format. If ``model`` is not a\u001B[39;00m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m:class:`torch.jit.ScriptModule` nor a :class:`torch.jit.ScriptFunction`, this runs\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;124;03m    model to the file ``f`` even if this is raised.\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n\u001B[0;32m--> 350\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    362\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    365\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/onnx/utils.py:163\u001B[0m, in \u001B[0;36mexport\u001B[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexport\u001B[39m(\n\u001B[1;32m    146\u001B[0m     model,\n\u001B[1;32m    147\u001B[0m     args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    160\u001B[0m     export_modules_as_functions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    161\u001B[0m ):\n\u001B[0;32m--> 163\u001B[0m     \u001B[43m_export\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m        \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/onnx/utils.py:1074\u001B[0m, in \u001B[0;36m_export\u001B[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001B[0m\n\u001B[1;32m   1071\u001B[0m     dynamic_axes \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   1072\u001B[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001B[0;32m-> 1074\u001B[0m graph, params_dict, torch_out \u001B[38;5;241m=\u001B[39m \u001B[43m_model_to_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_do_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfixed_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001B[39;00m\n\u001B[1;32m   1088\u001B[0m defer_weight_export \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1089\u001B[0m     export_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mExportTypes\u001B[38;5;241m.\u001B[39mPROTOBUF_FILE\n\u001B[1;32m   1090\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/onnx/utils.py:727\u001B[0m, in \u001B[0;36m_model_to_graph\u001B[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001B[0m\n\u001B[1;32m    724\u001B[0m     args \u001B[38;5;241m=\u001B[39m (args,)\n\u001B[1;32m    726\u001B[0m model \u001B[38;5;241m=\u001B[39m _pre_trace_quant_model(model, args)\n\u001B[0;32m--> 727\u001B[0m graph, params, torch_out, module \u001B[38;5;241m=\u001B[39m \u001B[43m_create_jit_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    728\u001B[0m params_dict \u001B[38;5;241m=\u001B[39m _get_named_param_dict(graph, params)\n\u001B[1;32m    730\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/onnx/utils.py:602\u001B[0m, in \u001B[0;36m_create_jit_graph\u001B[0;34m(model, args)\u001B[0m\n\u001B[1;32m    600\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m graph, params, torch_out, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    601\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 602\u001B[0m     graph, torch_out \u001B[38;5;241m=\u001B[39m \u001B[43m_trace_and_get_graph_from_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    603\u001B[0m     _C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_lint(graph)\n\u001B[1;32m    604\u001B[0m     state_dict \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39m_unique_state_dict(model)\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/onnx/utils.py:517\u001B[0m, in \u001B[0;36m_trace_and_get_graph_from_model\u001B[0;34m(model, args)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_trace_and_get_graph_from_model\u001B[39m(model, args):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;66;03m# A basic sanity check: make sure the state_dict keys are the same\u001B[39;00m\n\u001B[1;32m    514\u001B[0m     \u001B[38;5;66;03m# before and after running the model.  Fail fast!\u001B[39;00m\n\u001B[1;32m    515\u001B[0m     orig_state_dict_keys \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39m_unique_state_dict(model)\u001B[38;5;241m.\u001B[39mkeys()\n\u001B[0;32m--> 517\u001B[0m     trace_graph, torch_out, inputs_states \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_trace_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_return_inputs_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    520\u001B[0m     warn_on_static_input_change(inputs_states)\n\u001B[1;32m    522\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m orig_state_dict_keys \u001B[38;5;241m!=\u001B[39m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39m_unique_state_dict(model)\u001B[38;5;241m.\u001B[39mkeys():\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/jit/_trace.py:1175\u001B[0m, in \u001B[0;36m_get_trace_graph\u001B[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001B[0m\n\u001B[1;32m   1173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(args, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m   1174\u001B[0m     args \u001B[38;5;241m=\u001B[39m (args,)\n\u001B[0;32m-> 1175\u001B[0m outs \u001B[38;5;241m=\u001B[39m \u001B[43mONNXTracedModule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_return_inputs_states\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outs\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/jit/_trace.py:127\u001B[0m, in \u001B[0;36mONNXTracedModule.forward\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    125\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(out_vars)\n\u001B[0;32m--> 127\u001B[0m graph, out \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_graph_by_tracing\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrapper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[43min_vars\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_create_interpreter_name_lookup_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return_inputs:\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m graph, outs[\u001B[38;5;241m0\u001B[39m], ret_inputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/jit/_trace.py:118\u001B[0m, in \u001B[0;36mONNXTracedModule.forward.<locals>.wrapper\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return_inputs_states:\n\u001B[1;32m    117\u001B[0m     inputs_states\u001B[38;5;241m.\u001B[39mappend(_unflatten(in_args, in_desc))\n\u001B[0;32m--> 118\u001B[0m outs\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrace_inputs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return_inputs_states:\n\u001B[1;32m    120\u001B[0m     inputs_states[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m (inputs_states[\u001B[38;5;241m0\u001B[39m], trace_inputs)\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/torch/nn/modules/module.py:1118\u001B[0m, in \u001B[0;36mModule._slow_forward\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1116\u001B[0m         recording_scopes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1117\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1118\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1119\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1120\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m recording_scopes:\n",
      "\u001B[0;31mTypeError\u001B[0m: forward() missing 1 required positional argument: 'pro_labels_ids'"
     ]
    }
   ],
   "source": [
    "# import onnx\n",
    "# import onnxruntime\n",
    "\n",
    "\n",
    "\n",
    "dummy_input = inputs\n",
    "torch.onnx.export(model,               # model being run\n",
    "                dummy_input,               # model input (or a tuple for multiple inputs)\n",
    "                \"normal_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                export_params=True,        # store the trained parameter weights inside the model file\n",
    "                opset_version=11,          # the ONNX version to export the model to\n",
    "                do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                input_names = ['input_ids','attention_mask','pro_labels_ids','token_type_ids'],   # the model's input names\n",
    "                output_names = ['slot_logits', 'intent_token_logits', 'referee_token_logits','all_referee_token_logits'], ##['all_logits','other'],\n",
    "                )\n",
    "\n",
    "# ['slot_logits', 'intent_token_logits', 'referee_token_logits','all_referee_token_logits']\n",
    "\n",
    "\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = 'normal_resolution.onnx'\n",
    "model_quant = 'normal_resolution.quant.onnx'\n",
    "quantized_model = quantize_dynamic(model_fp32, model_quant)\n",
    "# for quantization\n",
    "# propagate through the model\n",
    "# outputs = model(dummy_input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[MatMul_81]\n",
      "Ignore MatMul due to non constant B: /[MatMul_86]\n",
      "Ignore MatMul due to non constant B: /[MatMul_139]\n",
      "Ignore MatMul due to non constant B: /[MatMul_144]\n",
      "Ignore MatMul due to non constant B: /[MatMul_197]\n",
      "Ignore MatMul due to non constant B: /[MatMul_202]\n",
      "Ignore MatMul due to non constant B: /[MatMul_255]\n",
      "Ignore MatMul due to non constant B: /[MatMul_260]\n",
      "Ignore MatMul due to non constant B: /[MatMul_313]\n",
      "Ignore MatMul due to non constant B: /[MatMul_318]\n",
      "Ignore MatMul due to non constant B: /[MatMul_371]\n",
      "Ignore MatMul due to non constant B: /[MatMul_376]\n",
      "Ignore MatMul due to non constant B: /[MatMul_429]\n",
      "Ignore MatMul due to non constant B: /[MatMul_434]\n",
      "Ignore MatMul due to non constant B: /[MatMul_487]\n",
      "Ignore MatMul due to non constant B: /[MatMul_492]\n",
      "Ignore MatMul due to non constant B: /[MatMul_545]\n",
      "Ignore MatMul due to non constant B: /[MatMul_550]\n",
      "Ignore MatMul due to non constant B: /[MatMul_603]\n",
      "Ignore MatMul due to non constant B: /[MatMul_608]\n",
      "Ignore MatMul due to non constant B: /[MatMul_661]\n",
      "Ignore MatMul due to non constant B: /[MatMul_666]\n",
      "Ignore MatMul due to non constant B: /[MatMul_719]\n",
      "Ignore MatMul due to non constant B: /[MatMul_724]\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input_ids\": batch[0][None,:],\n",
    "          \"attention_mask\": batch[1][None,:],\n",
    "          'token_type_ids':batch[2][None,:]}\n",
    "\n",
    "dummy_input = inputs\n",
    "torch.onnx.export(model.bert,               # model being run\n",
    "                dummy_input,               # model input (or a tuple for multiple inputs)\n",
    "                \"bert.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                export_params=True,        # store the trained parameter weights inside the model file\n",
    "                opset_version=11,          # the ONNX version to export the model to\n",
    "                do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                input_names = ['input_ids','attention_mask','token_type_ids'],   # the model's input names\n",
    "                output_names = ['sequence_output','pooled_output'], ##['all_logits','other'],\n",
    "                )\n",
    "\n",
    "# ['slot_logits', 'intent_token_logits', 'referee_token_logits','all_referee_token_logits']\n",
    "\n",
    "\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = 'bert.onnx'\n",
    "model_quant = './quantized_models/bert.quant.onnx'\n",
    "quantized_model = quantize_dynamic(model_fp32, model_quant)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "out = model.bert(**inputs)\n",
    "print(out[0].shape)\n",
    "print(out[1].shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# slot_classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "dummy_input = out[0]\n",
    "torch.onnx.export(model.slot_classifier,               # model being run\n",
    "                dummy_input,               # model input (or a tuple for multiple inputs)\n",
    "                \"slot_classifier.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                export_params=True,        # store the trained parameter weights inside the model file\n",
    "                opset_version=11,          # the ONNX version to export the model to\n",
    "                do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                input_names = ['sequence_output'],   # the model's input names\n",
    "                output_names = ['slot_logits'], ##['all_logits','other'],\n",
    "                )\n",
    "\n",
    "# ['slot_logits', 'intent_token_logits', 'referee_token_logits','all_referee_token_logits']\n",
    "\n",
    "\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = 'slot_classifier.onnx'\n",
    "model_quant = './quantized_models/slot_classifier.quant.onnx'\n",
    "quantized_model = quantize_dynamic(model_fp32, model_quant)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# intent_token_classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "dummy_input = out[0]\n",
    "torch.onnx.export(model.intent_token_classifier,               # model being run\n",
    "                dummy_input,               # model input (or a tuple for multiple inputs)\n",
    "                \"intent_token_classifier.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                export_params=True,        # store the trained parameter weights inside the model file\n",
    "                opset_version=11,          # the ONNX version to export the model to\n",
    "                do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                input_names = ['sequence_output'],   # the model's input names\n",
    "                output_names = ['intent_token_logits'], ##['all_logits','other'],\n",
    "                )\n",
    "\n",
    "# ['slot_logits', 'intent_token_logits', 'referee_token_logits','all_referee_token_logits']\n",
    "\n",
    "\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = 'intent_token_classifier.onnx'\n",
    "model_quant = './quantized_models/intent_token_classifier.quant.onnx'\n",
    "quantized_model = quantize_dynamic(model_fp32, model_quant)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# pro_classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True])\n",
      "torch.Size([1, 32, 1536])\n"
     ]
    }
   ],
   "source": [
    "# inputs = {\"input_ids\": batch[0],\n",
    "#           \"attention_mask\": batch[1],\n",
    "#           \"pro_labels_ids\": batch[4],\n",
    "#           'token_type_ids':batch[2]}\n",
    "\n",
    "pro_labels_ids = batch[4][None,:]\n",
    "\n",
    "sequence_output = out[0]\n",
    "if 1 in pro_labels_ids:  # if use pro, and the batch contain pronouns\n",
    "    # 1. concate pronoun to each word in the sequence\n",
    "    pro_token_mask = pro_labels_ids > 0\n",
    "    pro_sample_mask = torch.max(pro_token_mask.long(),dim = 1)[0] > 0\n",
    "    print(pro_sample_mask)\n",
    "    pro_vec = sequence_output[pro_token_mask]\n",
    "    pro_sequence_output = sequence_output[pro_sample_mask]\n",
    "    pro_vec = pro_vec[:, None, :]  # add new dimention\n",
    "    repeat_pro = pro_vec.repeat(1, 32, 1)#self.args.max_seq_len\n",
    "    concated_input = torch.cat((pro_sequence_output, repeat_pro), dim=2)\n",
    "\n",
    "\n",
    "print(concated_input.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "dummy_input = concated_input\n",
    "torch.onnx.export(model.pro_classifier,               # model being run\n",
    "                dummy_input,               # model input (or a tuple for multiple inputs)\n",
    "                \"pro_classifier.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                export_params=True,        # store the trained parameter weights inside the model file\n",
    "                opset_version=11,          # the ONNX version to export the model to\n",
    "                do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                input_names = ['concated_input'],   # the model's input names\n",
    "                output_names = ['referee_token_logits'], ##['all_logits','other'],\n",
    "                )\n",
    "\n",
    "# ['slot_logits', 'intent_token_logits', 'referee_token_logits','all_referee_token_logits']\n",
    "\n",
    "\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = 'pro_classifier.onnx'\n",
    "model_quant = './quantized_models/pro_classifier.quant.onnx'\n",
    "quantized_model = quantize_dynamic(model_fp32, model_quant)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Try Onnx Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading time ONNX:  0.1265733242034912\n",
      "Loading time ONNX:  0.0009701251983642578\n",
      "Loading time ONNX:  0.0007336139678955078\n",
      "Loading time ONNX:  0.0015423297882080078\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import time\n",
    "\n",
    "def initONNX(path):\n",
    "    start = time.time()\n",
    "    sess_options = onnxruntime.SessionOptions()\n",
    "    #sess_options.enable_profiling = True\n",
    "\n",
    "    sess_options.intra_op_num_threads = 1#4\n",
    "    sess_options.execution_mode = onnxruntime.ExecutionMode.ORT_PARALLEL\n",
    "    sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "    ort_session  = onnxruntime.InferenceSession(path, sess_options)\n",
    "    print(\"Loading time ONNX: \", time.time() - start)\n",
    "    return ort_session\n",
    "\n",
    "\n",
    "\n",
    "bert_ort_session = initONNX('./quantized_models/bert.quant.onnx')\n",
    "slot_classifier_ort_session = initONNX('./quantized_models/slot_classifier.quant.onnx')\n",
    "intent_token_classifier_ort_session = initONNX('./quantized_models/intent_token_classifier.quant.onnx')\n",
    "pro_classifier_ort_session = initONNX('./quantized_models/pro_classifier.quant.onnx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bert"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 32, 768)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs = {\"input_ids\": np.array(batch[0][None,:]),\n",
    "            \"attention_mask\": np.array(batch[1][None,:]),\n",
    "             \"token_type_ids\": np.array(batch[2][None,:])}\n",
    "sequence_output,pooled_output = bert_ort_session.run(None, bert_inputs)\n",
    "sequence_output.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## intent token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 32 10\n"
     ]
    }
   ],
   "source": [
    "intent_token_logits = slot_classifier_ort_session.run(None, {'sequence_output':sequence_output})\n",
    "print(len(intent_token_logits),len(intent_token_logits[0]),len(intent_token_logits[0][0]),len(intent_token_logits[0][0][0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## slot token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 32 16\n"
     ]
    }
   ],
   "source": [
    "slot_logits = intent_token_classifier_ort_session.run(None, {'sequence_output':sequence_output})\n",
    "print(len(slot_logits),len(slot_logits[0]),len(slot_logits[0][0]),len(slot_logits[0][0][0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## pro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True])\n",
      "(1, 32, 1536)\n"
     ]
    }
   ],
   "source": [
    "pro_labels_ids = batch[4][None,:]\n",
    "\n",
    "sequence_output = out[0]\n",
    "if 1 in pro_labels_ids:  # if use pro, and the batch contain pronouns\n",
    "    # 1. concate pronoun to each word in the sequence\n",
    "    pro_token_mask = pro_labels_ids > 0\n",
    "    pro_sample_mask = torch.max(pro_token_mask.long(),dim = 1)[0] > 0\n",
    "    print(pro_sample_mask)\n",
    "    pro_vec = sequence_output[pro_token_mask]\n",
    "    pro_sequence_output = sequence_output[pro_sample_mask]\n",
    "    pro_vec = pro_vec[:, None, :]  # add new dimention\n",
    "    repeat_pro = pro_vec.repeat(1, 32, 1)#self.args.max_seq_len\n",
    "    concated_input = torch.cat((pro_sequence_output, repeat_pro), dim=2)\n",
    "\n",
    "concated_input = concated_input.detach().numpy()\n",
    "print(concated_input.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  (32,)\n",
      "s:  (32, 4)\n",
      "d:  (32, 4)\n",
      "e:  (32, 8)\n"
     ]
    }
   ],
   "source": [
    "a = np.squeeze(pro_labels_ids.numpy())\n",
    "print('a: ',a.shape)\n",
    "c = np.array([1,0,0,0])\n",
    "\n",
    "s = np.ones((32,4))\n",
    "print('s: ',s.shape)\n",
    "d = np.tile(c,(32,1))\n",
    "print('d: ',d.shape)\n",
    "e = np.concatenate((s,d),axis = 1).shape\n",
    "print('e: ',e)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  (1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(32, 4)"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = np.zeros(32)\n",
    "g[0]=1\n",
    "k = s[g == 1]\n",
    "print('k: ',k.shape)\n",
    "np.tile(k,(32,1)).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[82], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43many\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpro_labels_ids\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "\n",
    "if 1 in pro_labels_ids:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 32 3\n"
     ]
    }
   ],
   "source": [
    "referee_token_logits = pro_classifier_ort_session.run(None, {'concated_input':concated_input})\n",
    "print(len(referee_token_logits),len(referee_token_logits[0]),len(referee_token_logits[0][0]),len(referee_token_logits[0][0][0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 32, 3)\n",
      "(32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array(referee_token_logits).shape)\n",
    "print(np.squeeze(np.array(referee_token_logits)).shape)\n",
    "a = np.squeeze(np.array(referee_token_logits))\n",
    "np.argmax(a,axis =1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/quantized_models/bert.quant.onnx'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# ! pip install onnx\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# ! pip install onnxruntime\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43monnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/quantized_models/bert.quant.onnx\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m output \u001B[38;5;241m=\u001B[39m[node\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39moutput]\n\u001B[1;32m      7\u001B[0m input_all \u001B[38;5;241m=\u001B[39m [node\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39minput]\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/onnx/__init__.py:133\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(f, format, load_external_data)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(\n\u001B[1;32m    117\u001B[0m     f: Union[IO[\u001B[38;5;28mbytes\u001B[39m], \u001B[38;5;28mstr\u001B[39m],\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28mformat\u001B[39m: Optional[Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    119\u001B[0m     load_external_data: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    120\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ModelProto:\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03m    Loads a serialized ModelProto into memory\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;124;03m    load_external_data is true if the external data under the same directory of the model and load the external data\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;124;03m        Loaded in-memory ModelProto\u001B[39;00m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 133\u001B[0m     s \u001B[38;5;241m=\u001B[39m \u001B[43m_load_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m     model \u001B[38;5;241m=\u001B[39m load_model_from_string(s, \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mformat\u001B[39m)\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m load_external_data:\n",
      "File \u001B[0;32m~/miniconda3/envs/jointbert/lib/python3.9/site-packages/onnx/__init__.py:34\u001B[0m, in \u001B[0;36m_load_bytes\u001B[0;34m(f)\u001B[0m\n\u001B[1;32m     32\u001B[0m     s \u001B[38;5;241m=\u001B[39m cast(IO[\u001B[38;5;28mbytes\u001B[39m], f)\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 34\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m readable:\n\u001B[1;32m     35\u001B[0m         s \u001B[38;5;241m=\u001B[39m readable\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m s\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/quantized_models/bert.quant.onnx'"
     ]
    }
   ],
   "source": [
    "# ! pip install onnx\n",
    "# ! pip install onnxruntime\n",
    "import onnx\n",
    "model = onnx.load('/quantized_models/bert.quant.onnx')\n",
    "output =[node.name for node in model.graph.output]\n",
    "\n",
    "input_all = [node.name for node in model.graph.input]\n",
    "input_initializer =  [node.name for node in model.graph.initializer]\n",
    "net_feed_input = list(set(input_all)  - set(input_initializer))\n",
    "\n",
    "print('Inputs: ', net_feed_input)\n",
    "print('Outputs: ', output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[name: \"slot_logits\"\ntype {\n  tensor_type {\n    elem_type: 1\n    shape {\n      dim {\n        dim_value: 1\n      }\n      dim {\n        dim_value: 32\n      }\n      dim {\n        dim_value: 10\n      }\n    }\n  }\n}\n, name: \"intent_token_logits\"\ntype {\n  tensor_type {\n    elem_type: 1\n    shape {\n      dim {\n        dim_value: 1\n      }\n      dim {\n        dim_value: 32\n      }\n      dim {\n        dim_value: 16\n      }\n    }\n  }\n}\n, name: \"referee_token_logits\"\ntype {\n  tensor_type {\n    elem_type: 1\n    shape {\n      dim {\n        dim_param: \"Addreferee_token_logits_dim_0\"\n      }\n      dim {\n        dim_value: 32\n      }\n      dim {\n        dim_value: 3\n      }\n    }\n  }\n}\n, name: \"all_referee_token_logits\"\ntype {\n  tensor_type {\n    elem_type: 1\n    shape {\n      dim {\n        dim_param: \"ScatterNDall_referee_token_logits_dim_0\"\n      }\n      dim {\n        dim_param: \"ScatterNDall_referee_token_logits_dim_1\"\n      }\n      dim {\n        dim_param: \"ScatterNDall_referee_token_logits_dim_2\"\n      }\n    }\n  }\n}\n]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph.input\n",
    "model.graph.output"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "jointbert",
   "language": "python",
   "display_name": "jointbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
